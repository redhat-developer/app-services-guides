[id="chap-using-quarkus-registry"]
= Using Quarkus applications with Kafka and {registry} instances in {registry-product-long}
ifdef::context[:parent-context: {context}]
:context: quarkus-service-registry

////
START GENERATED ATTRIBUTES
WARNING: This content is generated by running npm --prefix .build run generate:attributes
////


:community:
:imagesdir: ./images
:product-version: 1
:product-long: Application Services
:product: App Services
:registry-product-long: OpenShift Service Registry
:registry: Service Registry
// Placeholder URL, when we get a HOST UI for the service we can put it here properly
:service-url: https://console.redhat.com/beta/application-services/streams/
:registry-url: https://console.redhat.com/beta/application-services/service-registry/
:property-file-name: app-services.properties
:rhoas-version: 0.29.0

// Other upstream project names
:samples-git-repo: https://github.com/redhat-developer/app-services-guides

//URL components for cross refs
:base-url: https://github.com/redhat-developer/app-services-guides/blob/main/
:base-url-cli: https://github.com/redhat-developer/app-services-cli/tree/main/docs/
:getting-started-url: getting-started/README.adoc
:kafka-bin-scripts-url: kafka-bin-scripts/README.adoc
:kafkacat-url: kafkacat/README.adoc
:quarkus-url: quarkus/README.adoc
:rhoas-cli-url: rhoas-cli/README.adoc
:rhoas-cli-ref-url: commands
:topic-config-url: topic-configuration/README.adoc
:consumer-config-url: consumer-configuration/README.adoc
:service-binding-url: service-discovery/README.adoc

////
END GENERATED ATTRIBUTES
////


[IMPORTANT]
====
{registry-product-long} is currently available for Development Preview. Development Preview releases provide early access to a limited set of features that might not be fully tested and that might change in the final GA version. Users should not use Development Preview software in production or for business-critical workloads. Limited documentation is available for Development Preview releases and is typically focused on fundamental user goals.
====

// Purpose statement for the assembly
[role="_abstract"]
As a developer of applications and services, you can connect Quarkus applications to Kafka instances in {product-long} and {registry} instances in {registry-product-long}. 

https://quarkus.io/[Quarkus^] is a Kubernetes-native Java framework made for Java virtual machines (JVMs) and native compilation, and optimized for serverless, cloud, and Kubernetes environments. 

Quarkus is designed to work with popular Java standards, frameworks, and libraries like Eclipse MicroProfile and Spring, as well as Apache Kafka, RESTEasy (JAX-RS), Hibernate ORM (JPA), Infinispan, Camel, and many more.

.Prerequisites
ifndef::community[]
* You have a Red Hat account.
endif::[]
* You have a running Kafka instance in {product}.
* You have a running {registry} instance in {registry-product-long}.
* https://github.com/git-guides/[Git^] is installed.
* You have an IDE such as https://www.jetbrains.com/idea/download/[IntelliJ IDEA^], https://www.eclipse.org/downloads/[Eclipse^], or https://code.visualstudio.com/Download[VSCode^].
* https://adoptopenjdk.net/[JDK^] 11 or later is installed.
* https://maven.apache.org/[Apache Maven^] 3.6.2 or later is installed.
* For Windows, the latest version of https://www.oracle.com/java/technologies/javase-downloads.html[Oracle JDK^] is installed.

// Condition out QS-only content so that it doesn't appear in docs.
// All QS anchor IDs must be in this alternate anchor ID format `[#anchor-id]` because the ascii splitter relies on the other format `[id="anchor-id"]` to generate module files.
ifdef::qs[]
[#description]
Learn how to use Quarkus applications that produce messages to and consume messages from a Kafka instance in {product-long} and manage the message schemas in {registry-product-long}.

[#introduction]
Welcome to the quick start for {registry-product-long} with Quarkus. In this quick start, you'll learn how to use https://quarkus.io/[Quarkus^] to produce messages to and consume messages from your Kafka instances in {product} and manage the message schemas in {registry-product-long}.
endif::[]

[id="proc-importing-quarkus-registry-sample-code_{context}"]
== Importing the Quarkus sample code

[role="_abstract"]
For this quick start, you'll use the Quarkus {registry} sample code from the App Services {samples-git-repo}[Guides and Samples^] repository in GitHub. After you understand the concepts and tasks in this quick start, you can use your own Quarkus applications with {product} and {registry} in the same way.

.Procedure
. On the command line, clone the App Services {samples-git-repo}[Guides and Samples^] repository from GitHub.
+
.Cloning the guides and samples repository
[source,subs="+attributes"]
----
git clone {samples-git-repo} app-services-guides
----
. In your IDE, open the `code-examples/quarkus-service-registry-quickstart` directory from the repository that you cloned.

ifdef::qs[]
.Verification
* Is the Quarkus example application accessible in your IDE?
endif::[]

[id="proc-configuring-quarkus-registry-app_{context}"]
== Configuring the Quarkus application to connect to Kafka and {registry} instances

[role="_abstract"]
To enable your Quarkus application to access a Kafka instance, configure the connection properties using the Kafka bootstrap server endpoint. To access a {registry} instance, configure the registry endpoint connection property with the Core Registry API value. 

Access to the {registry} and Kafka instances is managed using the same service account and SASL/OAUTHBEARER token endpoint. For Quarkus, you can configure all connection properties using the `application.properties` file. This example sets environment variables and references them in this file.

Quarkus applications use https://github.com/eclipse/microprofile-reactive-messaging[MicroProfile Reactive Messaging^] to produce messages to and consume messages from your Kafka instances in {product}. For more details on configuration options, see https://quarkus.io/guides/kafka[Using Apache Kafka with Reactive Messaging^] in the Quarkus documentation.

.Prerequisites
ifndef::qs[]
* You have the Kafka bootstrap server endpoint for the Kafka instance. You copied this information previously for the Kafka instance in {product} by selecting the options menu (three vertical dots) and clicking *Connection*.
* You have the Core Registry API endpoint for the {registry} instance. You copied this information for the {registry} instance  by selecting the options menu (three vertical dots) and clicking *Connection*. From the list of endpoints, you copied the *Core Registry API* that is supported by the Apicurio serializer/deserializer (SerDes) used in this example. 
* You copied the *Token endpoint URL* from the same list of endpoints to be used for the OAuth based athentication method used in this example.
* You have generated a service account from the Service Accounts section of {product} and stored in a secure place.

endif::[]

.Procedure
. On the command line, set the Kafka and {registry} instance URLs, token endpoint URL, and client credentials as environment variables to be used by Quarkus or other applications. Replace the values with your own server and credential information:
+
--
ifdef::qs[]
* The `<bootstrap_server>` is the bootstrap server endpoint for your Kafka instance. 
* The `<registry_uri>` is the CORE API endpoint for your {registry} instance. 
* The `<client_id>` and `<client_secret>` are the generated credentials for your service account.
* The `<oauth_token_endpoint_uri>` is the SASL/OAUTHBEARER token endpoint. 
endif::[]

.Setting environment variables for server and credentials
[source,subs="+quotes"]
----
$ export BOOTSTRAP_SERVER=__<bootstrap_server>__
$ export REGISTRY_URL=__<registry_uri>__
$ export CLIENT_ID=__<client_id>__
$ export CLIENT_SECRET=__<client_secret>__
$ export OAUTH_TOKEN_ENDPOINT_URI=__<oauth_token_endpoint_uri>__
----
--
. In the Quarkus example application, review the `../src/main/resources/application.properties` files to understand how the environment variables you set in the previous step are used in your application. This example uses the `dev` configuration profile in the `application.properties` file.

ifdef::qs[]
.Verification
* Did you set the required environment variables for accessing your services?
endif::[]

[id="proc-create-prices-topic-registry_{context}"]
== Creating the requests and quotes Kafka topics in {product}

[role="_abstract"]
For this quick start, the Kafka topics that the Quarkus example application references are called `requests` and `quotes`. You need to create these topics in {product} so that the Quarkus application can interact with it.

.Prerequisites
* You've created a Kafka instance in {product} and the instance is in *Ready* state.

.Procedure
. In the {product} web console, go to *Streams for Apache Kafka* > *Kafka Instances* and click the name of the Kafka instance that you want to add a topic to.
. Select the *Topics* tab, click *Create topic*, and follow the guided steps to define the topic details. Click *Next* to complete each step and click *Finish* to complete the setup.
+
[.screencapture]
.Guided steps to define topic details
image::sak-create-topic.png[Image of wizard to create a topic]

* *Topic name*: Enter `requests` as the topic name.
* *Partitions*: Set the number of partitions for this topic. This example sets the partition to `1` for a single partition. Partitions are distinct lists of messages in a topic and enable parts of a topic to be distributed over multiple brokers in the cluster. A topic can contain one or more partitions, enabling producer and consumer loads to be scaled.
* *Message retention*: Set the message retention time and size to the relevant value and increment. This example sets the retention time to `A week` and the retention size to `Unlimited`. Message retention time is the amount of time that messages are retained in a topic before they are deleted or compacted, depending on the cleanup policy. Retention size is the maximum total size of all log segments in a partition before they are deleted or compacted.
* *Replicas*: For this release of {product}, the replicas are preconfigured. The number of partition replicas for the topic is set to `3` and the minimum number of follower replicas that must be in sync with a partition leader is set to `2`. 
+
Replicas are copies of partitions in a topic. Partition replicas are distributed over multiple brokers in the cluster to ensure topic availability if a broker fails. When a follower replica is in sync with a partition leader, the follower replica can become the new partition leader if needed.
+
After you complete the topic setup, the new Kafka topic is listed in the topics table. Next, using the same configuration, create the `quotes` topic. You can now run the Quarkus application to start producing and consuming messages to and from these topics.

.Verification
ifdef::qs[]
* Are the new Kafka topics `requests` and `quotes` listed in the topics table?
endif::[]
ifndef::qs[]
* Verify that the new Kafka topics `requests` and `quotes` are listed in the topics table.
endif::[]


[id="proc-running-quarkus-registry-example-app_{context}"]
== Running the Quarkus example application

[role="_abstract"]
After you configure your Quarkus application to connect to Kafka and  {registry} instances, and you create the Kafka topics, you can run the Quarkus application to start producing and consuming messages to and from these topics.

The Quarkus project in this quick start consists of two processes:

* The consumer application is implemented by the `QuotesResource` class. This class exposes the `/quotes/request` REST endpoint as an empty HTTP POST method. Every request to this endpoint is published to the `requests` topic. The same class exposes the `/quotes/quotes` REST endpoint that streams quotes from `quotes` topic. This application also has a minimal frontend that streams quotes from the latter endpoint using Server-Sent Events to the web page.
* The producer application is implemented by the `QuotesProducer` class. This class consumes quote requests from `requests` topic and generates a random quote value that is published to the `quotes` topic.

.Prerequisites
* You've configured the Quarkus example application to connect to the Kafka and {registry} instances.
* You've created the `requests` and `quotes` topics.

.Procedure
. On the command line, navigate to the `code-examples/quarkus-service-registry-quickstart` directory that you imported and run both example applications in the sub-folders.
+
.Running the consumer example application
[source]
----
$ cd ~/code-examples/quarkus-service-registry-quickstart/consumer
$ ./mvnw quarkus:dev
----
. After the application is running, in a web browser, go to http://localhost:8080/quotes.html[^] and verify that the application is available.

. Leave the consumer application running, and run the producer application on a different terminal.
+
.Running the producer example application
[source]
----
$ cd ~/code-examples/quarkus-service-registry-quickstart/producer
$ ./mvnw quarkus:dev
----

. When both the consumer and producer applications are running, view the generated quotes in the web browser at http://localhost:8080/quotes.html[^].

. In the web console, go to *{registry}* > *{registry} Instances*,  select your {registry} instance, and view the automatically generated schemas for your applications.


.What just happened?

* Both applications are configured to use `io.apicurio.registry.serde.avro.AvroKafkaSerializer` for serializing and deserializing messages to Avro format. This SerDes is configured to use remote schemas in {registry-product-long} rather than the local schemas in the project. 

* Because there are no schemas in the {registry} instance, the SerDes published two schemas, one for each topic. The names of the schemas are managed by the `TopicNameStrategy`, which uses the `topic_name-value` convention. You can find these schemas in the {registry} instance and configure compatability rules to govern how the schemas can evolve for future versions.

* If the Quarkus application fails to run, review the error log in the terminal and address any problems. Also review the steps in this quick start to ensure that the Quarkus application and Kafka topic are configured correctly.

ifdef::qs[]
.Verification
* Did the Quarkus example application run without any errors?
* Did you see the generated quotes at http://localhost:8080/quotes.html[^]?
* Did you see generated schemas in the {registry} instance?
endif::[]

ifdef::qs[]
[#conclusion]
Congratulations! You successfully completed the {product} and {registry} Quarkus quick start, and are now ready to use your own Quarkus applications with {product} and {registry}.
endif::[]

ifdef::parent-context[:context: {parent-context}]
ifndef::parent-context[:!context:]
