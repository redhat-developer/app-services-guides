////
START GENERATED ATTRIBUTES
WARNING: This content is generated by running npm --prefix .build run generate:attributes
////


:community:
:imagesdir: ./images
:product-version: 1
:product-long: Application Services
:product: App Services
:registry-product-long: OpenShift Service Registry
:registry: Service Registry
// Placeholder URL, when we get a HOST UI for the service we can put it here properly
:service-url: https://console.redhat.com/beta/application-services/streams/
:registry-url: https://console.redhat.com/beta/application-services/service-registry/
:property-file-name: app-services.properties
:rhoas-version: 0.32.0

// Other upstream project names
:samples-git-repo: https://github.com/redhat-developer/app-services-guides

//URL components for cross refs
:base-url: https://github.com/redhat-developer/app-services-guides/blob/main/
:base-url-cli: https://github.com/redhat-developer/app-services-cli/tree/main/docs/
:getting-started-url: getting-started/README.adoc
:kafka-bin-scripts-url: kafka-bin-scripts/README.adoc
:kafkacat-url: kafkacat/README.adoc
:quarkus-url: quarkus/README.adoc
:rhoas-cli-url: rhoas-cli/README.adoc
:rhoas-cli-kafka-url: rhoas-cli-kafka/README.adoc
:rhoas-cli-service-registry-url: rhoas-cli-service-registry/README.adoc
:rhoas-cli-ref-url: commands
:topic-config-url: topic-configuration/README.adoc
:consumer-config-url: consumer-configuration/README.adoc
:service-binding-url: service-discovery/README.adoc
:access-mgmt-url: access-mgmt/README.adoc

////
END GENERATED ATTRIBUTES
////

[id="chap-using-kafkacat"]
= Configuring and connecting Kafkacat with {product-long}
ifdef::context[:parent-context: {context}]
:context: using-kafkacat

[IMPORTANT]
====
{product-long} is currently available for Development Preview. Development Preview releases provide early access to a limited set of features that might not be fully tested and that might change in the final GA version. Users should not use Development Preview software in production or for business-critical workloads. Limited documentation is available for Development Preview releases and is typically focused on fundamental user goals.
====

// Purpose statement for the assembly
[role="_abstract"]
As a developer of applications and services, you can use https://github.com/edenhill/kafkacat[Kafkacat^] to test and debug your Kafka instances in {product-long}.
Kafkacat is a command-line utility for messaging in Apache Kafka 0.8 and later.
With Kafkacat, you can produce and consume messages for your Kafka instances directly from the command line,
and list topic and partition information for your Kafka instances.

ifndef::community[]
NOTE: Kafkacat is an open source community tool. Kafkacat is not a part of {product} and is therefore not supported by Red Hat.
endif::[]

You can install and use Kafkacat to test and debug your Kafka instances in {product}.

.Prerequisites
ifndef::community[]
* You have a Red Hat account.
endif::[]
//* You have a subscription to {product-long}. For more information about signing up, see *<@SME: Where to link?>*.
* You have a running Kafka instance in {product}.
* https://adoptopenjdk.net/[JDK^] 11 or later is installed.
* For Windows, the latest version of https://www.oracle.com/java/technologies/javase-downloads.html[Oracle JDK^] is installed.
* You have installed the latest supported version of https://github.com/edenhill/kafkacat[Kafkacat^] for your operating system.
+
.Verifying Kafkacat installation
[source]
----
$ kafkacat -V

kafkacat - Apache Kafka producer and consumer tool
https://github.com/edenhill/kafkacat
Copyright (c) 2014-2019, Magnus Edenhill
Version 1.6.0 (JSON, Avro, Transactions, librdkafka 1.6.1 builtin.features=gzip,snappy,ssl,sasl,regex,lz4,sasl_gssapi,sasl_plain,sasl_scram,plugins,zstd,sasl_oauthbearer)
----

// Condition out QS-only content so that it doesn't appear in docs.
// All QS anchor IDs must be in this alternate anchor ID format `[#anchor-id]` because the ascii splitter relies on the other format `[id="anchor-id"]` to generate module files.
ifdef::qs[]
[#description]
Learn how to use Kafkacat to interact with a Kafka instance in {product-long}.

[#introduction]
Welcome to the quick start for {product-long} with Kafkacat. In this quick start, you'll learn how to use https://github.com/edenhill/kafkacat[Kafkacat^] to produce and consume messages for your Kafka instances in {product}.
endif::[]

[id="proc-configuring-kafkacat_{context}"]
== Configuring Kafkacat to connect to a Kafka instance

To enable Kafkacat to access a Kafka instance, configure the connection using the bootstrap server endpoint for the instance and the generated credentials for your {product} service account. For Kafkacat, you can configure connection information either by passing options to the `kafkacat` command or by using a configuration file. The example in this task sets environment variables and then passes them to the `kafkcat` command.

For more information about Kafkacat configuration options, see https://github.com/edenhill/kafkacat#configuration[Configuration^] in the Kafkacat documentation.

NOTE: Kafkacat does not yet fully support SASL/OAUTHBEARER authentication, so connecting to a Kafka instance requires only the bootstrap server and the service account credentials for SASL/PLAIN authentication.

.Prerequisites
ifndef::qs[]
* You have the bootstrap server endpoint for your Kafka instance. To relocate the server endpoint, select your Kafka instance in the {product} web console, select the options menu (three vertical dots), and click *Connection*.
* You have the generated credentials for your service account. To regenerate the credentials, use the *Service Accounts* page in the {product} web console to find your service account and update the credentials.
* You've set the permissions for your service account to access the Kafka instance resources. To verify the current permissions, select your Kafka instance in the {product} web console and use the *Access* page to find your service account permission settings.
endif::[]

.Procedure
* On the command line, set the Kafka instance bootstrap server and client credentials as environment variables to be used by Kafkacat or other applications. Replace the values with your own server and credential information.
+
--
ifdef::qs[]
The `<bootstrap_server>` is the bootstrap server endpoint for your Kafka instance. The `<client_id>` and `<client_secret>` are the generated credentials for your service account. You copied this information previously for the Kafka instance in {product} by selecting the options menu (three vertical dots) and clicking *Connection*.
endif::[]

.Setting environment variables for server and credentials
[source,subs="+quotes"]
----
$ export BOOTSTRAP_SERVER=__<bootstrap_server>__
$ export USER=__<client_id>__
$ export PASSWORD=__<client_secret>__
----
--

[id="proc-producing-messages-kafkacat_{context}"]
== Producing messages in Kafkacat

You can use Kafkacat to produce messages to Kafka topics in several ways, such as reading them from standard input (`stdin`) directly on the command line or from a file. This example produces messages from input on the command line. For more examples of Kafkacat producer messaging, see the https://github.com/edenhill/kafkacat#examples[Examples^] in the Kafkacat documentation.

.Prerequisites
* Kafkacat is installed.
* You have a running Kafka instance in {product}.
* You've set the Kafka bootstrap server endpoint and your service account credentials as environment variables.

.Procedure
. On the command line, enter the following commands to start Kafkacat in _producer_ mode. This mode enables you to produce messages to your Kafka topic.
+
--
This example uses the SASL/PLAIN authentication mechanism with the server and credential environment variables that you set previously. This example produces messages to a topic in {product} named `my-first-kafka-topic`. Replace the topic name with the relevant topic as needed. The topic that you use in this command must already exist in {product}.

.Starting Kafkacat in producer mode
[source]
----
$ kafkacat -t my-first-kafka-topic -b "$BOOTSTRAP_SERVER" \
 -X security.protocol=SASL_SSL -X sasl.mechanisms=PLAIN \
 -X sasl.username="$USER" \
 -X sasl.password="$PASSWORD" -P
----

NOTE: {product} also supports the SASL/OAUTHBEARER mechanism for authentication, which is the recommended authentication mechanism to use. However, Kafkacat does not yet fully support OAUTHBEARER, so this example uses SASL/PLAIN.

--
. With Kafkacat running in producer mode, enter messages into Kafkacat that you want to produce to the Kafka topic.
+
.Example messages to produce to the Kafka topic
[source]
----
First message
Second message
Third message
----
. Keep this producer running to use later when you create a consumer.

.Verification
ifdef::qs[]
* Is your producer still running without any errors in the terminal?
endif::[]
ifndef::qs[]
* Verify that your producer is still running without any errors in the terminal.
endif::[]

[id="proc-consuming-messages-kafkacat_{context}"]
== Consuming messages in Kafkacat

You can use Kafkacat to consume messages from Kafka topics. This example consumes the messages that you sent previously with the producer that you created with Kafkacat.

.Prerequisites
* Kafkacat is installed.
* You have a running Kafka instance in {product}.
* You've set the Kafka bootstrap server endpoint and your service account credentials as environment variables.
* You used a producer to produce example messages to a topic.

.Procedure
. On the command line in a separate terminal from your producer, enter the following commands to start Kafkacat in _consumer_ mode. This mode enables you to consume messages from your Kafka topic.
+
--
This example uses the SASL/PLAIN authentication mechanism with the server and credential environment variables that you set previously. This example consumes and displays the messages from the `my-first-kafka-topic` example topic, and states that it reached the end of partition `0` in the topic.

.Starting Kafkacat in consumer mode
[source]
----
$ kafkacat -t my-first-kafka-topic -b "$BOOTSTRAP_SERVER" \
 -X security.protocol=SASL_SSL -X sasl.mechanisms=PLAIN \
 -X sasl.username="$USER" \
 -X sasl.password="$PASSWORD" -C

First message
Second message
Third message
% Reached end of topic my-first-kafka-topic [0] at offset 3
----
--
. If your producer is still running in a separate terminal, continue entering messages in the producer terminal and observe the messages being consumed in the consumer terminal.

.Verification
ifdef::qs[]
* Is your consumer running without any errors in the terminal?
* Did the consumer display the messages from the `my-first-kafka-topic` example topic?
endif::[]
ifndef::qs[]
. Verify that your consumer is running without any errors in the terminal.
. Verify that the consumer displays the messages from the `my-first-kafka-topic` example topic.
endif::[]

ifdef::qs[]
[#conclusion]
Congratulations! You successfully completed the {product} Kafkacat quick start, and are now ready to produce and consume messages in the service.
endif::[]

ifdef::parent-context[:context: {parent-context}]
ifndef::parent-context[:!context:]
