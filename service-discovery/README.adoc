////
START GENERATED ATTRIBUTES
WARNING: This content is generated by running npm --prefix .build run generate:attributes
////


:community:
:imagesdir: ./images
:product-version: 1
:product-long: Application Services
:product: App Services
// Placeholder URL, when we get a HOST UI for the service we can put it here properly
:service-url: https://console.redhat.com/beta/application-services/streams/
:property-file-name: app-services.properties
:rhoas-version: 0.25.0

// Other upstream project names
:samples-git-repo: https://github.com/redhat-developer/app-services-guides

//URL components for cross refs
:base-url: https://github.com/redhat-developer/app-services-guides/blob/main/
:base-url-cli: https://github.com/redhat-developer/app-services-cli/tree/main/docs/
:getting-started-url: getting-started/README.adoc
:kafka-bin-scripts-url: kafka-bin-scripts/README.adoc
:kafkacat-url: kafkacat/README.adoc
:quarkus-url: quarkus/README.adoc
:rhoas-cli-url: rhoas-cli/README.adoc
:rhoas-cli-ref-url: commands
:topic-config-url: topic-configuration/README.adoc
:consumer-config-url: consumer-configuration/README.adoc

////
END GENERATED ATTRIBUTES
////

[id="chap-binding-openshift-applications"]
= Binding OpenShift applications to {product-long}
:context: service-binding

[IMPORTANT]
====
{product-long} is currently available for Development Preview. Development Preview releases provide early access to a limited set of features that might not be fully tested and that might change in the final GA version. Users should not use Development Preview software in production or for business-critical workloads. Limited documentation is available for Development Preview releases and is typically focused on fundamental user goals.
====

[role="_abstract"]
As a developer of applications and services, you can connect applications deployed on a Kubernetes platform such as Red Hat OpenShift to Kafka instances created in {product-long}.

For example, suppose you have the following applications deployed on OpenShift:

* One application that publishes price updates for a variety of stocks
* A second application that consumes the price updates for publication on a web page

In addition, you have a Kafka instance in {product}. Each time the first application produces a price update, you want to use the Kafka instance to forward the update as an event to the second, consuming application.

To achieve this behavior, you need a way to connect the applications to your Kafka instance in {product}.

You can use a specialized Operator called the Service Binding Operator to automatically provide an application on Kubernetes with the parameters required to connect to a Kafka instance in {product}. This process is called __service binding__.

This guide describes how to perform service binding. The Kubernetes platform referred to in the remainder of this guide is Red Hat OpenShift.


[id="con-about-service-binding_{context}"]
== About service binding

You can use a specialized Operator called the Service Binding Operator to automatically provide an application on OpenShift with the parameters required to connect to a specified Kafka instance in {product-long}. This process is called __service binding__. To perform service binding, you must also install the Red Hat OpenShift Application Services (RHOAS) Operator.

The RHOAS Operator exposes a Kafka instance created in {product} to an OpenShift cluster. The Service Binding Operator collects and shares the information required for an application running on the OpenShift cluster to connect to the Kafka instance.

When the RHOAS Operator and Service Binding Operator are installed, you can use the RHOAS CLI to perform service binding. When connection between your application and Kafka instance is established, you can then work directly with the Kafka instance using standard OpenShift features and APIs.

When you perform service binding, the Service Binding Operator injects connection parameters for the Kafka instance into the pod for your application, as files. The Service Binding Operator creates the following directory and file structure in the application pod:

.Files injected by the Service Binding Operator
[source, subs="+quotes"]
----
/bindings/__<kafka-instance-name>__
├── bootstrapServers
├── password
├── provider
├── saslMechanism
├── securityProtocol
├── type
└── user
----

Each file that the Service Binding Operator injects into the application pod contains a single connection parameter, specified in plain text. The connection parameters that correspond to the injected files are described below.

bootstrapServers:: Bootstrap server endpoint for the Kafka instance.
password:: Password for connection to the Kafka instance.
provider:: Cloud provider for the Kafka instance.
saslMechanism:: Simple Authentication and Security Layer (SASL) mechanism used by the Kafka instance for client authentication.
securityProtocol:: Protocol used by the Kafka instance to secure client connections.
type:: Metadata that identifies the Red Hat OpenShift Application Services (RHOAS) service. For a Kafka instance in {product}, this is set to a value of `kafka`.
user:: User name for connection to the Kafka instance.

[id="proc-installing-rhoas-operator_{context}"]
== Installing the RHOAS Operator on OpenShift

[role="_abstract"]
Before you can bind Kafka instances in {product-long} to applications on OpenShift, you need to install the Red Hat OpenShift Application Services (RHOAS) Operator on your OpenShift cluster. The following procedure shows how to use the OperatorHub interface in the OpenShift web console to install the RHOAS Operator.

.Prerequisites
* You can access your OpenShift cluster with the `dedicated-admin` role (OpenShift Dedicated) or `cluster-admin` role. Only these roles have privileges to install an Operator on a cluster.

.Procedure
. Log in to the OpenShift web console with the `dedicated-admin` role (OpenShift Dedicated) or `cluster-admin` role.
. Click the perspective switcher in the upper-left corner. Switch to the *Administrator* perspective.
. In the left menu, click *Operators* > *OperatorHub*.
. In the *Filter by keyword* field, enter `RHOAS`.
. In the filtered results, select the *OpenShift Application Services (RHOAS)* Operator.
. If you see a dialog box entitled *Show community Operator*, review the included information. When you've finished, click *Continue*.
+
An information sidebar for the RHOAS Operator opens.

. In the sidebar, review the information about the RHOAS Operator and click *Install*.
. On the *Install Operator* page, perform the following actions:
.. For the *Installation mode* option, ensure that `All namespaces on the cluster` is selected.
.. For the *Update channel*, *Installed Namespace*, and *Update approval* options, keep the default values.
.. Click *Install*.
. When the installation process is finished, click *View Operator* to see the Operator details.
+
The *Operator details* page for the RHOAS Operator opens in the *Installed Operators* section of the web console.
+
On the **Operator details** page, the **Status** field shows a value of `Succeeded`.
+
Also, you can observe that the RHOAS Operator is installed in the `openshift-operators` namespace.

[id="proc-installing-service-binding-operator_{context}"]
== Installing the Service Binding Operator on OpenShift

[role="_abstract"]
Before you can bind Kafka instances in {product-long} to applications on OpenShift, you need to install the Service Binding Operator on your OpenShift cluster. The following procedure shows how to use the OperatorHub interface in the OpenShift web console to install the Service Binding Operator.

.Prerequisites
* You can access your OpenShift cluster with the `dedicated-admin` role (OpenShift Dedicated) or `cluster-admin` role. Only these roles have privileges to install an Operator on a cluster.

.Procedure
. Log in to the OpenShift web console with the `dedicated-admin` role (OpenShift Dedicated) or `cluster-admin` role.
. Click the perspective switcher in the upper-left corner. Switch to the *Administrator* perspective.
. In the left menu, click *Operators* > *OperatorHub*.
. In the *Filter by keyword* field, enter `Service Binding`.
. In the filtered results, click *Service Binding Operator*.
+
An information sidebar for the Service Binding Operator opens.
. In the sidebar, review the information about the Service Binding Operator and click *Install*.
. On the *Install Operator* page, perform the following actions:
.. For the *Update channel* option, select `beta`.
.. For the *Installation mode* option, ensure that `All namespaces on the cluster` is selected.
.. For the *Installed Namespace* and *Update approval* options, keep the default values.
.. Click *Install*.
. When the installation process is finished, click *View Operator* to see the Operator details.
+
The *Operator details* page for the Service Binding Operator opens in the *Installed Operators* section of the web console.
+
On the **Operator details** page, the **Status** field shows a value of `Succeeded`.
+
Also, you can observe that the Service Binding Operator is installed in the `openshift-operators` namespace.

[id="con-binding-openshift-application-using-cli_{context}"]
== Binding an OpenShift application to {product-long} using the RHOAS CLI

When the Red Hat OpenShift Application Services (RHOAS) Operator and Service Binding Operator are installed on your OpenShift cluster, you can use the RHOAS CLI to interact directly with the cluster. One CLI command instructs the RHOAS Operator to connect a specified Kafka instance to your OpenShift cluster. Another CLI command instructs the Service Binding Operator to automatically inject a specified application running on the cluster with the parameters required to connect to the Kafka instance. Using the Service Binding Operator to automatically inject an application with connection parameters for a Kafka instance is called __service binding__.

The following tutorial shows how to use the RHOAS CLI to perform service binding. In the tutorial, you create an example Quarkus application and connect this to a Kafka instance. link:https://quarkus.io/[Quarkus^] is a Kubernetes-native Java framework that is optimized for serverless, cloud, and Kubernetes environments.

When you perform service binding, the Service Binding Operator injects connection parameters as files into the pod for the application. Because the example Quarkus application uses the `quarkus-kubernetes-service-binding` link:https://quarkus.io/guides/deploying-to-kubernetes#service-binding[extension], the application automatically detects and uses the injected connection parameters.

In general, this automatic injection and detection of connection parameters eliminates the need to manually configure an application to connect to a Kafka instance in {product}. This is a particular advantage if you have many applications in your project that you want to connect to a Kafka instance.

[id="proc-verifying-connection-to-openshift-cluster_{context}"]
=== Verifying connection to your OpenShift cluster

[role="_abstract"]
In this step of the tutorial, you verify that the installed RHOAS Operator is working by using the RHOAS CLI to connect to your OpenShift cluster and retrieve the cluster status.

.Prerequisites
* The RHOAS Operator is installed on your OpenShift cluster. See xref:proc-installing-rhoas-operator_{context}[].
* You can access your OpenShift cluster with privileges to create a new project.
* You've installed the OpenShift CLI. For more information, see link:https://docs.openshift.com/container-platform/4.7/cli_reference/openshift_cli/getting-started-cli.html#installing-openshift-cli[Installing the OpenShift CLI].
* You've installed the RHOAS CLI. For more information, see link:{base-url}{rhoas-cli-url}#proc-installing-rhoas_getting-started-rhoas[Installing the RHOAS CLI].

.Procedure
. On your computer, open a command-line window.
. Log in to the OpenShift CLI using a token.
.. Log in to the OpenShift web console as a user who has privileges to create a new project in the cluster.
.. In the upper-right corner of the console, next to your user name, click the drop-down menu. Select *Copy login command*.
+
A new page opens.
.. Click the *Display Token* link.
.. In the section entitled *Log in with this token*, copy the full `oc login` command shown.
.. On the command line, paste the login command you copied. Right-click on the command line and select *Paste*.
+
You see output confirming that you're logged in to your OpenShift cluster and the current project that you're using.

. On the command line, create a new project, as shown in the following example.
+
.Creating a new OpenShift project
[source, subs="+quotes"]
----
$ oc new-project rhoas-quarkus
----

. Log in to the RHOAS CLI.
+
.Logging in to the RHOAS CLI
[source]
----
$ rhoas login
----
+
The login command opens a sign-in process in your web browser.

. On the command line, use the RHOAS CLI to connect to your OpenShift cluster and retrieve the cluster status.
+
.Using the RHOAS CLI to retrieve the status of your OpenShift cluster
[source]
----
$ rhoas cluster status
Namespace: rhoas-quarkus
RHOAS Operator: Installed
----
+
As shown in the output, the RHOAS CLI indicates that the RHOAS Operator was successfully installed. The CLI also retrieves the name of the current OpenShift project (namespace).

[id="proc-connecting-kafka-instance-to-openshift-cluster_{context}"]
=== Connecting a Kafka instance to your OpenShift cluster

[role="_abstract"]
When you've verified connection to your OpenShift cluster, you can connect a specific Kafka instance in {product} to the current project in the cluster. In this step of the tutorial, you use the RHOAS CLI to connect a specified Kafka instance to a project in your cluster.

.Prerequisites
* You've completed the previous steps in this tutorial:
** xref:proc-verifying-connection-to-openshift-cluster_{context}[]
* You’ve created a Kafka instance in {product} and the instance is in the *Ready* state. To learn how to create a Kafka instance, see link:{base-url}{getting-started-url}[Getting started with {product-long}].
* You have an API token to connect to your Kafka instance. To get a token, see the link:https://console.redhat.com/openshift/token[OpenShift Cluster Manager API Token] page.

.Procedure

. If you're not already logged in to the OpenShift CLI, log in using a token, as described earlier in this tutorial.

. If you're not already logged in to the RHOAS CLI, log in as described earlier in this tutorial.

. Use the OpenShift CLI to ensure that the current OpenShift project is the one created earlier in this tutorial, as shown in the following example.
+
.Using the OpenShift CLI to specify the current OpenShift project
[source]
----
$ oc project rhoas-quarkus
----

. Use the RHOAS CLI to connect a Kafka instance in {product} to the current project in your OpenShift cluster.
+
.Using the RHOAS CLI to connect a Kafka instance to your OpenShift cluster
[source]
----
$ rhoas cluster connect
----
+
You're prompted to specify the Kafka instance that you want to connect to OpenShift.

.  If you have more than one Kafka instance, use the up and down arrows on your keyboard to highlight the instance that you want to connect to OpenShift. Press *Enter*.
+
You should see output like the following:
+
.Example output from the cluster connect command
[source,options="nowrap"]
----
Connection Details:

Apache Kafka instance:  my-kafka-instance
Kubernetes Namespace:   rhoas-quarkus
Service Account Secret: rh-cloud-services-service-account
----

. Verify the connection details shown by the RHOAS CLI. When you're ready to continue, type `y` and then press *Enter*.
+
You're prompted to provide an access token. The RHOAS Operator requires this token to connect to your Kafka instance.

. In your web browser, open the link:https://console.redhat.com/openshift/token[OpenShift Cluster Manager API Token] page.

. On the OpenShift Cluster Manager API Token page, click **Load token**. When the page is refreshed, copy the API token shown.

. On the command line, right-click and select *Paste*. Press *Enter*.
+
The RHOAS Operator uses the API token to create a `KafkaConnection` resource on your OpenShift cluster. When this process is complete, you should see lines like the following:
+
.Example output from creation of KafkaConnection resource
[source,options="nowrap"]
----
Service Account Secret "rh-cloud-services-service-account" created successfully
KafkaConnection resource "my-kafka-instance" has been created
Waiting for status from KafkaConnection resource.
Created KafkaConnection can be injected into your application.
...
KafkaConnection successfully installed on your cluster.
----

. Use the OpenShift CLI to verify that the RHOAS Operator successfully created the connection.
+
.Using the OpenShift CLI to verify Operator connection to your cluster
[source]
----
$ oc get KafkaConnection

NAME   		         AGE
my-kafka-instance    2m35s
----
+
As shown in the output, the RHOAS Operator creates a `KafkaConnection` resource that matches the name of your Kafka instance. In this example, the resource name matches a Kafka instance called `my-kafka-instance`.

[id="proc-deploying-example-application-in-openshift_{context}"]
=== Deploying an example application in OpenShift

[role="_abstract"]
In this step of the tutorial, you deploy an example Quarkus application in the OpenShift project that you created earlier in the tutorial.

The Quarkus application generates random numbers between 0 and 100 and produces those numbers to a Kafka topic. Another part of the application consumes the numbers from the Kafka topic. Finally, the application uses __server-sent events__ to expose the numbers as a REST UI. A web page in the application displays the exposed numbers.

The example Quarkus application uses the `quarkus-kubernetes-service-binding` link:https://quarkus.io/guides/deploying-to-kubernetes#service-binding[extension], which means that the application automatically detects and uses the injected connection parameters. This eliminates the need for manual configuration of the application.

.Prerequisites
* You've completed the previous steps in this tutorial:
** xref:proc-verifying-connection-to-openshift-cluster_{context}[]
** xref:proc-connecting-kafka-instance-to-openshift-cluster_{context}[]
* You've privileges to deploy applications in the OpenShift project created earlier in this tutorial.

.Procedure

. If you're not already logged in to the OpenShift CLI, log in using a token, as described earlier in this tutorial. Log in as the same user who created a new project earlier in the tutorial.

. Use the OpenShift CLI to ensure that the current OpenShift project is the one created earlier in this tutorial, as shown in the following example.
+
.Using the OpenShift CLI to specify the current OpenShift project
[source]
----
$ oc project rhoas-quarkus
----

. To deploy the Quarkus application, apply an example application template provided by {product}.
+
.Deploying an example Quarkus application
[source,options="nowrap"]
----
$ oc apply -f https://raw.githubusercontent.com/redhat-developer/app-services-guides/main/code-examples/quarkus-kafka-quickstart/.kubernetes/kubernetes.yml

service/rhoas-quarkus-kafka created
deployment.apps/rhoas-quarkus-kafka created
route.route.openshift.io/rhoas-quarkus-kafka created
----
+
As shown in the output, when you deploy the application, OpenShift creates a service and route for access to the application.

. Get the URL of the route created for the application.
+
.Getting the route details for the Quarkus application
[source,options="nowrap"]
----
$ oc get route

NAME                   HOST/PORT
rhoas-quarkus-kafka    rhoas-quarkus-kafka-jbyrne-dev.apps.sandbox-m2.ll9k.p1.openshiftapps.com
----

. On the command line, highlight the URL shown under *HOST/PORT*. Right-click and select *Copy*.

. In your web browser, paste the URL for the route. Ensure that the URL includes `http://`.
+
A web page for the Quarkus application opens.

. In your web browser, append `/prices.html` to the URL.
+
A new web page entitled *Last price* opens.  Because you haven't yet connected the Quarkus application to your Kafka instance, the price value appears as `N/A`.

[id="proc-creating-topic-in-kafka-instance_{context}"]
=== Creating a topic in your Kafka instance

[role="_abstract"]
In the previous step of this tutorial, you created an example OpenShift application. The application is a Quarkus application that uses a Kafka topic called `prices` to produce and consume messages. In this step, you create the `prices` topic in your Kafka instance so that the Quarkus application can interact with it.

.Prerequisites
* You've completed the previous steps in this tutorial:
** xref:proc-verifying-connection-to-openshift-cluster_{context}[]
** xref:proc-connecting-kafka-instance-to-openshift-cluster_{context}[]
** xref:proc-deploying-example-application-in-openshift_{context}[]
* You’ve created a Kafka instance in {product} and the instance is in the *Ready* state. To learn how to create a Kafka instance, see link:{base-url}{getting-started-url}[Getting started with {product-long}].

.Procedure
. On the link:{service-url}[Kafka Instances] page of the {product} web console, click the name of the Kafka instance that you want to add a topic to.

. Click *Create topic* and follow the guided steps to define the details of the `prices` topic. Click *Next* to complete each step and click *Finish* to complete the setup.
+
.Guided steps to define topic
image::sak-create-prices-topic.png[Image of wizard to create prices topic]

*Topic name*:: Enter `prices` as the topic name.
*Partitions*:: Set the number of partitions for this topic. For this tutorial, set a value of `1`. Partitions are distinct lists of messages within a topic and enable parts of a topic to be distributed over multiple brokers in the cluster. A topic can contain one or more partitions, enabling producer and consumer loads to be scaled.
+
NOTE: You can increase the number of partitions later, but you cannot decrease them.
+
*Message retention*:: Set the message retention time to the relevant value and increment. For this tutorial, set a value of `7 days`. Message retention time is the amount of time that messages are retained in a topic before they are deleted or compacted, depending on the cleanup policy.
*Replicas*:: For this release of {product}, the replicas are preconfigured. The number of partition replicas for the topic is set to `3` and the minimum number of follower replicas that must be in sync with a partition leader is set to `2`. Replicas are copies of partitions in a topic. Partition replicas are distributed over multiple brokers in the cluster to ensure topic availability if a broker fails. When a follower replica is in sync with a partition leader, the follower replica can become the new partition leader if needed.
+
After you complete the topic setup, the new Kafka topic is listed in the topics table.

[id="proc-binding-kafka-instance-to-openshift-application_{context}"]
=== Binding your Kafka instance to your OpenShift application

In this step of the tutorial, you use the RHOAS CLI to bind your Kafka instance to your OpenShift application. When you perform this binding, the Service Binding Operator injects connection parameters as files into the pod for the application. The Quarkus application automatically detects and uses the connection parameters to bind to the Kafka instance.

.Prerequisites
* The Service Binding Operator is installed on your OpenShift cluster. See xref:proc-installing-service-binding-operator_{context}[].
* You've completed the previous steps in this tutorial:
** xref:proc-verifying-connection-to-openshift-cluster_{context}[]
** xref:proc-connecting-kafka-instance-to-openshift-cluster_{context}[]
** xref:proc-deploying-example-application-in-openshift_{context}[]
** xref:proc-creating-topic-in-kafka-instance_{context}[]
* You understand how the Service Binding Operator injects connection parameters as files into a client application pod. To learn more, see xref:con-about-service-binding_{context}[].

.Procedure
. If you're not already logged in to the OpenShift CLI, log in using a token, as described earlier in this tutorial. Log in as the same user who created a new project earlier in the tutorial.

. If you're not already logged in to the RHOAS CLI, log in as described earlier in the tutorial.

. Use the OpenShift CLI to ensure that the current OpenShift project is the one created earlier in this tutorial, as shown in the following example.
+
.Using the OpenShift CLI to specify the current OpenShift project
[source]
----
$ oc project rhoas-quarkus
----

. Use the RHOAS CLI to instruct the Service Binding Operator to bind your Kafka instance to an application in your OpenShift project.
+
.Using the RHOAS CLI to bind a Kafka instance to an application in OpenShift
[source]
----
$ rhoas cluster bind
----
+
You're prompted to specify the Kafka instance that you want to bind to an application in your OpenShift project.

.  If you have more than one Kafka instance, use the up and down arrows on your keyboard to highlight the instance that you want to bind to an application in OpenShift. Press *Enter*.
+
You're prompted to specify the application that you want to bind your Kafka instance to.

. If you have more than one application in your OpenShift project, use the up and down arrows on your keyboard to highlight the `rhoas-quarkus-kafka` example application. Press *Enter*.

. Type `y` to confirm that you want to continue. Press *Enter*.
+
When binding is complete, you should see output like the following:
+
.Example output from binding a Kafka instance to an application in OpenShift
[source]
----
Using Service Binding Operator to perform binding
Binding my-kafka-instance with rhoas-quarkus-kafka app succeeded
----
+
The output shows that the RHOAS CLI successfully instructed the Service Binding Operator to bind a Kafka instance called `my-kafka-instance` to the example Quarkus application called `rhoas-quarkus-kafka`. The Quarkus application automatically detected the connection parameters injected by the Service Binding Operator and used them to bind with the Kafka instance.
+
When service binding is complete, OpenShift redeploys the Quarkus application. When the application is running again, it starts to use the `prices` Kafka topic that you created in your Kafka instance. One part of the Quarkus application publishes price updates to this topic, while another part of the application consumes the updates.

. To verify that the Quarkus application is using the Kafka topic, reopen the *Last price* web page that you opened earlier in this tutorial.
+
On the *Last price* web page, observe that the price value is continuously updated. The updates show that the Quarkus application is now using the `prices` topic in your Kafka instance to produce and consume messages that correspond to price updates.
