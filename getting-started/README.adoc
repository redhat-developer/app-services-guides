////
START GENERATED ATTRIBUTES
WARNING: This content is generated by running npm --prefix .build run generate:attributes
////


:org-name: Application Services
:community:
:imagesdir: ./images
:product-version: 1
:product-long: OpenShift Streams for Apache Kafka
:product: Streams for Apache Kafka
:registry-product-long: OpenShift Service Registry
:registry: Service Registry
// Placeholder URL, when we get a HOST UI for the service we can put it here properly
:service-url: https://console.redhat.com/application-services/streams/
:registry-url: https://console.redhat.com/application-services/service-registry/
:property-file-name: app-services.properties

// Other upstream project names
:samples-git-repo: https://github.com/redhat-developer/app-services-guides

//URL components for cross refs
:base-url: https://github.com/redhat-developer/app-services-guides/blob/main/
:base-url-cli: https://github.com/redhat-developer/app-services-cli/tree/main/docs/
:getting-started-url: getting-started/README.adoc
:getting-started-service-registry-url: getting-started-service-registry/README.adoc
:kafka-bin-scripts-url: kafka-bin-scripts/README.adoc
:kafkacat-url: kafkacat/README.adoc
:quarkus-url: quarkus/README.adoc
:quarkus-service-registry-url: quarkus-service-registry/README.adoc
:rhoas-cli-url: rhoas-cli/README.adoc
:rhoas-cli-kafka-url: rhoas-cli-kafka/README.adoc
:rhoas-cli-service-registry-url: rhoas-cli-service-registry/README.adoc
:rhoas-cli-ref-url: commands
:topic-config-url: topic-configuration/README.adoc
:consumer-config-url: consumer-configuration/README.adoc
:service-binding-url: service-discovery/README.adoc
:access-mgmt-url: access-mgmt/README.adoc
:access-mgmt-service-registry-url: access-mgmt-service-registry/README.adoc
:metrics-monitoring-url: metrics-monitoring/README.adoc

////
END GENERATED ATTRIBUTES
////

[id="chap-getting-started"]
= Getting started with {product-long}
ifdef::context[:parent-context: {context}]
:context: getting-started

// Purpose statement for the assembly
[role="_abstract"]
As a developer of applications and services, you can use {product-long} to create and set up Kafka instances and connect your applications and services to these instances. {product} is a managed cloud service that enables you to add Kafka data-streaming functionality in your applications without having to install, configure, run, and maintain your own Kafka clusters.

//For more overview information about {product}, see [variablized link to overview here https://access.redhat.com/documentation/en-us/red_hat_openshift_streams_for_apache_kafka/].

.Prerequisites
ifndef::community[]
* You have a Red Hat account.
//* You have a subscription to {product-long}. For more information about signing up, see *<@SME: Where to link?>*.
endif::[]
* https://adoptopenjdk.net/[JDK^] 11 or later is installed.
* For Windows, the latest version of https://www.oracle.com/java/technologies/javase-downloads.html[Oracle JDK^] is installed.

// Condition out QS-only content so that it doesn't appear in docs.
// All QS anchor IDs must be in this alternate anchor ID format `[#anchor-id]` because the ascii splitter relies on the other format `[id="anchor-id"]` to generate module files.
ifdef::qs[]
[#description]
Learn how to create and set up your first Apache Kafka instance in {product-long}.

[#introduction]
Welcome to the quick start for {product-long}. In this quick start, you'll learn how to create and inspect a Kafka instance, create a service account to connect an application or service to the instance, and create a topic in the instance.
endif::[]

[id="proc-creating-kafka-instance_{context}"]
== Creating a Kafka instance in {product}

Use the {product} web console to create and configure a Kafka instance for your applications or services. A Kafka instance in {product} includes a Kafka cluster, bootstrap server, and the configurations needed to connect to producer and consumer services.

ifndef::qs[]
.Prerequisites
* You're logged in to the {product} web console at {service-url}[^].
endif::[]

.Procedure
. In the {product} web console, go to *Streams for Apache Kafka* > *Kafka Instances* and click *Create Kafka instance*.
. Enter a unique *Name* for the Kafka instance, such as `my-first-kafka-instance`, and select the relevant *Cloud region* option. All other fields are preconfigured.
+
////
//For post preview, when more options are available.
. In the *Streams for Apache Kafka* page of the web console, click *Create Kafka instance* and define the following instance details. Some values currently have only one option.
* *Instance name*: Enter a unique name for the instance, such as `my-first-kafka-instance`.
* *Cloud provider*: Select `Amazon Web Services`.
* *Cloud region*: Select `US East, N. Virginia`.
* *Availability zones*: Select `Multi`.
////
. Click *Create instance* to start the creation process for your Kafka instance.
+
--
[.screencapture]
.Kafka instance configuration details
image::sak-configure-kafka-instance.png[Image of instance configuration details in Create Kafka instance window]

The new Kafka instance is listed in the instances table. Typically, you need to wait a few minutes for the instance creation process to finish.

When the instance *Status* is *Ready*, you can start using the Kafka instance. You can use the options icon (three vertical dots) to view instance details, connect to the instance, change the instance owner, or delete the instance.

[.screencapture]
.Kafka instance options menu
image::sak-kafka-instance-options.png[Image of Kafka instance options menu]

NOTE: Although you can see Kafka instances created by other users in your organization, you might not be able to manage or connect to those instances. Only the instance owner or users with permissions to access the instance can edit or delete the instance, access the associated service account and topics, or connect to the instance.
--

.Verification
ifdef::qs[]
* Is the new Kafka instance listed in the instances table?
* Is the state of the new Kafka instance shown as *Ready*?
endif::[]
ifndef::qs[]
. Verify that the new Kafka instance is listed in the instances table.
. Verify that the state of the new Kafka instance is shown as *Ready*.
endif::[]


////
// Commenting out the following for now, which belongs in an onboarding tour (Stetson, 4 March 2021)

When you're in the {Product_short} environment, you will see a left menu panel. This panel provides access to all resources related to the service, including the `Quick starts` and `Documentation`.

In the lower left of the screen you'll see a lightbulb icon. This icon gives access to the `Resource Center`. Here you can find the latest information about the service, like product updates, upcoming events, etc.

image::sak-crc-resource-center.png[Image of Resource Center in web console]

The center of the page shows you the list of Kafka instances that are currently running within your organisation. If this is your, or your organisations, first interaction with {Product_short}, this list will be empty.

image::sak-kafka-overview.png[Image of initial empty instances table]
////

[id="proc-creating-service-account_{context}"]
== Creating a service account to connect to a Kafka instance in {product}

To connect your applications or services to a Kafka instance in the {product} web console, you need to create a service account that's associated with the instance. You also need to save the bootstrap server endpoint for the instance, the generated service account credentials, and the authentication token endpoint to a secure location. You'll use the service account and Kafka instance information later when you configure your application.

.Prerequisites
* You've created a Kafka instance and the instance is in *Ready* state.

.Procedure
. In the *Kafka Instances* page of the web console, for the relevant Kafka instance that you want to connect to, select the options icon (three vertical dots) and click *Connection*.
. In the *Connection* page, copy the *Bootstrap server* endpoint to a secure location. This is the bootstrap server endpoint that you'll need for connecting to this Kafka instance.
. Click *Create service account* to set up the account that you'll use to access this Kafka instance.
. Enter a unique service account name, such as `my-service-account`, add an optional description, and click *Create*.
. Copy the generated *Client ID* and *Client Secret* to a secure location. These are the credentials that you'll use to connect to this Kafka instance.
+
IMPORTANT: The generated credentials are displayed only one time, so ensure that you've successfully and securely saved the copied credentials before closing the credentials window.

. After you save the generated credentials to a secure location, select the confirmation check box in the credentials window and close the window.
. For the *Authentication method*, copy the SASL/OAUTHBEARER *Token endpoint URL* to a secure location. This is the endpoint that you'll use with your service account credentials to authenticate the connection to this Kafka instance.
+
NOTE: SASL/PLAIN authentication is also available for tools and libraries that don't support SASL/OAUTHBEARER, but SASL/OAUTHBEARER is recommended whenever possible. With SASL/PLAIN authentication, you use only the service account credentials to authenticate the connection to the Kafka instance.

+
You'll use the service account information that you saved to configure your application to connect to your Kafka instances when you're ready. For example, if you plan to use https://github.com/edenhill/kafkacat[Kafkacat^] to interact with your Kafka instance, you'll use this information to set your bootstrap server and client environment variables.
. To review your service account information, reset your credentials, or delete the service account, use the left navigation menu to go to the *Service Accounts* page.

.Verification
ifdef::qs[]
* Did you save the bootstrap server, client credentials, and authentication token endpoint to a secure location?
* Did you verify that your service account was successfully created in the *Service Accounts* page?
endif::[]
ifndef::qs[]
. Verify that the bootstrap server, client credentials, and authentication token endpoint are saved to a secure location.
. Verify that your service account was successfully created in the *Service Accounts* page.
endif::[]

[id="proc-setting-service-account-permissions_{context}"]
== Setting permissions for a service account in a Kafka instance in {product}

After you create a service account to connect to a Kafka instance, you must also set the appropriate level of access for that new account in the Access Control List (ACL) of the Kafka instance. {product} uses ACLs provided by Kafka that enable you to manage how other user accounts and service accounts are permitted to interact with the Kafka resources that you create.

.Prerequisites
* You've created a Kafka instance and the instance is in *Ready* state.
* You've created a service account that you want to allow to access the running Kafka instance.

.Procedure
. In the *Kafka Instances* page of the web console, click the name of the Kafka instance that you want the service account to access.
. Click the *Access* tab to view the current ACL for this instance.
. Click *Manage access*, use the *Account* drop-down menu to select the service account that you previously created, and click *Next*.
. Under *Assign Permissions*, use the drop-down menus to set the permissions shown in the following table for this service account. Click *Add* to add each new resource permission.
+
--
These permissions enable applications associated with the service account to create and delete topics in the instance, to produce and consume messages in any topic in the instance, and to use any consumer group and any producer.

.Example ACL permissions for a new service account
[cols="25%,25%,25%,25%"]
|===
h|Resource type
h|Resource identifier and value
h|Access type
h|Operation

|`Topic`
|`Is` = `*`
|`Allow`
|`All`

|`Consumer group`
|`Is` = `*`
|`Allow`
|`Read`

|`Transactional ID`
|`Is` = `*`
|`Allow`
|`All`
|===
--
. After you add these permissions for the service account, click *Save* to finish.

.Verification
ifdef::qs[]
* Are the new permissions for the service account listed in the *Access* page of the Kafka instance?
endif::[]
ifndef::qs[]
* Verify that the new permissions for the service account are listed in the *Access* page of the Kafka instance.

[role="_additional-resources"]
.Additional resources
* link:https://kafka.apache.org/documentation/#security_authz[Authorization and ACLs^] in Kafka documentation
endif::[]

[id="proc-creating-kafka-topic_{context}"]
== Creating a Kafka topic in {product}

After you create a Kafka instance, you can create Kafka topics to start producing and consuming messages in your services.

.Prerequisites
* You've created a Kafka instance and the instance is in *Ready* state.

.Procedure
. In the *Kafka Instances* page of the web console, click the name of the Kafka instance that you want to add a topic to.
. Select the *Topics* tab, click *Create topic*, and follow the guided steps to define the topic details. Click *Next* to complete each step and click *Finish* to complete the setup.
+
--
[.screencapture]
.Guided steps to define topic details
image::sak-create-topic.png[Image of wizard to create a topic]

* *Topic name*: Enter a unique topic name, such as `my-first-kafka-topic`.
* *Partitions*: Set the number of partitions for this topic. This example sets the partition to `1` for a single partition. Partitions are distinct lists of messages within a topic and enable parts of a topic to be distributed over multiple brokers in the cluster. A topic can contain one or more partitions, enabling producer and consumer loads to be scaled.
* *Message retention*: Set the message retention time and size to the relevant value and increment. This example sets the retention time to `A week` and the retention size to `Unlimited`. Message retention time is the amount of time that messages are retained in a topic before they are deleted or compacted, depending on the cleanup policy. Retention size is the maximum total size of all log segments in a partition before they are deleted or compacted.
* *Replicas*: For this release of {product}, the replicas are preconfigured. The number of partition replicas for the topic is set to `3` and the minimum number of follower replicas that must be in sync with a partition leader is set to `2`. Replicas are copies of partitions in a topic. Partition replicas are distributed over multiple brokers in the cluster to ensure topic availability if a broker fails. When a follower replica is in sync with a partition leader, the follower replica can become the new partition leader if needed.

After you complete the topic setup, the new Kafka topic is listed in the topics table. You can now start producing and consuming messages to and from this topic using services that you connect to this instance.
--
. In the topics table, on the right side of the Kafka topic, use the options icon (three vertical dots) to edit or delete the topic as needed.
+
[.screencapture]
.Edit or delete Kafka topic
image::sak-edit-topic.png[Image of topic options to edit or delete]

.Verification
ifdef::qs[]
* Is the new Kafka topic listed in the topics table?
endif::[]
ifndef::qs[]
* Verify that the new Kafka topic is listed in the topics table.
endif::[]

[role="_additional-resources"]
== Additional resources
* https://kafka.apache.org/081/documentation.html#configuration[Configuration^] in Kafka
* {base-url}{rhoas-cli-kafka-url}[_Getting started with the `rhoas` CLI for {product-long}_^]
* {base-url-cli}{rhoas-cli-ref-url}[_CLI command reference (rhoas)_^]
* {base-url}{kafkacat-url}[_Configuring and connecting Kafkacat with {product-long}_^]
* {base-url}{kafka-bin-scripts-url}[_Configuring and connecting Kafka scripts with {product-long}_^]
* {base-url}{quarkus-url}[_Using Quarkus applications with Kafka instances in {product-long}_^]

ifdef::qs[]
[#conclusion]
Congratulations! You successfully completed the {product} Getting Started quick start, and are now ready to use the service.

You can use Kafka scripts to check that you can connect with your Kafka instance.
endif::[]

ifdef::parent-context[:context: {parent-context}]
ifndef::parent-context[:!context:]
