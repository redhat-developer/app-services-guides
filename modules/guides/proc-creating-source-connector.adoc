[id='proc-creating-source-connector_{context}']
= Creating a {connectors} instance for a data source
:imagesdir: ../_images

[role="_abstract"]
A _source_ connector consumes events from an external data source and produces Kafka messages.

You configure your {connectors} instance to listen for events from the data source and produce a Kafka message for each event. Your {connectors} instance sends the messages at regular intervals to the Kafka topic that you created for {connectors}.

For this example, you create an instance of the Data Generator source connector. The Data Generator is provided for development and testing purposes. You specify the text for a message and how often to send the message.

.Prerequisites

* If you want to use a dead letter queue (DLQ) to handle any messaging errors, create a Kafka topic for the DLQ.

ifndef::qs[]
* You're logged in to the {product-long-connectors} web console at {service-url-connectors}[^].
endif::[]

.Procedure
. In the {product-long-connectors} web console, click *Create a {connectors} instance*.
. Select the connector that you want to use for connecting to a data source.
+
You can browse through the catalog of available connectors. You can also search for a particular connector by name, and filter for sink or source connectors.
+
For example, to find the Data Generator source connector, type `data` in the search box. The list is filtered to show only the *Data Generator source* card.
+
Click the card to select the connector, and then click *Next*.

. On the *Kafka Instance* page, click the card for the {product-kafka} instance that you configured for {connectors}. For example, click the *test-connect* card.
+
Click *Next*.

. On the *Deployment* page, the namespace that you select depends on your {openshift} environment.
+
If you're using your own {openshift} environment, select the card for the namespace that was created when a cluster administrator added the {connectors} service to your cluster, as described in https://access.redhat.com/documentation/en-us/openshift_connectors/1/guide/15a79de0-8827-4bf1-b445-8e3b3eef7b01[Adding the Red Hat {openshift} {connectors} add-on to your {openshift} cluster^].
+
If you're using the hosted preview environment, click *Create preview namespace* to provision a namespace for hosting the {connectors} instances that you create.
+
Click *Next*.

. Specify the core configuration for your {connectors} instance:
.. Type a name for your {connectors} instance. For example, type `hello world generator`.
.. In the *Client ID* and *Client Secret* fields, type the credentials for the service account that you created for {connectors} and then click *Next*.
. Provide connector-specific configuration. For the Data Generator, provide the following information:
.. *Topic Name*: Type the name of the Kafka topic that you created for {connectors}. For example, type `test-topic`.
.. *Content Type*: Accept the default, `text/plain`.
.. *Message*: Type the content of the message that you want the {connectors} instance to send to the Kafka topic. For example, type `Hello World!!`.
.. *Period*: Specify the interval (in milliseconds) at which you want the {connectors} instance to send messages to the Kafka topic. For example, to send a message every 10 seconds, specify `10000`.
.. *Data Shape Produces Format*: Accept the default, `application/octet-stream`.
+
Click *Next*.

. Select one of the following error handling policies for your {connectors} instance:
+
* *Stop*: If a message fails to send, the {connectors} instance stops running and changes its status to the *Failed* state. You can view the error message.
* *Ignore*: If a message fails to send, the {connectors} instance ignores the error and continues to run. No error message is logged.
* *Dead letter queue*: If a message fails to send, the {connectors} instance sends error details to the Kafka topic that you created for the DLQ.
+
Click *Next*.

. Review the summary of the configuration properties and then click *Create {connectors} instance*.
+
Your {connectors} instance is listed on the *{connectors} Instances* page. After a couple of seconds, the status of your {connectors} instance changes to the *Ready* state and it starts producing messages and sending them to its associated Kafka topic.
+
From the *{connectors} Instances* page, you can stop, start, duplicate, and delete your {connectors} instance, as well as edit its configuration, by clicking the Options icon (three vertical dots).

.Verification
ifdef::qs[]
* Does your source {connectors} instance generate messages?
endif::[]
ifndef::qs[]
* Verify that your source {connectors} instance generates messages.
endif::[]

.. In the {product-long-rhoas} web console, select *Streams for Apache Kafka* > *Kafka Instances*.
.. Click the Kafka instance that you created for connectors. For example, click *test-connect*.
.. Click the *Topics* tab and then click the topic that you specified for your source {connectors} instance. For example, click *test-topic*.
.. Click the *Messages* tab to see a list of `Hello World!!` messages.

