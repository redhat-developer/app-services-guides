////
START GENERATED ATTRIBUTES
WARNING: This content is generated by running npm --prefix .build run generate:attributes
////

//All OpenShift Application Services
:org-name: Application Services
:product-long-rhoas: OpenShift Application Services
:community:
:imagesdir: ./images
:property-file-name: app-services.properties
:samples-git-repo: https://github.com/redhat-developer/app-services-guides
:base-url: https://github.com/redhat-developer/app-services-guides/tree/main/docs/
:sso-token-url: https://sso.redhat.com/auth/realms/redhat-external/protocol/openid-connect/token
:cloud-console-url: https://console.redhat.com/
:service-accounts-url: https://console.redhat.com/application-services/service-accounts

//to avoid typos
:openshift: OpenShift
:openshift-dedicated: OpenShift Dedicated

//OpenShift Application Services CLI
:base-url-cli: https://github.com/redhat-developer/app-services-cli/tree/main/docs/
:command-ref-url-cli: commands
:installation-guide-url-cli: rhoas/rhoas-cli-installation/README.adoc
:service-contexts-url-cli: rhoas/rhoas-service-contexts/README.adoc

//OpenShift Streams for Apache Kafka
:product-long-kafka: OpenShift Streams for Apache Kafka
:product-kafka: Streams for Apache Kafka
:product-version-kafka: 1
:service-url-kafka: https://console.redhat.com/application-services/streams/
:getting-started-url-kafka: kafka/getting-started-kafka/README.adoc
:kafka-bin-scripts-url-kafka: kafka/kafka-bin-scripts-kafka/README.adoc
:kafkacat-url-kafka: kafka/kcat-kafka/README.adoc
:quarkus-url-kafka: kafka/quarkus-kafka/README.adoc
:nodejs-url-kafka: kafka/nodejs-kafka/README.adoc
:getting-started-rhoas-cli-url-kafka: kafka/rhoas-cli-getting-started-kafka/README.adoc
:topic-config-url-kafka: kafka/topic-configuration-kafka/README.adoc
:consumer-config-url-kafka: kafka/consumer-configuration-kafka/README.adoc
:access-mgmt-url-kafka: kafka/access-mgmt-kafka/README.adoc
:metrics-monitoring-url-kafka: kafka/metrics-monitoring-kafka/README.adoc
:service-binding-url-kafka: kafka/service-binding-kafka/README.adoc
:message-browsing-url-kafka: kafka/message-browsing-kafka/README.adoc

//OpenShift Service Registry
:product-long-registry: OpenShift Service Registry
:product-registry: Service Registry
:registry: Service Registry
:product-version-registry: 1
:service-url-registry: https://console.redhat.com/application-services/service-registry/
:getting-started-url-registry: registry/getting-started-registry/README.adoc
:quarkus-url-registry: registry/quarkus-registry/README.adoc
:getting-started-rhoas-cli-url-registry: registry/rhoas-cli-getting-started-registry/README.adoc
:access-mgmt-url-registry: registry/access-mgmt-registry/README.adoc
:content-rules-registry: https://access.redhat.com/documentation/en-us/red_hat_openshift_service_registry/1/guide/9b0fdf14-f0d6-4d7f-8637-3ac9e2069817[Supported Service Registry content and rules]
:service-binding-url-registry: registry/service-binding-registry/README.adoc

//OpenShift Connectors
:connectors: Connectors
:product-long-connectors: OpenShift Connectors
:product-connectors: Connectors
:product-version-connectors: 1
:service-url-connectors: https://console.redhat.com/application-services/connectors
:getting-started-url-connectors: connectors/getting-started-connectors/README.adoc
:getting-started-rhoas-cli-url-connectors: connectors/rhoas-cli-getting-started-connectors/README.adoc

//OpenShift API Designer
:product-long-api-designer: OpenShift API Designer
:product-api-designer: API Designer
:product-version-api-designer: 1
:service-url-api-designer: https://console.redhat.com/application-services/api-designer/
:getting-started-url-api-designer: api-designer/getting-started-api-designer/README.adoc

//OpenShift API Management
:product-long-api-management: OpenShift API Management
:product-api-management: API Management
:product-version-api-management: 1
:service-url-api-management: https://console.redhat.com/application-services/api-management/

////
END GENERATED ATTRIBUTES
////

[id="chap-connecting-client-applications-rhoas-cli"]
= Connecting client applications to {product-long-rhoas} using the rhoas CLI
:context: connecting-client-applications-rhoas-cli

[role="_abstract"]
As a developer of applications and services, you might need to connect client applications to instances in cloud services such as {product-long-kafka} and {product-long-registry}.

For example, suppose you have the following applications running locally on your computer:

* One application that is designed to publish a stream of stock price updates
* A second application that is designed to consume the stock price updates and chart them on a dashboard

In addition, suppose you have the following instances in {product-long-rhoas}:

* A Kafka instance in {product-kafka}
* A {registry} instance in {product-registry}

Each time the first application produces a stock price update, you want to use the Kafka instance to forward the update as an event to the second, consuming application. In addition, you want each of the applications to use a schema in the {registry} instance to validate that messages conform to a particular format.

In this scenario, you need to connect your applications to your Kafka and {registry} instances. To achieve this, you can use the {product-long-rhoas} (`rhoas`) command-line interface (CLI) to create a _context_ for your service instances. You can then use another CLI command to generate the required connection information for each service instance in the context.

This guide describes how to use the `rhoas` CLI to create contexts and then generate the connection configuration information that client applications need to connect to service instances in those contexts.

//Additional line break to resolve mod docs generation error

[id="con-about-service-contexts_{context}"]
== About service contexts

In {product-long-rhoas}, a service context is a defined set of instances running in cloud services such as {product-long-kafka} and {product-long-registry}. You might create different contexts for specific use cases, projects, or environments.

To create a context, you can use the {product-long-rhoas} (`rhoas`) command-line interface (CLI). New service instances that you create are automatically added to the context that is currently in use. You can switch between different contexts and add or remove service instances as required. You can include the same service instance in multiple contexts.

When you have created a service context, you can use a single CLI command to generate the configuration information that client applications need to connect to the instances in that context. You can generate connection configuration information in various formats such as an environment variables file (.env), a JSON file, a Java properties file, and a Kubernetes ConfigMap.

[id="proc-creating-new-service-contexts_{context}"]
== Creating new service contexts

The following example shows how to use the CLI to create contexts in {product-long-rhoas} and then manage the service instances that are defined in those contexts.

.Prerequisites
* You have installed the {product-long-rhoas} (`rhoas`) CLI. For more information, see https://access.redhat.com/documentation/en-us/red_hat_openshift_application_services/1/guide/bb30ee92-9e0a-4fd6-a67f-aed8910d7da3#proc-installing-rhoas_installing-rhoas-cli[Installing the rhoas CLI^].

.Procedure

. Log in to the CLI.
+
[source,shell]
----
$ rhoas login
----
+
The login command opens a sign-in process in your web browser.

. Use the CLI to create a new service context.
+
[source,shell]
----
$ rhoas context create --name development-context
----
+
The new context becomes the _current_ (that is, active) context by default.

. Create a new Kafka instance in {product-long-kafka}.
+
[source,shell]
----
$ rhoas kafka create --name my-kafka-instance
----
+
The CLI automatically adds the Kafka instance to the current context.

. Create a new {registry} instance in {product-long-registry}.
+
[source,shell]
----
$ rhoas service-registry create --name my-registry-instance
----
+
The CLI also automatically adds the {registry} instance to the current context.

. Confirm that the Kafka and {registry} instances are in the current context and are running.
+
.Command to view status of service instances in current context
[source,shell]
----
$ rhoas context status
----
+
You see output that looks like the following example:
+
.Status of example context with single Kafka and {registry} instances
[source,shell,subs="+quotes",options="nowrap"]
----
Service Context Name:	development-context
Context File Location:	/home/_<user-name>_/.config/rhoas/contexts.json

Kafka
-----------------------------------------------------------------------------
ID:                cafkr2jma40lhulbl1c0
Name:              my-kafka-instance
Status:            ready
Bootstrap URL:     kafka-inst-cafkr-jma--lhulbl-ca.bf2.kafka.rhcloud.com:443

Service Registry
------------------------------------------------------------------------------
ID:                0aa1dd8b-63d5-466c-9de8-7c03320a81c2
Name:              my-registry-instance
Status:            ready
Registry URL:      https://bu98.serviceregistry.rhcloud.com/t/0aa1dd8b-63d5-466c-9de8-7c03320a81c2
----

. Create another service context.
+
[source,shell]
----
$ rhoas context create --name production-context
----
+
The new service context becomes the current context.

. Add the Kafka instance that you created earlier in the procedure to the new service context.
+
[source,shell]
----
$ rhoas context set-kafka --name my-kafka-instance
----
+
The Kafka instance is now part of both of the service contexts that you created.

[NOTE]
====
To remove a particular service from a context, use the `context unset` command with the `--services` flag and specify the service name, for example, `kafka` or `service-registry`. An example is shown.

[source,shell]
----
$ rhoas context unset --name development-context --services kafka
----
====

[role="_additional-resources"]
.Additional resources
* To learn more about the `context` commands that you can use to manage service contexts, see https://access.redhat.com/documentation/en-us/red_hat_openshift_application_services/1/guide/8bd088a6-b7b7-4e5d-832a-b0f0494f9070[CLI command reference (rhoas)^]

[id="proc-generating-connection-information-quarkus_{context}"]
== Generating connection configuration information for a local Quarkus application
The following example shows how to connect an example Quarkus application running locally on your computer to the service instances defined in a context in {product-long-rhoas}. https://quarkus.io/[Quarkus^] is a Kubernetes-native Java framework that is optimized for serverless, cloud, and Kubernetes environments.

The Quarkus application uses a topic in a Kafka instance to produce and consume a stream of quote values and display these on a web page. The application consists of two components:

* A producer component that periodically produces a new quote value and publishes this to a Kafka topic called `quotes`.
* A consumer component that streams quote values from the Kafka topic. This component also has a minimal front end that uses server-sent events to show the quote values on a web page.

In addition, the producer and consumer components serialize and deserialize Kafka messages using an Avro schema stored in {registry}. Use of the schema ensures that message values conform to a defined format.

.Prerequisites

ifndef::community[]
* You have a {org-name} account.
endif::[]
* You have a service context with a Kafka and {registry} instance.
* https://github.com/git-guides/[Git^] is installed.
* You have an IDE such as https://www.jetbrains.com/idea/download/[IntelliJ IDEA^], https://www.eclipse.org/downloads/[Eclipse^], or https://code.visualstudio.com/Download[Visual Studio Code^].
* https://adoptopenjdk.net/[OpenJDK^] 11 or later is installed on Linux or MacOS. (The latest LTS version of OpenJDK is recommended.)
* https://maven.apache.org/[Apache Maven^] 3.8.x or later is installed (for Quarkus 2.2.x).

.Procedure

. On the command line, clone the {product-long-rhoas} https://github.com/redhat-developer/app-services-guides[Guides and Samples^] repository from GitHub.
+
[source,shell]
----
$ git clone https://github.com/redhat-developer/app-services-guides app-services-guides
----

. In your IDE, open the `code-examples/quarkus-service-registry-quickstart` directory from the repository that you cloned.
+
You see that the sample Quarkus application has two components - a producer component and a consumer component. The producer component publishes a stream of quote values to a Kafka topic. The consumer component consumes these values and displays them on a web page.

. On the command line, create the `quotes` topic required by the Quarkus application.
+
[source,shell]
----
$ rhoas kafka topic create --name quotes
----

. Ensure that you are using the service context that includes your Kafka and {registry} instances, as shown in the following example:
+
[source,shell]
----
$ rhoas context use --name development-context
----

. In the guides and samples repository that you cloned, navigate to the directory for the Quarkus application.
+
[source,shell]
----
$ cd ~/app-services-guides/code-examples/quarkus-service-registry-quickstart/
----

. Create a service account for the Quarkus application to authenticate with the Kafka and {registry} instances in the context. Save the credentials in an environment variables file in the directory for the producer component.
+
[source,shell]
----
$ rhoas service-account create --type env --output-file ./producer/.env
----

. Generate an environment variables file that contains the connection configuration information required by the producer component.
+
[source,shell]
----
$ rhoas generate-config --type env --output-file ./producer/rhoas.env
----

. Append the contents of the connection configuration file to the service account environment variables file.
+
[source,shell]
----
$ cat ./producer/rhoas.env >> ./producer/.env
----

. Copy the updated `.env` file to the directory for the consumer component, as shown in the following Linux example:
+
[source,shell]
----
$ cp ./producer/.env ./consumer/.env
----
+
For a service context with single Kafka and {registry} instances, the `.env` file looks like the following example:
+
.Example environment variables file for connection configuration and credentials
[source,shell,subs="+attributes,+quotes"]
----
\\## Generated by rhoas cli
RHOAS_SERVICE_ACCOUNT_CLIENT_ID=_<client-id>_
RHOAS_SERVICE_ACCOUNT_CLIENT_SECRET=_<client-secret>_
RHOAS_SERVICE_ACCOUNT_OAUTH_TOKEN_URL={sso-token-url}
## Generated by rhoas cli
\\## Kafka Configuration
KAFKA_HOST=kafka-inst-cafkr-jma--lhulbl-ca.bf2.kafka.rhcloud.com:443
## Service Registry Configuration
SERVICE_REGISTRY_URL=https://bu98.serviceregistry.rhcloud.com/t/0aa1dd8b-63d5-466c-9de8-7c03320a81c2
SERVICE_REGISTRY_CORE_PATH=/apis/registry/v2
SERVICE_REGISTRY_COMPAT_PATH=/apis/ccompat/v6
----
+
As shown in the example, the file that you generate contains the endpoints for your service instances, and the credentials required to connect to those instances.

. Set Access Control List (ACL) permissions to enable the new service account to access resources in the Kafka instance.
+
.Example command for granting access to Kafka instance
[source,shell,subs="+quotes"]
----
$ rhoas kafka acl grant-access --producer --consumer --service-account _<client-id>_ --topic quotes --group all
----
+
The command you entered allows applications to use the service account to produce and consume messages in the `quotes` topic. Applications can use any consumer group.

. Use Role-Based Access Control (RBAC) to enable the new service account to access the {registry} instance and the artifacts (such as schemas) that it contains.
+
.Example command for granting access to {registry} instance
[source,shell,subs="+quotes"]
----
$ rhoas service-registry role add --role manager --service-account _<client-id>_
----

. In the guides and samples repository, navigate to the directory for the producer component. Use Apache Maven to run the producer component in developer mode.
+
[source,shell,options="nowrap"]
----
$ cd ~/app-services-guides/code-examples/quarkus-service-registry-quickstart/producer
$ mvn quarkus:dev
----
+
The producer component starts to generate quote values to the `quotes` topic in the Kafka instance.
+
The Quarkus application also created an Avro schema called `quotes-value` in the {registry} instance. The producer and consumer components use the schema to ensure that message values conform to a defined format.
+
To view the contents of the `quotes-value` schema, run the following command:
+
[source,shell]
----
$ rhoas service-registry artifact get --artifact-id quotes-value
----
+
You see output that looks like the following example:
+
.Example Avro schema in {registry}
[source,shell]
----
{
  "type": "record",
  "name": "Quote",
  "namespace": "org.acme.kafka.quarkus",
  "fields": [
    {
      "name": "id",
      "type": {
        "type": "string",
        "avro.java.string": "String"
      }
    },
    {
      "name": "price",
      "type": "int"
    }
  ]
}
----

. With the producer component still running, open a second command-line window or tab. In the guides and samples repository, navigate to the directory for the consumer component and run the component in developer mode.
+
[source,shell,options="nowrap"]
----
$ cd ~/app-services-guides/code-examples/quarkus-service-registry-quickstart/consumer
$ mvn quarkus:dev
----
+
The consumer component starts to consume the stream of quote values from the `quotes` topic.

. In a web browser, go to  http://localhost:8080/quotes.html[^].
+
You see that the consumer component displays the stream of quote values on the web page. This output shows that the Quarkus application used the connection configuration information that you generated to connect to the Kafka and {registry} instances in your service context.

[role="_additional-resources"]
.Additional resources
* https://access.redhat.com/documentation/en-us/red_hat_openshift_application_services/1/guide/8bd088a6-b7b7-4e5d-832a-b0f0494f9070#_b7f033ec-6f0c-4b3c-89b0-cb1801de19f9[CLI command reference (rhoas)^]
* https://access.redhat.com/documentation/en-us/red_hat_openshift_streams_for_apache_kafka/1/guide/2f4bf7cf-5de2-4254-8274-6bf71673f407[ Managing account access in {product-long-kafka}^]
* https://access.redhat.com/documentation/en-us/red_hat_openshift_service_registry/1/guide/7717db0b-9fad-4fff-91b7-b311b63290a4[Managing account access in {product-long-registry}^]

[id="proc-generating-connection-information-helm_{context}"]
== Generating connection configuration information for a Helm-based OpenShift application
The following example shows how to use Helm to deploy an example Quarkus application on Kubernetes and then connect the Quarkus application to a Kafka instance in {product-long-kafka}. https://helm.sh/[Helm^] is an open source utility for creating, configuring, and deploying applications on Kubernetes. The Kubernetes platform referred to in the remainder of this example is Red Hat OpenShift.

One part of the example Quarkus application is designed to generate random price values and produce these to a Kafka topic. Another part of the application consumes the numbers from the Kafka topic. The application uses server-sent events to expose the values as a REST UI. Finally, a web page in the application displays the exposed values.

To connect the Quarkus application to a Kafka instance in {product-kafka}, you define a service context that includes the Kafka instance. You then generate connection configuration information for the service context as an OpenShift ConfigMap object and provide this to the application.

.Prerequisites
* You have a running Kafka instance in {product-kafka}.
* You have created a service context for your Kafka instance.
* You have installed the latest version of the `rhoas` command-line interface (CLI). See {base-url}{installation-guide-url-cli}[Installing and configuring the rhoas CLI^].
* You have installed version 3.9.0 or greater of the https://helm.sh/docs/intro/install/[Helm CLI^].
* You have installed version 4.8.5 or greater of the https://docs.openshift.com/container-platform/4.11/cli_reference/openshift_cli/getting-started-cli.html[OpenShift CLI^].
* https://github.com/git-guides/[Git^] is installed.
* You have an IDE such as https://www.jetbrains.com/idea/download/[IntelliJ IDEA^], https://www.eclipse.org/downloads/[Eclipse^], or https://code.visualstudio.com/Download[Visual Studio Code^].


.Procedure
. On the command line, clone the {product-long-rhoas} {samples-git-repo}[Guides and Samples^] repository in GitHub.
+
[source,shell,options="nowrap"]
----
git clone https://github.com/redhat-developer/app-services-guides app-services-guides
----

. Log in to the rhoas CLI.
+
[source,shell]
----
$ rhoas login
----
+
The login command opens a sign-in process in your web browser.

. Check the service context that is currently in use.
+
[source,shell]
----
$ rhoas context list
----
+
The CLI shows a check mark next to the service context that is currently in use.

. (Optional) To switch to a different service context that includes your Kafka instance, use the following command. Replace `_<service-context>_` with your service context name.
+
[source,shell,subs="+quotes"]
----
$ rhoas context use --name _<service-context>_
----

. Generate connection configuration information for the service context as an OpenShift `ConfigMap` and save this in a YAML file, as shown in the following example:
+
.Generating ConfigMap from service context
[source,shell]
----
$ rhoas generate-config --type configmap --output-file ./rhoas-services.yaml
----
+
For a service context with a single Kafka instance, the contents of the `ConfigMap` file look like the following example:
+
.Example ConfigMap file generated from service context
[source,yaml,subs="+quotes"]
----
apiVersion: v1
kind: ConfigMap
metadata:
    name: _<service-context>_-configuration
data:
    ## Kafka Configuration
    kafka_host: __<host>__:__<port>__
----
+
As indicated in the example, the name of the generated `ConfigMap` object has a format of `_<service-context>_-configuration`.

. On the command line, create the `prices` topic required by the Quarkus application.
+
[source,shell]
----
$ rhoas kafka topic create --name prices
----

. Create a service account for the Quarkus application to authenticate with your Kafka instance by performing the following actions.
.. Create a new service account as an OpenShift secret and save this in a YAML file, as shown in the following example:
+
[source,shell]
----
$ rhoas service-account create --file-format secret --output-file ./rhoas-secrets.yaml
----
.. Open the YAML file for the secret in your IDE.
+
The contents of the file look like the following example:
+
.Example secret file for service account credentials
[source,yaml,subs="+quotes"]
----
apiVersion: v1
kind: Secret
metadata:
  name: service-account-credentials
type: Opaque
stringData:
  RHOAS_SERVICE_ACCOUNT_CLIENT_ID: _<client-id>_
  RHOAS_SERVICE_ACCOUNT_CLIENT_SECRET: _<client-secret>_
  RHOAS_SERVICE_ACCOUNT_OAUTH_TOKEN_URL: _<oauth-token-endpoint-uri>_
----
+
As indicated in the example, the generated secret has a default name of `service-account-credentials`.

.. Set Access Control List (ACL) permissions to enable the new service account to access resources in the Kafka instance.
+
.Example command for granting access to Kafka instance
[source,shell,subs="+quotes"]
----
$ rhoas kafka acl grant-access --producer --consumer --service-account _<client-id>_ --topic prices --group all
----
+
The command you entered allows applications to use the service account to produce and consume messages in the `prices` topic. Applications can use any consumer group.

. Log in to the OpenShift CLI using a token by performing the following actions.
.. Log in to the OpenShift web console as a user who has privileges to create a new project in the cluster.
.. In the upper-right corner of the console, click your user name and select *Copy login command*.
+
A new page opens.
.. Click the *Display Token* link.
.. In the *Log in with this token* section, copy the full `oc login` command shown.
.. On the command line, right-click and select *Paste*.
+
You see output confirming that you are logged in to your OpenShift cluster and the current project that you are using. By default, this is the project in which you will deploy the Quarkus application.
.. (Optional) To change to another, existing project, use the following command:
+
[source,shell,subs="+quotes"]
----
$ oc project _<project>_
----

.. (Optional) To create a _new_ project in which to deploy the Quarkus application, use the following command:
+
[source,shell,subs="+quotes"]
----
$ oc new-project _<project>_
----

. Use the OpenShift CLI to apply the `ConfigMap` and secret files to the current project in your OpenShift cluster.
+
.Applying ConfigMap and secret files to OpenShift project
[source,shell]
----
$ oc apply -f ./rhoas-services.yaml
$ oc apply -f ./rhoas-secrets.yaml
----
+
When you apply the YAML files, the OpenShift CLI shows the names of the `ConfigMap` and `Secret` objects that it creates in your OpenShift project, as shown in the following example output:
+
[source,shell]
----
configmap/my-service-context-configuration created
secret/service-account-credentials created
----

. In your IDE, open the `deployment.yaml` file in the `code-examples/helm-kafka-example/templates` directory of the repository that you cloned.
+
The `deployment.yaml` file is a template file that is part of the Helm chart for the example Quarkus application. The template defines environment variables for the connection information required to connect to your Kafka instance. The environment variables (`KAFKA_HOST`,`RHOAS_SERVICE_ACCOUNT_OAUTH_TOKEN_URL`, `RHOAS_SERVICE_ACCOUNT_CLIENT_ID`, and `RHOAS_SERVICE_ACCOUNT_CLIENT_SECRET`) are shown in the following sample from the template file:
+
.Example Helm template file for application deployment
[source,yaml]
----
spec:
  containers:
    - env:
        - name: KAFKA_HOST
          valueFrom:
            configMapKeyRef:
              name: {{ .Values.rhoas.config }}
              key: kafka_host
        - name: RHOAS_SERVICE_ACCOUNT_OAUTH_TOKEN_URL
          valueFrom:
            secretKeyRef:
              name:  {{ .Values.rhoas.secret }}
              key: RHOAS_SERVICE_ACCOUNT_OAUTH_TOKEN_URL
        - name: RHOAS_SERVICE_ACCOUNT_CLIENT_ID
          valueFrom:
            secretKeyRef:
              name:  {{ .Values.rhoas.secret }}
              key: RHOAS_SERVICE_ACCOUNT_CLIENT_ID
        - name: RHOAS_SERVICE_ACCOUNT_CLIENT_SECRET
          valueFrom:
            secretKeyRef:
              name:  {{ .Values.rhoas.secret }}
              key: RHOAS_SERVICE_ACCOUNT_CLIENT_SECRET
----
+
The template uses parameters called `rhoas.config` and `rhoas.secret` to reference the names of your `ConfigMap` and `Secret` objects. You specify the names of your `ConfigMap` and `Secret` objects as values for these parameters in a later step, when you install the Helm chart. Also, as you saw previously, the `ConfigMap` and `Secret` objects that you created contain parameters that correspond directly to the key values defined in the template.

. On the command line, navigate to the `code-examples/helm-kafka-example` directory of the repository that you cloned.
+
[source,shell]
----
$ cd app-services-guides/code-examples/helm-kafka-example
----

. Deploy the Helm chart, specifying the names of the `ConfigMap` and `Secret` objects that you created in your OpenShift project.
+
.Deploying the Helm chart
[source,shell,subs="+quotes",options="nowrap"]
----
$ helm install . --generate-name --set-string rhoas.config=_<configmap>_,rhoas.secret=service-account-credentials
----
+
You use the `--set-string` option to specify the names of the `ConfigMap` and `Secret` objects directly in the `helm install` command. You pass these values to the `rhoas.config` and `rhoas.secret` parameters that are defined in the template for the Helm chart.
+
NOTE: An alternative way to pass values from the `ConfigMap` and `Secret` objects to the Helm template is to create a YAML file that contains the names of the `ConfigMap` and `Secret` objects. This approach also works for Deployment-based OpenShift applications. For an example of doing this, see the https://github.com/redhat-developer/app-services-guides/blob/main/code-examples/helm-kafka-example/README.md[README file^] that accompanies the Quarkus application used in this example.
+
When you install the Helm chart, Helm automatically processes the contents of the chart `/templates` directory. Helm uses the templates to generate manifests for deployment of the application and creation of a service for the application. Helm provides these manifests to OpenShift.

. When the Helm chart is installed, get the service endpoint for the application on OpenShift.
+
[source,shell]
----
$ oc get service
----
+
You see output like the following example:
+
.Service information for running Quarkus application on OpenShift
[source,shell,options="nowrap"]
----
NAME                                TYPE           CLUSTER-IP       EXTERNAL-IP                                                               PORT(S)          AGE
rhoas-quarkus-kafka-quickstart      LoadBalancer   172.30.128.12    a81b115a35629488685b6ed3cf322fbf-1904626303.us-east-2.elb.amazonaws.com   8080:31110/TCP   11m
----
+
The output indicates that the Quarkus application is successfully running on your OpenShift cluster.

. On the command line, copy the value shown under *EXTERNAL-IP*.
. In a web browser, go to `_<external-ip-value>_:8080/prices.html`.
+
You see that the web page continuously updates the `Last price` value. The continuously updating output shows that the Quarkus application is using the connection configuration information that you generated to connect to the Kafka instance defined in your service context. The application uses the `prices` topic that you created to produce and consume messages.

[role="_additional-resources"]
.Additional resources
* https://access.redhat.com/documentation/en-us/red_hat_openshift_application_services/1/guide/8bd088a6-b7b7-4e5d-832a-b0f0494f9070#_b7f033ec-6f0c-4b3c-89b0-cb1801de19f9[CLI command reference (rhoas)^]
* https://access.redhat.com/documentation/en-us/red_hat_openshift_streams_for_apache_kafka/1/guide/2f4bf7cf-5de2-4254-8274-6bf71673f407[ Managing account access in {product-long-kafka}^]
