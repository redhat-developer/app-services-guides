////
START GENERATED ATTRIBUTES
WARNING: This content is generated by running npm --prefix .build run generate:attributes
////

//All OpenShift Application Services
:org-name: Application Services
:product-long-rhoas: OpenShift Application Services
:community:
:imagesdir: ./images
:property-file-name: app-services.properties
:samples-git-repo: https://github.com/redhat-developer/app-services-guides
:base-url: https://github.com/redhat-developer/app-services-guides/tree/main/docs/
:sso-token-url: https://sso.redhat.com/auth/realms/redhat-external/protocol/openid-connect/token

//OpenShift Application Services CLI
:base-url-cli: https://github.com/redhat-developer/app-services-cli/tree/main/docs/
:command-ref-url-cli: commands
:installation-guide-url-cli: rhoas/rhoas-cli-installation/README.adoc
:service-contexts-url-cli: rhoas/rhoas-service-contexts/README.adoc

//OpenShift Streams for Apache Kafka
:product-long-kafka: OpenShift Streams for Apache Kafka
:product-kafka: Streams for Apache Kafka
:product-version-kafka: 1
:service-url-kafka: https://console.redhat.com/application-services/streams/
:getting-started-url-kafka: kafka/getting-started-kafka/README.adoc
:kafka-bin-scripts-url-kafka: kafka/kafka-bin-scripts-kafka/README.adoc
:kafkacat-url-kafka: kafka/kcat-kafka/README.adoc
:quarkus-url-kafka: kafka/quarkus-kafka/README.adoc
:nodejs-url-kafka: kafka/nodejs-kafka/README.adoc
:getting-started-rhoas-cli-url-kafka: kafka/rhoas-cli-getting-started-kafka/README.adoc
:topic-config-url-kafka: kafka/topic-configuration-kafka/README.adoc
:consumer-config-url-kafka: kafka/consumer-configuration-kafka/README.adoc
:access-mgmt-url-kafka: kafka/access-mgmt-kafka/README.adoc
:metrics-monitoring-url-kafka: kafka/metrics-monitoring-kafka/README.adoc
:service-binding-url-kafka: kafka/service-binding-kafka/README.adoc
:message-browsing-url-kafka: kafka/message-browsing-kafka/README.adoc

//OpenShift Service Registry
:product-long-registry: OpenShift Service Registry
:product-registry: Service Registry
:registry: Service Registry
:product-version-registry: 1
:service-url-registry: https://console.redhat.com/application-services/service-registry/
:getting-started-url-registry: registry/getting-started-registry/README.adoc
:quarkus-url-registry: registry/quarkus-registry/README.adoc
:getting-started-rhoas-cli-url-registry: registry/rhoas-cli-getting-started-registry/README.adoc
:access-mgmt-url-registry: registry/access-mgmt-registry/README.adoc
:content-rules-registry: https://access.redhat.com/documentation/en-us/red_hat_openshift_service_registry/1/guide/9b0fdf14-f0d6-4d7f-8637-3ac9e2069817[Supported Service Registry content and rules]
:service-binding-url-registry: registry/service-binding-registry/README.adoc

//OpenShift Connectors
:product-long-connectors: OpenShift Connectors
:product-connectors: Connectors
:product-version-connectors: 1
:service-url-connectors: https://console.redhat.com/application-services/connectors
:getting-started-url-connectors: connectors/getting-started-connectors/README.adoc

//OpenShift API Designer
:product-long-api-designer: OpenShift API Designer
:product-api-designer: API Designer
:product-version-api-designer: 1
:service-url-api-designer: https://console.redhat.com/application-services/api-designer/
:getting-started-url-api-designer: api-designer/getting-started-api-designer/README.adoc

//OpenShift API Management
:product-long-api-management: OpenShift API Management
:product-api-management: API Management
:product-version-api-management: 1
:service-url-api-management: https://console.redhat.com/application-services/api-management/

////
END GENERATED ATTRIBUTES
////

[id="chap-produce-consume-rhoas-cli"]
= Getting started with producing and conuming messages in Rhoas Cli for {product-long-kafka}
ifdef::context[:parent-context: {context}]
:context: getting-started-produce-consume

// Purpose statement for the assembly
[role="_abstract"]
As a developer of applications and services, you can use the Rhoas Cli to create and read message in {product-long-kafka} and third-party systems.

In this example, you will produce messages to a kafka instance and consume them in the Rhoas Cli.

// Condition out QS-only content so that it doesn't appear in docs.
// All QS anchor IDs must be in this alternate anchor ID format `[#anchor-id]` because the ascii splitter relies on the other format `[id="anchor-id"]` to generate module files.
ifdef::qs[]
[#description]
====
Learn how to produce and consume message in {product-long-rhoas}.
====

[#introduction]
====
Welcome to the quick start for producing and consuming messages in the Rhoas Cli.

In this quick start, you will learn how to produce messages to a kafka instance and consume them in the Rhoas Cli.


====
endif::[]

ifndef::qs[]
== Overview

{product-long-kafka} is a cloud service that simplifies the process of running Apache Kafka. Apache Kafka is an open-source, distributed, publish-subscribe messaging system for creating fault-tolerant, real-time data feeds.

You can use {product-long-connectors} to configure communication between {product-kafka} instances and external services and applications. {product-long-connectors} allow you to configure how data moves from one endpoint to another without writing code.

The following diagram illustrates how data flows from a data source through a data source connector to a Kafka topic. And how data flows from a Kafka topic to a data sink through a data sink connector.

[.screencapture]
.{product-long-connectors} data flow
image::connectors-diagram.png[Illustration of data flow from data source through Kafka to data sink]

endif::[]

[id="proc-configure-kafka-instance_{context}"]
== Configuring the {product-kafka} instance

[role="_abstract"]
After you create a {product-kafka} instance, configure by performing the following tasks:

* Create *Kafka topics* to store messages sent by you and make them available to consumers.

For this example, you create one Kafka topic, named *test-topic* which will be used for all commands in the following examples.

ifdef::qs[]
.Prerequisites
* You've created a {product-kafka} instance and the instance is in the *Ready* state.
endif::[]

.Procedure
. Create a Kafka topic for your kafka instance:
.. In the OpenShift Application Services web console, select *Streams for Apache Kafka* > *Kafka Instances*.
.. Click the name of the {product-kafka} instance that you created.
.. Select the *Topics* tab, and then click *Create topic*.
.. Type a unique name for your topic. For example, type *test-topic* for *Topic Name*.
.. Accept the default settings for message retention, and replicas. But set the partition count to *2*.

ifdef::qs[]
.Verification
* Did you create a topic for the kafka instance?
endif::[]


[id="proc-produce-message_{context}"]
== Producing a message to a {product-kafka} instance

[role="_abstract"]
You can produce your own message from the Cli instead of using an application. This is very useful for testing and debuging your {product-kafka} instance. 

.Prerequisites
. You're logged in to the  OpenShift Application Services web console at {service-url-connectors}[^].
. You configured a {product-kafka} instance for connectors as described _Configuring the {product-kafka} instance for use with {product-long-connectors}_.
. You are logged into the Rhoas Cli with your OpenShift Application Services account using `rhoas login`.

.Procedure
. To produce a message to your kafka topic use the following command `rhoas kafka topic produce --name=test-topic` and enter a value when prompted, for example enter `Hello world!`.

. Read the message
.. In the OpenShift Application Services web console, select *Streams for Apache Kafka* > *Kafka Instances*.
.. Click the name of the {product-kafka} instance that you created.
.. Select the *Topics* tab, and then click the name of your topic.
.. Select the *Messages* tab, and see the message you create from the Rhoas Cli

. By default any message you create is sent to the *0* partition. To create a message for the *1* partition run the following and enter another value `rhoas kafka topic produce --name=test-topic --partition=0`.

. Go back to the messages tab in the topic and see if your message is now on a different partition.

.Verification
* Does running the commands produce messages?

.. In the OpenShift Application Services web console, select *Streams for Apache Kafka* > *Kafka Instances*.
.. Click the Kafka instance that you created.
.. Click the *Topics* tab and then click the topic that you specified for your {product-kafka} instance.
.. Click the *Messages* tab to see a `Hello World!` message.


[id="proc-consume-message_{context}"]
== Consuming messages from a {product-kafka} instance
[role="_abstract"]
You can consume your own message from the Cli instead of using an application. This is very useful for testing and debuging your {product-kafka} instance. 

.Prerequisites
. You're logged in to the  OpenShift Application Services web console at {service-url-connectors}[^].
. You configured a {product-kafka} instance for connectors as described _Configuring the {product-kafka} instance for use with {product-long-connectors}_.
. You are logged into the Rhoas Cli with your OpenShift Application Services account using `rhoas login`.

.Procedure
. To consume a message to your kafka topic use the following command `rhoas kafka topic consume --name=test-topic`. You will now see all messages you produced to the topic.
. Just like produce set the `--partition` flag to consume from a specific partition. Run `rhoas kafka topic consume --name=test-topic --partition=1`. You will now see all messages you produced to the topic on the *1* partition.

.Verification
* Does running the commands output messages on the correct partitions?

ifdef::qs[]
[#conclusion]
====
Congratulations! You successfully completed producing and conuming messages in Rhoas Cli for {product-long-kafka} quick start.
====
endif::[]

ifdef::parent-context[:context: {parent-context}]
ifndef::parent-context[:!context:]
