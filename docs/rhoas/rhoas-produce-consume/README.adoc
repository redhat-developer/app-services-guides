////
START GENERATED ATTRIBUTES
WARNING: This content is generated by running npm --prefix .build run generate:attributes
////

//All OpenShift Application Services
:org-name: Application Services
:product-long-rhoas: OpenShift Application Services
:community:
:imagesdir: ./images
:property-file-name: app-services.properties
:samples-git-repo: https://github.com/redhat-developer/app-services-guides
:base-url: https://github.com/redhat-developer/app-services-guides/tree/main/docs/
:sso-token-url: https://sso.redhat.com/auth/realms/redhat-external/protocol/openid-connect/token
:cloud-console-url: https://console.redhat.com/
:service-accounts-url: https://console.redhat.com/application-services/service-accounts

//to avoid typos
:openshift: OpenShift
:openshift-dedicated: OpenShift Dedicated

//OpenShift Application Services CLI
:base-url-cli: https://github.com/redhat-developer/app-services-cli/tree/main/docs/
:command-ref-url-cli: commands
:installation-guide-url-cli: rhoas/rhoas-cli-installation/README.adoc
:service-contexts-url-cli: rhoas/rhoas-service-contexts/README.adoc

//OpenShift Streams for Apache Kafka
:product-long-kafka: OpenShift Streams for Apache Kafka
:product-kafka: Streams for Apache Kafka
:product-version-kafka: 1
:service-url-kafka: https://console.redhat.com/application-services/streams/
:getting-started-url-kafka: kafka/getting-started-kafka/README.adoc
:kafka-bin-scripts-url-kafka: kafka/kafka-bin-scripts-kafka/README.adoc
:kafkacat-url-kafka: kafka/kcat-kafka/README.adoc
:quarkus-url-kafka: kafka/quarkus-kafka/README.adoc
:nodejs-url-kafka: kafka/nodejs-kafka/README.adoc
:getting-started-rhoas-cli-url-kafka: kafka/rhoas-cli-getting-started-kafka/README.adoc
:topic-config-url-kafka: kafka/topic-configuration-kafka/README.adoc
:consumer-config-url-kafka: kafka/consumer-configuration-kafka/README.adoc
:access-mgmt-url-kafka: kafka/access-mgmt-kafka/README.adoc
:metrics-monitoring-url-kafka: kafka/metrics-monitoring-kafka/README.adoc
:service-binding-url-kafka: kafka/service-binding-kafka/README.adoc
:message-browsing-url-kafka: kafka/message-browsing-kafka/README.adoc

//OpenShift Service Registry
:product-long-registry: OpenShift Service Registry
:product-registry: Service Registry
:registry: Service Registry
:product-version-registry: 1
:service-url-registry: https://console.redhat.com/application-services/service-registry/
:getting-started-url-registry: registry/getting-started-registry/README.adoc
:quarkus-url-registry: registry/quarkus-registry/README.adoc
:getting-started-rhoas-cli-url-registry: registry/rhoas-cli-getting-started-registry/README.adoc
:access-mgmt-url-registry: registry/access-mgmt-registry/README.adoc
:content-rules-registry: https://access.redhat.com/documentation/en-us/red_hat_openshift_service_registry/1/guide/9b0fdf14-f0d6-4d7f-8637-3ac9e2069817[Supported Service Registry content and rules]
:service-binding-url-registry: registry/service-binding-registry/README.adoc

//OpenShift Connectors
:connectors: Connectors
:product-long-connectors: OpenShift Connectors
:product-connectors: Connectors
:product-version-connectors: 1
:service-url-connectors: https://console.redhat.com/application-services/connectors
:getting-started-url-connectors: connectors/getting-started-connectors/README.adoc
:getting-started-rhoas-cli-url-connectors: connectors/rhoas-cli-getting-started-connectors/README.adoc

//OpenShift API Designer
:product-long-api-designer: OpenShift API Designer
:product-api-designer: API Designer
:product-version-api-designer: 1
:service-url-api-designer: https://console.redhat.com/application-services/api-designer/
:getting-started-url-api-designer: api-designer/getting-started-api-designer/README.adoc

//OpenShift API Management
:product-long-api-management: OpenShift API Management
:product-api-management: API Management
:product-version-api-management: 1
:service-url-api-management: https://console.redhat.com/application-services/api-management/

////
END GENERATED ATTRIBUTES
////

[id="chap-producing-consuming-rhoas-cli"]
= Producing and consuming messages using the rhoas CLI
ifdef::context[:parent-context: {context}]
:context: produce-consume-rhoas-cli

// Purpose statement for the assembly
[role="_abstract"]
As a developer of applications and services, you can use the `rhoas` command-line interface (CLI) to produce and consume messages for Kafka instances in {product-long-kafka}. This is a useful way to test and debug your Kafka instances.

.Prerequisites
ifndef::community[]
* You have a Red Hat account.
endif::[]
* You have a running Kafka instance in {product-kafka}.
* You've installed the latest version of the `rhoas` CLI. See {base-url}{installation-guide-url-cli}[Installing and configuring the rhoas CLI^].

// Condition out QS-only content so that it doesn't appear in docs.
// All QS anchor IDs must be in this alternate anchor ID format `[#anchor-id]` because the ascii splitter relies on the other format `[id="anchor-id"]` to generate module files.
ifdef::qs[]
[#description]
====
Learn how to use the `rhoas` command-line interface (CLI) to produce and consume messages for a Kafka instance.
====

[#introduction]
====
Welcome to the quick start for producing and consuming Kafka messages using the `rhoas` command-line interface (CLI).

In this quick start, you'll use a CLI command to produce messages to different topic partitions in a Kafka instance. You'll then use the {product-long-kafka} web console to inspect the messages. When you're ready, you'll use another CLI command to consume the messages.
====
endif::[]

[id="proc-creating-kafka-topic-for-cli-production-consumption_{context}"]
== Creating a Kafka topic in {product-kafka}

[role="_abstract"]
In this task, you'll create a new topic in your Kafka instance. You'll use this topic in later tasks to produce and consume messages.

.Prerequisites
* You've created a Kafka instance in {product-long-kafka} and the instance is in the *Ready* state.

.Procedure
. On the {service-url-kafka}[Kafka Instances^] page of the {product-kafka} web console, click the Kafka instance that you want to add a topic to.
. Select the *Topics* tab.
. Click *Create topic* and follow the guided steps to define the topic details.
+
You must specify the following topic properties:

* *Topic name*: For this quick start, enter `test-topic` as the topic name.
* *Partitions*: Set the number of partitions for the topic. For this quick start, set the value to `2`.
* *Message retention*: Set the message retention time and size. For this quick start, set the retention time to `A week` and the retention size to `Unlimited`.
* *Replicas*: For this release of {product-kafka}, replica values are preconfigured. The number of partition replicas and the minimum number of follower replicas that must be in sync with a partition leader are both set to `1`.
+
After you complete the setup, the new topic appears on the *Topics* page.

.Verification
ifdef::qs[]
* Does `test-topic` appear on the *Topics* page?
endif::[]
ifndef::qs[]
* Verify that `test-topic` appears on the *Topics* page.
endif::[]

[id="proc-producing-messages_{context}"]
== Producing messages to your Kafka instance

[role="_abstract"]
When you have a Kafka instance with a topic, you're ready to use the CLI to produce messages. In this task, you'll produce four messages to your Kafka instance.

.Prerequisites
* You've created `test-topic` on your Kafka instance.

.Procedure
. Log in to the `rhoas` CLI.
+
[source]
----
$ rhoas login
----

. Specify the Kafka instance that you want to produce messages to.
+
[source,subs="+quotes"]
----
$ rhoas kafka use --name=_<my-kafka-instance>_
----

. Produce your first message to `test-topic`.
+
[source]
----
rhoas kafka topic produce --name=test-topic
----
+
You're prompted to enter a message value.

. Enter `First message` as the message value.

. Repeat the previous steps to produce your second and third messages to `test-topic`. Enter `Second message` and `Third message` as the message values.

. Produce your fourth and final message to `test-topic`. This time, specify a partition value of `1` and a custom message key. An example is shown below.
+
[source]
----
rhoas kafka topic produce --name=test-topic --partition=1 --key="{'location': 'us-east-1'}"
----

. Enter `Fourth message` as the value of the final message.

. To view the messages in the {product-long-kafka} {service-url-kafka}[web console^], perform the following actions:
.. On the *Kafka Instances* page, click the name of your Kafka instance.
.. Select the *Topics* tab, and then click `test-topic`.
.. Select the *Messages* tab.
+
The messages table shows the messages you produced.
.. Observe the following details about the messages you produced:
+
* Because you didn't specify a partition value when producing the first three messages, these messages all went to partition `0` by default.
* The three messages on partition `0` have offset values of `0`, `1`, and `2`.
* The final message is on partition `1` and has the custom key value that you specified.

.Verification
ifdef::qs[]
* Does the messages table show the four messages that you produced?
endif::[]
ifndef::qs[]
* Verify that the messages table shows the four messages you produced.
endif::[]

[id="proc-consuming-messages_{context}"]
== Consuming messages from your Kafka instance
[role="_abstract"]
When you've produced messages to your Kafka instance and verified them using the {product-long-kafka} web console, you're ready to consume the messages. In this task, you'll use the CLI to consume the messages.

.Prerequisites
* You've produced messages to `test-topic` in your Kafka instance.
* You're logged in to the `rhoas` CLI.

.Procedure
. Specify the Kafka instance that you want to consume messages from.
+
[source,subs="+quotes"]
----
$ rhoas kafka use --name=_<my-kafka-instance>_
----

. Consume the messages on partition `0` of `test-topic`.
+
[source]
----
rhoas kafka topic consume --name=test-topic --partition=0
----
+
The CLI displays the messages. Observe that because you didn't specify an offset value, the CLI displays *all* of the messages on partition `0`.

. Consume the third message that you produced by specifying the appropriate partition and offset values.
+
[source]
----
rhoas kafka topic consume --name=test-topic --partition=0 --offset=2
----

. Consume the fourth message, which you produced to partition `1` of the topic.
+
[source]
----
rhoas kafka topic consume --name=test-topic --partition=1
----

ifdef::qs[]
.Verification
* When you entered the `kafka topic consume` command, did you see the expected messages?
endif::[]

ifdef::qs[]
[#conclusion]
====
Congratulations! You successfully completed the quick start for producing and consuming messages using the `rhoas` CLI.
====
endif::[]

ifdef::parent-context[:context: {parent-context}]
ifndef::parent-context[:!context:]
