////
START GENERATED ATTRIBUTES
WARNING: This content is generated by running npm --prefix .build run generate:attributes
////

//All OpenShift Application Services
:org-name: Application Services
:product-long-rhoas: OpenShift Application Services
:community:
:imagesdir: ./images
:property-file-name: app-services.properties
:samples-git-repo: https://github.com/redhat-developer/app-services-guides
:base-url: https://github.com/redhat-developer/app-services-guides/tree/main/docs/
:sso-token-url: https://sso.redhat.com/auth/realms/redhat-external/protocol/openid-connect/token
:cloud-console-url: https://console.redhat.com/
:service-accounts-url: https://console.redhat.com/application-services/service-accounts

//OpenShift
:openshift: OpenShift
:osd-name-short: OpenShift Dedicated

//OpenShift Application Services CLI
:base-url-cli: https://github.com/redhat-developer/app-services-cli/tree/main/docs/
:command-ref-url-cli: commands
:installation-guide-url-cli: rhoas/rhoas-cli-installation/README.adoc
:service-contexts-url-cli: rhoas/rhoas-service-contexts/README.adoc

//OpenShift Streams for Apache Kafka
:product-long-kafka: OpenShift Streams for Apache Kafka
:product-kafka: Streams for Apache Kafka
:product-version-kafka: 1
:service-url-kafka: https://console.redhat.com/application-services/streams/
:getting-started-url-kafka: kafka/getting-started-kafka/README.adoc
:kafka-bin-scripts-url-kafka: kafka/kafka-bin-scripts-kafka/README.adoc
:kafkacat-url-kafka: kafka/kcat-kafka/README.adoc
:quarkus-url-kafka: kafka/quarkus-kafka/README.adoc
:nodejs-url-kafka: kafka/nodejs-kafka/README.adoc
:getting-started-rhoas-cli-url-kafka: kafka/rhoas-cli-getting-started-kafka/README.adoc
:topic-config-url-kafka: kafka/topic-configuration-kafka/README.adoc
:consumer-config-url-kafka: kafka/consumer-configuration-kafka/README.adoc
:access-mgmt-url-kafka: kafka/access-mgmt-kafka/README.adoc
:metrics-monitoring-url-kafka: kafka/metrics-monitoring-kafka/README.adoc
:service-binding-url-kafka: kafka/service-binding-kafka/README.adoc
:message-browsing-url-kafka: kafka/message-browsing-kafka/README.adoc

//OpenShift Service Registry
:product-long-registry: OpenShift Service Registry
:product-registry: Service Registry
:registry: Service Registry
:product-version-registry: 1
:service-url-registry: https://console.redhat.com/application-services/service-registry/
:getting-started-url-registry: registry/getting-started-registry/README.adoc
:quarkus-url-registry: registry/quarkus-registry/README.adoc
:getting-started-rhoas-cli-url-registry: registry/rhoas-cli-getting-started-registry/README.adoc
:access-mgmt-url-registry: registry/access-mgmt-registry/README.adoc
:content-rules-registry: https://access.redhat.com/documentation/en-us/red_hat_openshift_service_registry/1/guide/9b0fdf14-f0d6-4d7f-8637-3ac9e2069817[Supported Service Registry content and rules]
:service-binding-url-registry: registry/service-binding-registry/README.adoc

//OpenShift Connectors
:connectors: Connectors
:product-long-connectors: OpenShift Connectors
:product-connectors: Connectors
:product-version-connectors: 1
:service-url-connectors: https://console.redhat.com/application-services/connectors
:getting-started-url-connectors: connectors/getting-started-connectors/README.adoc
:getting-started-rhoas-cli-url-connectors: connectors/rhoas-cli-getting-started-connectors/README.adoc

//OpenShift API Designer
:product-long-api-designer: OpenShift API Designer
:product-api-designer: API Designer
:product-version-api-designer: 1
:service-url-api-designer: https://console.redhat.com/application-services/api-designer/
:getting-started-url-api-designer: api-designer/getting-started-api-designer/README.adoc

//OpenShift API Management
:product-long-api-management: OpenShift API Management
:product-api-management: API Management
:product-version-api-management: 1
:service-url-api-management: https://console.redhat.com/application-services/api-management/

////
END GENERATED ATTRIBUTES
////

[id="chap-binding-openshift-applications"]
= Binding OpenShift applications to {product-long-kafka} and {product-long-registry}
:context: service-binding

[role="_abstract"]
As a developer of applications and services, you can connect applications on a Kubernetes platform such as Red Hat OpenShift to cloud services such as {product-long-kafka} and {product-long-registry}.

For example, suppose you have the following applications deployed on OpenShift:

* One application that publishes price updates for a variety of stocks
* A second application that consumes the price updates for publication on a web page

In addition, suppose you have a Kafka instance in {product-kafka}. Each time the first application produces a price update, you want to use the Kafka instance to forward the update as an event to the second, consuming application.
To achieve this behavior, you need a way to connect the applications on OpenShift to your Kafka instance in {product-kafka}.

In cases such as this, you can use a specialized Operator called the Service Binding Operator. The Service Binding Operator automatically provides an application on Kubernetes with the parameters required to connect to a Kafka instance in {product-kafka}. This process is called __service binding__.

You can also use the Service Binding Operator to connect the application to a {registry} instance. {registry} instances store value and key schemas (as well as APIs). When you use a schema with your Kafka instance, the schema ensures that messages conform to a specified format.

This guide describes how to perform service binding for {product-kafka} and {registry}. The Kubernetes platform referred to in the remainder of this guide is Red Hat OpenShift.


[id="con-about-service-binding_{context}"]
== About service binding

You can use a specialized Operator called the Service Binding Operator to automatically provide an application on OpenShift with the parameters required to connect to a specified Kafka instance in {product-kafka}. If you're using a schema with your Kafka instance, you can also use the Service Binding Operator to provide the application with connection parameters for a {registry} instance. Using the Service Binding Operator to automatically generate connection parameters for these cloud services is called __service binding__.

To perform service binding, you must also install the Red Hat OpenShift Application Services (RHOAS) Operator.
The RHOAS Operator exposes a Kafka or {registry} instance to an OpenShift cluster. The Service Binding Operator then collects and shares the information required for an application running on the OpenShift cluster to connect to the Kafka or {registry} instance.

When the RHOAS Operator and Service Binding Operator are installed, you can use the RHOAS CLI or OpenShift web console to perform service binding. When connection between your application and Kafka or {registry} instance is established, you can then work directly with the instance using standard OpenShift features and APIs.

As part of the service binding process, the Service Binding Operator injects connection parameters for the Kafka or {registry} instance into the pod for your application, as files.

When you bind to a Kafka instance in {product-kafka}, the Service Binding Operator creates the following directory and file structure in the application pod:

.Files injected by the Service Binding Operator for a Kakfa instance
[source, subs="+quotes"]
----
/bindings/__<kafka-instance-name>__
├── bootstrapServers
├── password
├── provider
├── saslMechanism
├── securityProtocol
├── type
└── user
----

Each file that the Service Binding Operator injects into the application pod contains a single connection parameter, specified in plain text. The connection parameters that correspond to the injected files are described below.

bootstrapServers:: Bootstrap server endpoint for the Kafka instance.
password:: Password for connection to the Kafka instance.
provider:: Cloud provider for the Kafka instance.
saslMechanism:: Simple Authentication and Security Layer (SASL) mechanism used by the Kafka instance for client authentication.
securityProtocol:: Protocol used by the Kafka instance to secure client connections.
type:: Metadata that identifies the Red Hat OpenShift Application Services (RHOAS) service. For a Kafka instance in {product-kafka}, this is set to a value of `kafka`.
user:: User name for connection to the Kafka instance.

When you bind to a {registry} instance, the Service Binding Operator creates the following directory and file structure in the application pod:

.Files injected by the Service Binding Operator for a {registry} instance
[source, subs="+quotes"]
----
/bindings/__<registry-instance-name>__
├── clientId
├── clientSecret
├── oauthRealm
├── oauthTokenUrl
├── registry
└── type
----

Each file that the Service Binding Operator injects into the application pod contains a single connection parameter, specified in plain text. The connection parameters that correspond to the injected files are described below. Some of these parameters are required by the OAuth (Open Authorization) protocol, which is used to secure connections to {registry} instances.

clientId:: Client ID used by OAuth to connect to the {registry} instance.
clientSecret:: Name of the secret that contains the password used by OAuth to connect to the {registry} instance.
oauthRealm:: Authentication realm used by OAuth to connect to the {registry} instance.
oauthTokenUrl:: Endpoint for the access token used by OAuth to connect to the {registry} instance.
registry:: Endpoint for the {registry} instance.
type:: Metadata that identifies the Red Hat OpenShift Application Services (RHOAS) service. For a {registry} instance, this is set to a value of `service-registry`.

[id="proc-installing-service-binding-operator_{context}"]
== Installing the Service Binding Operator on OpenShift

[role="_abstract"]
Before you can bind Kafka or {registry} instances to applications on OpenShift, you need to install the Service Binding Operator on your OpenShift cluster. The following procedure shows how to use the OperatorHub interface in the OpenShift web console to install the Service Binding Operator.

.Prerequisites
* You can access your OpenShift cluster with the `dedicated-admin` role (OpenShift Dedicated) or `cluster-admin` role. Only these roles have privileges to install an Operator on a cluster.

.Procedure
. Log in to the OpenShift web console with the `dedicated-admin` role (OpenShift Dedicated) or `cluster-admin` role.
. Click the perspective switcher in the upper-left corner. Switch to the *Administrator* perspective.
. In the left menu, click *Operators* > *OperatorHub*.
. In the *Filter by keyword* field, enter `Service Binding`.
. In the filtered results, click *Service Binding Operator*.
+
An information sidebar for the Service Binding Operator opens.
. In the sidebar, review the information about the Service Binding Operator and click *Install*.
. On the *Install Operator* page, perform the following actions:
.. For the *Update channel* option, ensure that `stable` is selected.
.. For the *Installation mode* option, ensure that `All namespaces on the cluster` is selected.
.. For the *Installed Namespace* and *Update approval* options, keep the default values.
.. Click *Install*.
. When the installation process is finished, click *View Operator* to see the Operator details.
+
The *Operator details* page for the Service Binding Operator opens in the *Installed Operators* section of the web console.
+
On the **Operator details** page, the **Status** field shows a value of `Succeeded`.
+
Also, you can observe that the Service Binding Operator is installed in the `openshift-operators` namespace.

[id="proc-installing-rhoas-operator_{context}"]
== Installing the RHOAS Operator on OpenShift

[role="_abstract"]
Before you can bind Kafka or {registry} instances to applications on OpenShift, you need to install the Red Hat OpenShift Application Services (RHOAS) Operator on your OpenShift cluster. The following procedure shows how to use the OperatorHub interface in the OpenShift web console to install the RHOAS Operator.

.Prerequisites
* You can access your OpenShift cluster with the `dedicated-admin` role (OpenShift Dedicated) or `cluster-admin` role. Only these roles have privileges to install an Operator on a cluster.

.Procedure
. Log in to the OpenShift web console with the `dedicated-admin` role (OpenShift Dedicated) or `cluster-admin` role.
. Click the perspective switcher in the upper-left corner. Switch to the *Administrator* perspective.
. In the left menu, click *Operators* > *OperatorHub*.
. In the *Filter by keyword* field, enter `RHOAS`.
. In the filtered results, select the *OpenShift Application Services (RHOAS)* Operator.
. If you see a dialog box entitled *Show community Operator*, review the included information. When you've finished, click *Continue*.
+
An information sidebar for the RHOAS Operator opens.

. In the sidebar, review the information about the RHOAS Operator and click *Install*.
. On the *Install Operator* page, perform the following actions:
.. For the *Installation mode* option, ensure that `All namespaces on the cluster` is selected.
.. For the *Update channel*, *Installed Namespace*, and *Update approval* options, keep the default values.
.. Click *Install*.
. When the installation process is finished, click *View Operator* to see the Operator details.
+
The *Operator details* page for the RHOAS Operator opens in the *Installed Operators* section of the web console.
+
On the **Operator details** page, the **Status** field shows a value of `Succeeded`.
+
Also, you can observe that the RHOAS Operator is installed in the `openshift-operators` namespace.

[id="proc-verifying-connection-to-openshift-cluster_{context}"]
== Verifying connection to your OpenShift cluster

[role="_abstract"]
After you install the RHOAS Operator, you can verify that the Operator is working by using the RHOAS CLI to connect to your OpenShift cluster and retrieve the cluster status. The following example shows how to verify connection to your OpenShift cluster.

.Prerequisites
* The RHOAS Operator is installed on your OpenShift cluster. See {base-url}{service-binding-url-registry}#proc-installing-rhoas-operator_{context}[Installing the RHOAS Operator on OpenShift].
* You can access your OpenShift cluster with privileges to create a new project.
* You've installed the OpenShift CLI. For more information, see link:https://docs.openshift.com/container-platform/4.8/cli_reference/openshift_cli/getting-started-cli.html#installing-openshift-cli[Installing the OpenShift CLI^].
* You've installed the latest version of the RHOAS CLI. For more information, see {base-url}{installation-guide-url-cli}[Installing the RHOAS CLI^].

.Procedure
. On your computer, open a command-line window.
. Log in to the OpenShift CLI using a token.
.. Log in to the OpenShift web console as a user who has privileges to create a new project in the cluster.
.. In the upper-right corner of the console, next to your user name, click the drop-down menu. Select *Copy login command*.
+
A new page opens.
.. Click the *Display Token* link.
.. In the section entitled *Log in with this token*, copy the full `oc login` command shown.
.. On the command line, paste the login command you copied. Right-click on the command line and select *Paste*.
+
You see output confirming that you're logged in to your OpenShift cluster and the current project that you're using.

. On the command line, create a new project, as shown in the following example.
+
.Creating a new OpenShift project
[source, subs="+quotes"]
----
$ oc new-project my-project
----

. Log in to the RHOAS CLI.
+
.Logging in to the RHOAS CLI
[source]
----
$ rhoas login
----
+
The login command opens a sign-in process in your web browser.

. On the command line, use the RHOAS CLI to connect to your OpenShift cluster and retrieve the cluster status.
+
.Using the RHOAS CLI to retrieve the status of your OpenShift cluster
[source]
----
$ rhoas cluster status
RHOAS Operator: Installed
Service Binding Operator: Installed
----
+
As shown in the output, the RHOAS CLI indicates that the RHOAS Operator and Service Binding Operator were successfully installed.

[id="proc-connecting-kafka-registry-instance-to-openshift-cluster_{context}"]
== Connecting a Kafka and {registry} instance to your OpenShift cluster

[role="_abstract"]
When you've verified connection to your OpenShift cluster, you can connect Kafka and {registry} instances to the current project in the cluster. You must establish these connections before you can bind applications running in the project to the Kafka and {registry} instances.

The following procedure shows how to use the RHOAS CLI to connect a specified Kafka or {registry} instance to a project in your cluster.

[IMPORTANT]
====
Before you can bind an application running on OpenShift to your Kafka and {registry} instances, you must connect *each* of these cloud services to your OpenShift cluster. Therefore, you must perform the following procedure for both services.
====

.Prerequisites
* You've installed the RHOAS Operator and verified connection to your OpenShift cluster. See {base-url}{service-binding-url-registry}#proc-verifying-connection-to-openshift-cluster_{context}[Verifying connection to your OpenShift cluster].
* You’ve created a Kafka instance in {product-kafka} and the instance is in the *Ready* state. To learn how to create a Kafka instance, see {base-url}{getting-started-url-kafka}[Getting started with {product-long-kafka}^].
* You've created a {registry} instance, and it's in the *Ready* state. To learn how to create a {registry} instance, see {base-url}{getting-started-url-registry}[Getting started with {product-long-registry}^].
* You have an API token to connect to your cloud services instances. To get a token, see the link:https://console.redhat.com/openshift/token[OpenShift Cluster Manager API Token^] page.
* You understand how Access Control Lists (ACLs) enable you to manage how user accounts and service accounts can access the Kafka resources that you create. For more information, see {base-url}{access-mgmt-url-kafka}[Managing account access in {product-long-kafka}^].
* You understand how Role-Based Access Control (RBAC) enables you to manage how user accounts and service accounts can access the {registry} instances you create and the artifacts they contain. For more information, see {base-url}{access-mgmt-url-registry}[Managing account access in {product-long-registry}^].

.Procedure

. If you're not already logged in to the OpenShift CLI, log in using a token, as described in {base-url}{service-binding-url-registry}#proc-verifying-connection-to-openshift-cluster_{context}[Verifying connection to your OpenShift cluster].

. Log in to the RHOAS CLI.
+
.Logging in to the RHOAS CLI
[source]
----
$ rhoas login
----

. Use the OpenShift CLI to specify the current OpenShift project. Specify the project that you created when verifying connection to your OpenShift cluster, as shown in the following example.
+
.Using the OpenShift CLI to specify the current OpenShift project
[source]
----
$ oc project my-project
----

. Use the RHOAS CLI to connect a Kafka or {registry} instance to the current project in your OpenShift cluster.
+
.Using the RHOAS CLI to connect a Kafka or {registry} instance to your OpenShift cluster
[source]
----
$ rhoas cluster connect
----
+
You're prompted to specify the cloud service that you want to connect to OpenShift.

. Use the up and down arrows on your keyboard to highlight `kafka` or `service-registry`. Press *Enter*.
+
Based on the service you select, you're prompted to specify the Kafka or {registry} instance that you want to connect to OpenShift.

.  If you have more than one Kafka or {registry} instance, use the up and down arrows on your keyboard to highlight the instance that you want to connect to OpenShift. Press *Enter*.
+
The RHOAS CLI shows details for the connection that you'll create. The following example shows connection details for a Kafka instance.
+
.Example connection details
[source,options="nowrap"]
----
Connection Details:

Service Type: kafka
Service Name: my-kafka-instance
Kubernetes Namespace:  my-project
Service Account Secret: rh-cloud-services-service-account
----

. Verify the connection details shown by the RHOAS CLI. When you're ready to continue, type `y` and then press *Enter*.
+
You're prompted to provide an access token. The RHOAS Operator requires this token to connect to your Kafka or {registry} instance.

. In your web browser, open the link:https://console.redhat.com/openshift/token[OpenShift Cluster Manager API Token^] page.

. On the OpenShift Cluster Manager API Token page, click **Load token**. When the page is refreshed, copy the API token shown.

. On the command line, right-click and select *Paste*. Press *Enter*.
+
Based on the cloud service that you previously selected, the RHOAS Operator uses the API token to create a `KafkaConnection` or `ServiceRegistryConnection` object on your OpenShift cluster.
+
The following example shows output for a Kafka instance.
+
.Example output from rhoas cluster connect command
[source,subs="+quotes",options="nowrap"]
----
Service Account Secret "rh-cloud-services-service-account" created successfully
Client ID: _<client_id>_
...
KafkaConnection resource "my-kafka-instance" has been created
Waiting for status from KafkaConnection resource.
Created KafkaConnection can be injected into your application.
...
KafkaConnection successfully installed on your cluster.
----
+
As shown in the preceding example, the RHOAS Operator creates a new service account to access the Kafka or {registry} instance that you specified. The Operator stores the service account information in a secret.
+
The RHOAS Operator also creates a `KafkaConnection` or `ServiceRegistryConnection` object for your Kafka or {registry} instance, which connects the instance to the OpenShift cluster. When you bind your Kafka or {registry} instance to an application on OpenShift, the Service Binding Operator uses the `KafkaConnection` or `ServiceRegistryConnection` object to provide the application with the necessary connection information for the instance. Binding an application to your Kafka or {registry} instance is described later in this guide.

. Enable the new service account created by the RHOAS Operator to access the Kafka or {registry} instance that you specified.
.. If you connected to a Kafka instance, set Access Control List (ACL) permissions to enable the new service account to access resources in the Kafka instance.
+
.Setting Kafka access permissions for the service account
[source,options="nowrap",subs="+quotes"]
----
$ rhoas kafka acl grant-access --consumer --producer --service-account _<client_id>_ --topic "\*" --group "*"
----
+
You should see output like the following example:
+
.Example output when setting Kafka access permissions
[source,subs="+quotes",options="nowrap"]
----
The following ACL rules are to be created:

  PRINCIPAL (7)  PERMISSION         DESCRIPTION
  -------------- ----------------   -------------
  _<client_id>_    ALLOW | DESCRIBE   TOPIC is "\*"
  _<client_id>_    ALLOW | READ       TOPIC is "*"
  _<client_id>_    ALLOW | READ       GROUP is "\*"
  _<client_id>_    ALLOW | WRITE      TOPIC is "*"
  _<client_id>_    ALLOW | CREATE     TOPIC is "\*"
  _<client_id>_    ALLOW | WRITE      TRANSACTIONAL_ID is "*"
  _<client_id>_    ALLOW | DESCRIBE   TRANSACTIONAL_ID is "*"

? Are you sure you want to create the listed ACL rules (y/N) Yes
✔️ ACLs successfully created in the Kafka instance "my-kafka-instance"
----
+
In this example, the permissions you create allow applications to use the service account to create topics in the Kafka instance, to produce and consume messages in any topic in the instance, and to use any consumer group.

.. If you connected to a {registry} instance, use Role-Based Access Control (RBAC) to enable the new service account to access the {registry} instance and the artifacts (such as schemas) that it contains.
+
.Setting {registry} access permissions for the service account
[source,options="nowrap",subs="+quotes"]
----
rhoas service-registry role add --role=manager --service-account _<client_id>_
Updating role for principal
Role was successfully applied
----
+
In this example, the `manager` role that you assign to the service account allows applications to use the service account to view and write to schemas in the {registry} instance.

. Use the OpenShift CLI to verify that the RHOAS Operator successfully created the `KafkaConnection` or `ServiceRegistryConnection` object, as shown in the following example:
+
.Using the OpenShift CLI to verify Operator connection to your cluster
[source]
----
$ oc get KafkaConnection

NAME   		         AGE
my-kafka-instance    2m35s
----
+
As indicated by this output, when you use the `rhoas cluster connect` command, the RHOAS Operator creates a `KafkaConnection` or `ServiceRegistryConnection` object that matches the name of your Kafka or {registry} instance. In the preceding example, the object name matches a Kafka instance called `my-kafka-instance`.

. Repeat the preceding steps to ensure that *both* your {product-kafka} and {registry} instances are connected to your OpenShift cluster.

[id="con-kafka-registry-binding-quarkus-application-using-cli_{context}"]
== Binding a Quarkus application to {product-long-kafka} and {product-long-registry} using the RHOAS CLI

When the RHOAS Operator and Service Binding Operator are installed on your OpenShift cluster and you've connected a Kafka and {registry} instance to the cluster, you're ready to deploy an application and perform service binding. __Service binding__ means instructing the Service Binding Operator to automatically inject the application with the parameters required to connect to the Kafka and {registry} instances.

The following tutorial shows how to use the RHOAS CLI to perform service binding. In the tutorial, you create an example Quarkus application and connect this to a Kafka and {registry} instance. link:https://quarkus.io/[Quarkus^] is a Kubernetes-native Java framework that is optimized for serverless, cloud, and Kubernetes environments. The Quarkus application in the tutorial uses an Apache Avro schema to serialize and deserialize messages. The application automatically publishes the Avro schema that it uses to your {registry} instance.

When you perform service binding, the Service Binding Operator automatically injects connection parameters as files into the pod for the application. The Quarkus application uses link:https://quarkus.io/guides/deploying-to-kubernetes#service-binding[service binding extensions^] for Kafka, {registry}, and the Service Binding Operator. These extensions enable the application to automatically detect and use the injected connection parameters, eliminating the need for manual configuration of the application.

In general, this automatic injection and detection of connection parameters eliminates the need to manually configure an application to connect to a Kafka or {registry} instance. This is a particular advantage if you have many applications in your project that you want to connect to these cloud services.

=== Prerequisites
* The Service Binding Operator is installed on your OpenShift cluster. See {base-url}{service-binding-url-registry}#proc-installing-service-binding-operator_{context}[Installing the Service Binding Operator on OpenShift].
* The RHOAS Operator is installed on your OpenShift cluster and you've verified connection to the cluster. See {base-url}{service-binding-url-registry}#proc-verifying-connection-to-openshift-cluster_{context}[Verifying connection to your OpenShift cluster].
* You've connected a Kafka and {registry} instance to a project in your OpenShift cluster. See {base-url}{service-binding-url-registry}#proc-connecting-kafka-registry-instance-to-openshift-cluster_{context}[Connecting a Kafka and {registry} instance to your OpenShift cluster].

[id="proc-kafka-registry-deploying-example-quarkus-application-on-openshift_{context}"]
=== Deploying an example Quarkus application on OpenShift

[role="_abstract"]
In this step of the tutorial, you deploy an example Quarkus application in the OpenShift project that you previously connected your Kafka and {registry} instances to.

The Quarkus application generates random movie names and produces those names to a Kafka topic. Another part of the application consumes the names from the Kafka topic. Finally, the application uses __server-sent events__ to expose the numbers as a REST UI. A web page in the application displays the exposed names.

The example Quarkus application uses link:https://quarkus.io/guides/deploying-to-kubernetes#service-binding[service binding extensions^] for Kafka, {registry}, and the Service Binding Operator. These extensions enable the application to automatically detect and use the injected connection parameters, eliminating the need for manual configuration of the application.

.Prerequisites
* You have privileges to deploy applications in the OpenShift project that you connected your Kafka and {registry} instances to.

.Procedure

. If you're not already logged in to the OpenShift CLI, log in using a token, as described in {base-url}{service-binding-url-registry}#proc-verifying-connection-to-openshift-cluster_{context}[Verifying connection to your OpenShift cluster]. Log in as the same user who verified connection to the cluster.

. Use the OpenShift CLI to ensure that the current OpenShift project is the one that you previously connected your Kafka and {registry} instances to, as shown in the following example.
+
.Using the OpenShift CLI to specify the current OpenShift project
[source]
----
$ oc project my-project
----

. To create the Quarkus application, deploy a container image provided by {org-name}.
+
.Deploying an example Quarkus application
[source,options="nowrap"]
----
$ oc new-app quay.io/rhoas/kafka-avro-schema-quickstart

imagestream.image.openshift.io "kafka-avro-schema-quickstart" created
deploymentconfig.apps.openshift.io "kafka-avro-schema-quickstart" created
service "kafka-avro-schema-quickstart" created
----
+
As shown in the output, when you deploy the application, OpenShift creates a service for the application. However, the service is *not* exposed by default. You must expose the service to create a route for clients to access the application.

. Expose the previously created service to create a route to the application.
+
.Creating a route to the Quarkus application
[source,options="nowrap"]
----
$ oc expose svc/kafka-avro-schema-quickstart

route.route.openshift.io/kafka-avro-schema-quickstart exposed
----

. Get the URL of the route created for the application. An example is shown below.
+
.Getting the route details for the Quarkus application
[source,options="nowrap"]
----
$ oc get route

NAME                            HOST/PORT
kafka-avro-schema-quickstart    kafka-avro-schema-quickstart-my-project.apps.sandbox-m2.ll9k.p1.openshiftapps.com
----

. On the command line, highlight the URL shown under *HOST/PORT*. Right-click and select *Copy*.

. In your web browser, paste the URL for the route. Ensure that the URL includes `http://`.
+
A web page for the Quarkus application opens.

. In your web browser, append `/movies.html` to the URL.
+
A new web page entitled *Last movie* opens.  Because you haven't yet connected the Quarkus application to your Kafka instance, the name value appears as `N/A`.

[id="proc-creating-movies-topic-in-kafka-instance_{context}"]
=== Creating the movies topic in your Kafka instance

[role="_abstract"]
In the previous step of this tutorial, you deployed an example application on OpenShift. The application is a Quarkus application that uses a Kafka topic called `movies` to produce and consume messages. In this step, you create the `movies` topic in your Kafka instance.

.Prerequisites
* You've deployed the example Quarkus application. See {base-url}{service-binding-url-registry}#proc-kafka-registry-deploying-example-quarkus-application-on-openshift_{context}[Deploying an example Quarkus application on OpenShift].
* You’ve created a Kafka instance in {product-kafka} and the instance is in the *Ready* state. To learn how to create a Kafka instance, see {base-url}{getting-started-url-kafka}[Getting started with {product-long-kafka}^].

.Procedure
. On the link:{service-url}[Kafka Instances^] page of the {product-kafka} web console, click the name of the Kafka instance that you want to add a topic to.

. Select the *Topics* tab, click *Create topic*, and follow the guided steps to define the details of the `movies` topic. Click *Next* to complete each step and click *Finish* to complete the setup.
+
.Guided steps to define topic
image::sak-create-movies-topic.png[Image of wizard to create movies topic]

*Topic name*:: Enter `movies` as the topic name.
*Partitions*:: Set the number of partitions for this topic. For this tutorial, set a value of `1`. Partitions are distinct lists of messages within a topic and enable parts of a topic to be distributed over multiple brokers in the cluster. A topic can contain one or more partitions, enabling producer and consumer loads to be scaled.
+
NOTE: You can increase the number of partitions later, but you cannot decrease them.
+
*Message retention*:: Set the message retention time to the relevant value and increment. For this tutorial, set a value of `A week`. Message retention time is the amount of time that messages are retained in a topic before they are deleted or compacted, depending on the cleanup policy.
*Replicas*:: For this release of {product-kafka}, the replicas are preconfigured. The number of partition replicas for the topic is set to `3` and the minimum number of follower replicas that must be in sync with a partition leader is set to `2`. Replicas are copies of partitions in a topic. Partition replicas are distributed over multiple brokers in the cluster to ensure topic availability if a broker fails. When a follower replica is in sync with a partition leader, the follower replica can become the new partition leader if needed.
+
After you complete the topic setup, the new Kafka topic is listed in the topics table.

[id="proc-binding-quarkus-application-to-kafka-and-registry-instances-using-cli_{context}"]
=== Binding the Quarkus application to your Kafka and {registry} instances using the RHOAS CLI

[role="_abstract"]
In this step of the tutorial, you use the RHOAS CLI to bind the example Quarkus application that you deployed on OpenShift to your Kafka and {registry} instances. When you perform this binding, the Service Binding Operator injects connection parameters as files into the pod for the application. The Quarkus application automatically detects and uses the connection parameters to bind to the Kafka and {registry} instances.

.Prerequisites
* The Service Binding Operator is installed on your OpenShift cluster. See {base-url}{service-binding-url-registry}#proc-installing-service-binding-operator_{context}[Installing the Service Binding Operator on OpenShift].
* You understand how the Service Binding Operator injects connection parameters as files into the pod for a client application. See {base-url}{service-binding-url-registry}#con-about-service-binding_{context}[About service binding].
* The RHOAS Operator is installed on your OpenShift cluster and you've verified connection to the cluster. See {base-url}{service-binding-url-registry}#proc-verifying-connection-to-openshift-cluster_{context}[Verifying connection to your OpenShift cluster].
* You've connected both a Kafka and {registry} instance to a project in your OpenShift cluster. See {base-url}{service-binding-url-registry}#proc-connecting-kafka-registry-instance-to-openshift-cluster_{context}[Connecting a Kafka and {registry} instance to your OpenShift cluster].
* You've deployed the example Quarkus application. See {base-url}{service-binding-url-registry}#proc-kafka-registry-deploying-example-quarkus-application-on-openshift_{context}[Deploying an example Quarkus application on OpenShift].
* You've created the topic required by the Quarkus application. See {base-url}{service-binding-url-registry}#proc-creating-movies-topic-in-kafka-instance_{context}[Creating the movies topic in your Kafka instance].

.Procedure
. If you're not already logged in to the OpenShift CLI, log in using a token, as described in {base-url}{service-binding-url-registry}#proc-verifying-connection-to-openshift-cluster_{context}[Verifying connection to your OpenShift cluster]. Log in as the same user who verified connection to the cluster.

. Log in to the RHOAS CLI.
+
.Logging in to the RHOAS CLI
[source]
----
$ rhoas login
----

. Use the OpenShift CLI to ensure that the current OpenShift project is the one that you previously connected your Kafka and {registry} instances to, as shown in the following example.
+
.Using the OpenShift CLI to specify the current OpenShift project
[source]
----
$ oc project my-project
----
+
. Use the RHOAS CLI to instruct the Service Binding Operator to bind a Kafka or {registry} instance to an application in your OpenShift project.
+
.Using the RHOAS CLI to bind a cloud services instance to an application on OpenShift
[source]
----
$ rhoas cluster bind
----
+
You're prompted to specify the cloud service that you want to bind to your OpenShift application.
+
IMPORTANT: Steps 5-8 that follow show how to bind a *Kafka* instance to the Quarkus application. Later in the procedure, you're instructed to repeat the steps for your *{registry}* instance.

. Use the up and down arrows on your keyboard to highlight `kafka`. Press *Enter*.
+
You're prompted to specify the Kafka instance that you want to bind to an application in your OpenShift project.

.  If you have more than one Kafka instance, use the up and down arrows on your keyboard to highlight the instance that you want to bind to an application in OpenShift. Press *Enter*.
+
You're prompted to specify the application that you want to bind your Kafka instance to.

. If you have more than one application in your OpenShift project, use the up and down arrows on your keyboard to highlight the `kafka-avro-schema-quickstart` example application. Press *Enter*.

. Type `y` to confirm that you want to continue. Press *Enter*.
+
When binding is complete, you should see output like the following:
+
.Example output from binding a Kafka instance to an application in OpenShift
[source]
----
Using Service Binding Operator to perform binding
Binding my-kafka-instance with kafka-avro-schema-quickstart app succeeded
----
+
The output shows that the RHOAS CLI successfully instructed the Service Binding Operator to bind a Kafka instance called `my-kafka-instance` to the example Quarkus application called `kafka-avro-schema-quickstart`. The Quarkus application automatically detected the connection parameters injected by the Service Binding Operator and used them to bind with the Kafka instance.

. *Repeat steps 5-8* of this procedure to bind your {registry} instance to the Quarkus application. This time, when you're prompted to specify the cloud service that you want to connect to OpenShift, use the up and down arrows on your keyboard to highlight `service-registry`.
+
When service binding is complete, OpenShift redeploys the Quarkus application. When the application is running again, it starts to use the `movies` topic that you created in your Kafka instance. One part of the Quarkus application publishes movie name updates to this topic, while another part of the application consumes the updates.

. To verify that the Quarkus application is using the Kafka topic, reopen the *Last movie* web page that you opened earlier in this tutorial.
+
On the *Last movie* web page, observe that the movie name is continuously updated. The updates show that the Quarkus application is now using the `movies` topic in your Kafka instance to produce and consume messages.
