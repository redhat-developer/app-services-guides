////
START GENERATED ATTRIBUTES
WARNING: This content is generated by running npm --prefix .build run generate:attributes
////

//All OpenShift Application Services
:org-name: Application Services
:product-long-rhoas: OpenShift Application Services
:community:
:imagesdir: ./images
:property-file-name: app-services.properties
:samples-git-repo: https://github.com/redhat-developer/app-services-guides
:base-url: https://github.com/redhat-developer/app-services-guides/tree/main/docs/
:sso-token-url: https://sso.redhat.com/auth/realms/redhat-external/protocol/openid-connect/token
:cloud-console-url: https://console.redhat.com/
:service-accounts-url: https://console.redhat.com/application-services/service-accounts
:rh-sso-url: https://sso.redhat.com 

//OpenShift
:openshift: OpenShift
:osd-name: OpenShift Dedicated
:osd-name-short: OpenShift Dedicated
:rosa-name: OpenShift Service for AWS
:rosa-name-short: OpenShift Service for AWS

//OpenShift Application Services CLI
:base-url-cli: https://github.com/redhat-developer/app-services-cli/tree/main/docs/
:command-ref-url-cli: commands
:installation-guide-url-cli: rhoas/rhoas-cli-installation/README.adoc
:service-contexts-url-cli: rhoas/rhoas-service-contexts/README.adoc

//OpenShift Streams for Apache Kafka
:product-long-kafka: OpenShift Streams for Apache Kafka
:product-kafka: Streams for Apache Kafka
:product-version-kafka: 1
:service-url-kafka: https://console.redhat.com/application-services/streams/
:getting-started-url-kafka: kafka/getting-started-kafka/README.adoc
:kafka-bin-scripts-url-kafka: kafka/kafka-bin-scripts-kafka/README.adoc
:kafkacat-url-kafka: kafka/kcat-kafka/README.adoc
:quarkus-url-kafka: kafka/quarkus-kafka/README.adoc
:nodejs-url-kafka: kafka/nodejs-kafka/README.adoc
:getting-started-rhoas-cli-url-kafka: kafka/rhoas-cli-getting-started-kafka/README.adoc
:topic-config-url-kafka: kafka/topic-configuration-kafka/README.adoc
:consumer-config-url-kafka: kafka/consumer-configuration-kafka/README.adoc
:access-mgmt-url-kafka: kafka/access-mgmt-kafka/README.adoc
:metrics-monitoring-url-kafka: kafka/metrics-monitoring-kafka/README.adoc
:service-binding-url-kafka: kafka/service-binding-kafka/README.adoc
:message-browsing-url-kafka: kafka/message-browsing-kafka/README.adoc

//OpenShift Service Registry
:product-long-registry: OpenShift Service Registry
:product-registry: Service Registry
:registry: Service Registry
:product-version-registry: 1
:service-url-registry: https://console.redhat.com/application-services/service-registry/
:getting-started-url-registry: registry/getting-started-registry/README.adoc
:quarkus-url-registry: registry/quarkus-registry/README.adoc
:getting-started-rhoas-cli-url-registry: registry/rhoas-cli-getting-started-registry/README.adoc
:access-mgmt-url-registry: registry/access-mgmt-registry/README.adoc
:content-rules-registry: https://access.redhat.com/documentation/en-us/red_hat_openshift_service_registry/1/guide/9b0fdf14-f0d6-4d7f-8637-3ac9e2069817[Supported Service Registry content and rules]
:service-binding-url-registry: registry/service-binding-registry/README.adoc

//OpenShift Connectors
:connectors: Connectors
:product-long-connectors: OpenShift Connectors
:product-connectors: Connectors
:product-version-connectors: 1
:service-url-connectors: https://console.redhat.com/application-services/connectors
:getting-started-url-connectors: connectors/getting-started-connectors/README.adoc
:getting-started-rhoas-cli-url-connectors: connectors/rhoas-cli-getting-started-connectors/README.adoc

//OpenShift API Designer
:product-long-api-designer: OpenShift API Designer
:product-api-designer: API Designer
:product-version-api-designer: 1
:service-url-api-designer: https://console.redhat.com/application-services/api-designer/
:getting-started-url-api-designer: api-designer/getting-started-api-designer/README.adoc

//OpenShift API Management
:product-long-api-management: OpenShift API Management
:product-api-management: API Management
:product-version-api-management: 1
:service-url-api-management: https://console.redhat.com/application-services/api-management/

////
END GENERATED ATTRIBUTES
////

[id="chap-using-quarkus-registry"]
= Using Quarkus applications with Kafka instances and {product-long-registry}
ifdef::context[:parent-context: {context}]
:context: quarkus-service-registry

// Purpose statement for the assembly
[role="_abstract"]
As a developer of applications and services, you can connect Quarkus applications to Kafka instances in {product-long-kafka} and {registry} instances in {product-long-registry}. This makes it easy for development teams to store and reuse schemas in event-streaming architectures.

https://quarkus.io/[Quarkus^] is a Kubernetes-native Java framework made for Java virtual machines (JVMs) and native compilation, and optimized for serverless, cloud, and Kubernetes environments. Quarkus is designed to work with popular Java standards, frameworks, and libraries like Eclipse MicroProfile and Spring, as well as Apache Kafka, RESTEasy (JAX-RS), Hibernate ORM (JPA), Infinispan, Camel, and many more.

In this quick start, you'll manually configure connections from an example Quarkus application to Kafka and {registry} instances. The application will use the Kafka instance to produce and consume messages and a schema stored in the {registry} instance to serialize/deserialize the messages.

NOTE: When you've completed this quick start and understand the required connection configurations for Kafka and {registry} instances, you can use the {product-long-rhoas} command-line interface (CLI) to generate these types of configurations in a more automated way. To learn more, see {base-url}{service-contexts-url-cli}[Connecting client applications to {product-long-rhoas} using the rhoas CLI^].

.Prerequisites
ifndef::community[]
* You have a {org-name} account.
endif::[]
* You have a running Kafka instance in {product-kafka} (see {base-url}{getting-started-url-kafka}[Getting started with {product-long-kafka}^]).
* You have a running {registry} instance in {product-long-registry} (see {base-url}{getting-started-url-registry}[Getting started with {product-long-registry}^]).
* You have a command-line terminal application.
* https://github.com/git-guides/[Git^] is installed.
* You have an IDE such as https://www.jetbrains.com/idea/download/[IntelliJ IDEA^], https://www.eclipse.org/downloads/[Eclipse^], or https://code.visualstudio.com/Download[Visual Studio Code^].
* https://adoptopenjdk.net/[OpenJDK^] 11 or later is installed. (The latest LTS version of OpenJDK is recommended.)

* https://maven.apache.org/[Apache Maven^] 3.8 (or a later Maven 3 release) is installed.

// Condition out QS-only content so that it doesn't appear in docs.
// All QS anchor IDs must be in this alternate anchor ID format `[#anchor-id]` because the ascii splitter relies on the other format `[id="anchor-id"]` to generate module files.
ifdef::qs[]
[#description]
====
Manually connect a Quarkus application to a Kafka instance and to a {registry} instance.
====

[#introduction]
====
Welcome to the quick start for {product-long-registry} with Quarkus. In this quick start, you'll learn how to manually connect an example https://quarkus.io/[Quarkus^] application to a Kafka instance in {product-long-kafka} and a {registry} instance in {product-registry}. The application will use the Kafka instance to produce and consume messages and a schema stored in the {registry} instance to serialize/deserialize the messages.
====
endif::[]

[id="proc-importing-quarkus-registry-sample-code_{context}"]
== Importing the Quarkus sample code

[role="_abstract"]
For this quick start, you'll use the Quarkus {registry} sample code from the App Services {samples-git-repo}[Guides and Samples^] repository in GitHub. After you understand the concepts and tasks in this quick start, you can use your own Quarkus applications with {product-kafka} and {registry} in the same way.

.Procedure
. On the command line, clone the App Services {samples-git-repo}[Guides and Samples^] repository from GitHub.
+
[source,subs="+attributes"]
----
git clone {samples-git-repo} app-services-guides
----
. In your IDE, open the `code-examples/quarkus-service-registry-quickstart` directory from the repository that you cloned.

ifdef::qs[]
.Verification
* Is the Quarkus example application accessible in your IDE?
endif::[]

[id="proc-configuring-quarkus-registry-app_{context}"]
== Configuring the Quarkus application to connect to Kafka and {registry} instances

[role="_abstract"]
To enable your Quarkus applications to access a Kafka instance, configure the connection properties using the Kafka bootstrap server endpoint. To access a {registry} instance, configure the registry endpoint connection property with the Core Registry API value.

Access to the {registry} and Kafka instances is managed using the same service account and SASL/OAUTHBEARER token endpoint. For Quarkus, you can configure all connection properties using the `application.properties` file. The example in this task sets environment variables and then references them in the  `application.properties` file.

Quarkus applications use https://github.com/eclipse/microprofile-reactive-messaging[MicroProfile Reactive Messaging^] to produce messages to and consume messages from your Kafka instances in {product-kafka}. For details on configuration options, see the https://quarkus.io/guides/kafka[Apache Kafka Reference Guide^] in the Quarkus documentation.

This Quarkus example application includes producer and consumer processes that serialize/deserialize Kafka messages using a schema stored in {registry}.

.Prerequisites
* You have a service account with write access to Kafka and {registry} instances and have stored your credentials securely (see {base-url}{getting-started-url-kafka}[Getting started with {product-long-kafka}^] and {base-url}{getting-started-url-registry}[Getting started with {product-long-registry}^]).
* You have the bootstrap server endpoint for the Kafka instance. To get this information, select your Kafka instance in the {service-url-kafka}[{product-kafka} web console^], select the options icon (three vertical dots), and click *Connection*.
* You have the Core Registry API endpoint for the {registry} instance. To get this information, select your {registry} instance in the {service-url-registry}[{product-registry} web console^], select the options icon (three vertical dots) and click *Connection*. Copy the *Core Registry API* endpoint supported by the Apicurio serializer/deserializer (SerDes) used in this example.
* You have the SASL/OAUTHBEARER token endpoint used by the {registry} and Kafka instances. To get this information, select your {registry} instance in the {service-url-registry}[{product-registry} web console^], select the options icon (three vertical dots) and click *Connection*. Copy the *Token endpoint URL* value.

.Procedure
. On the command line, set the following environment variables to use your Kafka and {registry} instances with Quarkus or other applications. Replace values in angle brackets (`< >`) with your own server and credential information.
+
* The `<bootstrap_server>` value is the bootstrap server endpoint for your Kafka instance.
* The `<service_registry_url>` value is the URL for your {registry} instance.
* The `SERVICE_REGISTRY_CORE_PATH` variable is a constant value used to set the API path for {product-registry}.
* The `<oauth_token_endpoint_uri>` value is the SASL/OAUTHBEARER token endpoint.
* The `<client_id>` and `<client_secret>` values are the generated credentials for your service account.
+
.Setting environment variables for server and credentials
[source,subs="+quotes"]
----
$ export KAFKA_HOST=__<bootstrap_server>__
$ export SERVICE_REGISTRY_URL=__<service_registry_url>__
$ export SERVICE_REGISTRY_CORE_PATH=/apis/registry/v2
$ export RHOAS_SERVICE_ACCOUNT_OAUTH_TOKEN_URL=__<oauth_token_endpoint_uri>__
$ export RHOAS_SERVICE_ACCOUNT_CLIENT_ID=__<client_id>__
$ export RHOAS_SERVICE_ACCOUNT_CLIENT_SECRET=__<client_secret>__
----

. In the Quarkus example application, review the `/src/main/resources/application.properties` files in the `consumer` and `producer` subfolders to understand how the environment variables you set in the previous step are used. This example uses the `dev` configuration profile in the `application.properties` files.

ifdef::qs[]
.Verification
* Did you set the required environment variables for accessing your services?
endif::[]

[id="proc-create-prices-topic-registry_{context}"]
== Creating the quotes Kafka topic in {product-kafka}

[role="_abstract"]
The Quarkus application in this quick start uses a Kafka topic called `quotes` to produce and consume messages. In this task, you'll create the `quotes` topic in your Kafka instance.

.Prerequisites
* You have a running Kafka instance in {product-long-kafka}.

.Procedure
. In the {product-kafka} {service-url-kafka}[web console^], select *Kafka Instances* and then click the name of the Kafka instance that you want to add a topic to.
. Select the *Topics* tab.
. Click *Create topic* and follow the guided steps to define the topic details.
+
--
You must specify the following topic properties:

* *Topic name*: For this quick start, enter `quotes` as the topic name.
* *Partitions*: Set the number of partitions for the topic. For this quick start, set the value to `1`.
* *Message retention*: Set the message retention time and size. For this quick start, set the retention time to `A week` and the retention size to `Unlimited`.
* *Replicas*: For this release of {product-kafka}, the replica values are preconfigured. The number of partition replicas for the topic is set to `3` and the minimum number of follower replicas that must be in sync with a partition leader is set to `2`. For a trial Kafka instance, the number of replicas and the minimum in-sync replica factor are both set to `1`.

After you complete the setup, the new topic appears on the *Topics* page. You can now run the Quarkus application to start producing and consuming messages to and from this topic.
--

.Verification
ifdef::qs[]
* Is the `quotes` topic listed on the *Topics* page?
endif::[]
ifndef::qs[]
* Verify that the `quotes` topic is listed on the *Topics* page.
endif::[]


[id="proc-running-quarkus-registry-example-app_{context}"]
== Running the Quarkus example application

[role="_abstract"]
After you configure your Quarkus application to connect to Kafka and {registry} instances, and you create the Kafka topic, you can run the Quarkus application to start producing and consuming messages to and from this topic.

The Quarkus application in this quick start consists of the following processes:

* A consumer process that is implemented by the `QuotesResource` class. This class exposes the `/quotes` REST endpoint that streams quotes from the `quotes` topic. This process also has a minimal frontend that uses Server-Sent Events to stream the quotes to a web page.
* A producer process that is implemented by the `QuotesProducer` class. This class produces a new quote periodically (every 5 seconds) with a random  value that is published to the `quotes` topic.

.Prerequisites
* You've configured the Quarkus example application to connect to your Kafka and {registry} instances.
* You've created the Kafka `quotes` topic.
ifndef::qs[]
* You're logged in to the {registry} web console at {service-url-registry}[^].
endif::[]


.Procedure
. On the command line, change to the `code-examples/quarkus-service-registry-quickstart/consumer` directory that you imported and run the consumer process.
+
.Running the example consumer process
[source]
----
$ cd ~/code-examples/quarkus-service-registry-quickstart/consumer
$ mvn quarkus:dev
----
. After the consumer process is running, in a web browser, go to http://localhost:8080/quotes.html[^] and verify that this process is available.

. Leave the consumer process running, and run the producer process in a different terminal.
+
.Running the example producer process
[source]
----
$ cd ~/code-examples/quarkus-service-registry-quickstart/producer
$ mvn quarkus:dev
----

. When both the consumer and producer processes are running, view the generated quotes in the web browser at http://localhost:8080/quotes.html[^].

. In the web console, go to *{registry}* > *{registry} Instances*,  select your {registry} instance, and view the automatically generated schema for your application.


.What just happened?

* The Quarkus application is configured to use the `io.apicurio.registry.serde.avro.AvroKafkaSerializer` Java class for serializing and the `io.apicurio.registry.serde.avro.AvroKafkaDeserializer` class for deserializing messages to Avro format. This SerDes is configured to use remote schemas in {product-long-registry} rather than the local schemas in the application.

* Because there are no schemas in the {registry} instance, the SerDes published the schema for the `quotes` topic. The name of the schema is managed by the `TopicRecordIdStrategy` class, which uses the `topic_name-value` convention. You can find this schema in the {registry} instance and configure compatability rules to govern how the schema can evolve for future versions.

* If the Quarkus application fails to run, review the error log in the terminal and address any problems. Also review the steps in this quick start to ensure that the Quarkus application and Kafka topic are configured correctly.

ifdef::qs[]
.Verification
* Did the Quarkus example application run without any errors?
* Did you see the generated quotes at http://localhost:8080/quotes.html[^]?
* Did you see generated schemas in the {registry} instance?
endif::[]

ifdef::qs[]
[#conclusion]
====
Congratulations! You successfully completed the {product-kafka} and {registry} Quarkus quick start, and are now ready to use your own Quarkus application with {product-kafka} and {registry}.
====
endif::[]

ifdef::parent-context[:context: {parent-context}]
ifndef::parent-context[:!context:]
