////
START GENERATED ATTRIBUTES
WARNING: This content is generated by running npm --prefix .build run generate:attributes
////

//All OpenShift Application Services
:org-name: Application Services
:product-long-rhoas: OpenShift Application Services
:community:
:imagesdir: ./images
:property-file-name: app-services.properties
:samples-git-repo: https://github.com/redhat-developer/app-services-guides
:base-url: https://github.com/redhat-developer/app-services-guides/tree/main/docs/
:sso-token-url: https://sso.redhat.com/auth/realms/redhat-external/protocol/openid-connect/token
:cloud-console-url: https://console.redhat.com/
:service-accounts-url: https://console.redhat.com/application-services/service-accounts

//OpenShift
:openshift: OpenShift
:osd-name-short: OpenShift Dedicated

//OpenShift Application Services CLI
:base-url-cli: https://github.com/redhat-developer/app-services-cli/tree/main/docs/
:command-ref-url-cli: commands
:installation-guide-url-cli: rhoas/rhoas-cli-installation/README.adoc
:service-contexts-url-cli: rhoas/rhoas-service-contexts/README.adoc

//OpenShift Streams for Apache Kafka
:product-long-kafka: OpenShift Streams for Apache Kafka
:product-kafka: Streams for Apache Kafka
:product-version-kafka: 1
:service-url-kafka: https://console.redhat.com/application-services/streams/
:getting-started-url-kafka: kafka/getting-started-kafka/README.adoc
:kafka-bin-scripts-url-kafka: kafka/kafka-bin-scripts-kafka/README.adoc
:kafkacat-url-kafka: kafka/kcat-kafka/README.adoc
:quarkus-url-kafka: kafka/quarkus-kafka/README.adoc
:nodejs-url-kafka: kafka/nodejs-kafka/README.adoc
:getting-started-rhoas-cli-url-kafka: kafka/rhoas-cli-getting-started-kafka/README.adoc
:topic-config-url-kafka: kafka/topic-configuration-kafka/README.adoc
:consumer-config-url-kafka: kafka/consumer-configuration-kafka/README.adoc
:access-mgmt-url-kafka: kafka/access-mgmt-kafka/README.adoc
:metrics-monitoring-url-kafka: kafka/metrics-monitoring-kafka/README.adoc
:service-binding-url-kafka: kafka/service-binding-kafka/README.adoc
:message-browsing-url-kafka: kafka/message-browsing-kafka/README.adoc

//OpenShift Service Registry
:product-long-registry: OpenShift Service Registry
:product-registry: Service Registry
:registry: Service Registry
:product-version-registry: 1
:service-url-registry: https://console.redhat.com/application-services/service-registry/
:getting-started-url-registry: registry/getting-started-registry/README.adoc
:quarkus-url-registry: registry/quarkus-registry/README.adoc
:getting-started-rhoas-cli-url-registry: registry/rhoas-cli-getting-started-registry/README.adoc
:access-mgmt-url-registry: registry/access-mgmt-registry/README.adoc
:content-rules-registry: https://access.redhat.com/documentation/en-us/red_hat_openshift_service_registry/1/guide/9b0fdf14-f0d6-4d7f-8637-3ac9e2069817[Supported Service Registry content and rules]
:service-binding-url-registry: registry/service-binding-registry/README.adoc

//OpenShift Connectors
:connectors: Connectors
:product-long-connectors: OpenShift Connectors
:product-connectors: Connectors
:product-version-connectors: 1
:service-url-connectors: https://console.redhat.com/application-services/connectors
:getting-started-url-connectors: connectors/getting-started-connectors/README.adoc
:getting-started-rhoas-cli-url-connectors: connectors/rhoas-cli-getting-started-connectors/README.adoc

//OpenShift API Designer
:product-long-api-designer: OpenShift API Designer
:product-api-designer: API Designer
:product-version-api-designer: 1
:service-url-api-designer: https://console.redhat.com/application-services/api-designer/
:getting-started-url-api-designer: api-designer/getting-started-api-designer/README.adoc

//OpenShift API Management
:product-long-api-management: OpenShift API Management
:product-api-management: API Management
:product-version-api-management: 1
:service-url-api-management: https://console.redhat.com/application-services/api-management/

////
END GENERATED ATTRIBUTES
////

[id="chap-getting-started-service-registry"]
= Getting started with {product-long-registry}
ifdef::context[:parent-context: {context}]
:context: getting-started-sr

// Purpose statement for the assembly
[role="_abstract"]
As a developer of applications and services, you can use {product-long-registry} to create and set up {registry} instances and connect your applications and services to these instances. {product-long-registry} is a managed cloud service that enables you to manage schema and API definitions in your applications without having to install, configure, run, and maintain your own {registry} clusters.

For more overview information, see the https://access.redhat.com/documentation/en-us/red_hat_openshift_service_registry/1[{product-long-registry} user documentation^]

ifndef::community[]
.Prerequisites
* You have a {org-name} account.
* You have a subscription to {product-long-kafka} or {product-long-api-management}.
//For more information about signing up, see *<@SME: Where to link?>*.
endif::[]

// Condition out QS-only content so that it doesn't appear in docs.
// All QS anchor IDs must be in this alternate anchor ID format `[#anchor-id]` because the ascii splitter relies on the other format `[id="anchor-id"]` to generate module files.
ifdef::qs[]
[#description]
====
Learn how to create and set up your first {registry} instance in {product-long-registry}.
====

[#introduction]
====
Welcome to the quick start for {product-long-registry}. In this quick start, you'll learn how to create and view a {registry} instance, create a schema in this instance, and create a service account to connect an application or service to this instance.
====
endif::[]

[id="proc-creating-service-registry-instance_{context}"]
== Creating a {registry} instance

[role="_abstract"]
Use the {product-long-registry} web console to create and configure a {registry} instance for your applications or services. A {registry} instance is an isolated virtual tenant in a multi-tenanted deployment with its own unique instance URL and configuration to connect to producer and consumer applications.

ifndef::qs[]
.Prerequisites
* You're logged in to the {registry} web console at {service-url-registry}[^].
endif::[]

.Procedure
. In the {service-url-registry}[{registry} web console], click *Create {registry} instance*.
. Enter a unique *Instance name*, such as `my-service-registry-instance`.

. Click *Create* to start the creation process for your {registry} instance. The new {registry} instance is listed in the instances table.

. When the *Status* is *Ready*, you can start using this {registry} instance. You can use the options icon (three vertical dots) to connect to or delete the instance as needed.

[.screencapture]
.{registry} instance options menu
image::service-registry-instance-options.png[Image of {registry} instance options menu]

.Verification
ifdef::qs[]
* Is the new {registry} instance listed in the instances table?
* Is the state of the new {registry} instance shown as *Ready*?
endif::[]
ifndef::qs[]
. Verify that the new {registry} instance is listed in the instances table.
. Verify that the state of the new {registry} instance is shown as *Ready*.
endif::[]


[id="proc-uploading-registry-schema_{context}"]
== Uploading a schema to {registry}

[role="_abstract"]
After you create a {registry} instance, you can upload schema or API content to the instance. The following example shows uploading an Apache Avro schema for serializing and deserializing Kafka messages in client applications.

.Prerequisites
* You've created a {registry} instance and the instance is in *Ready* state.

.Procedure
. In the *{registry}* instances page of the web console, select the {registry} instance that you want to upload a schema to.
. Click *Upload artifact* and complete the form to define the schema details:
+
[.screencapture]
.Guided steps to define artifact details
image::upload-schema.png[Image of form to upload a schema]
+
* *Group*: Enter an optional unique group name such as `my-org` to organize the artifact in a named collection. Each group contains a logically related set of schemas or API designs, typically managed by a single entity, belonging to a particular application or organization.
+
NOTE:  Specifying a group is optional when using the web console, and a `default` group is automatically created.
+
* *ID*: Enter an optional unique ID for this artifact such as `my-ID`. If you do not specify a unique artifact ID, {registry} generates one automatically as a UUID.
* *Type*: Use the default *Auto-Detect* setting to automatically detect the artifact type, or select the artifact type from the drop-down, for example, Avro Schema or OpenAPI.
* *Artifact*: Drag and drop or click *Browse* to upload a file. For this example, copy and paste the following simple Avro schema:
+
[source,json,subs="+quotes,attributes"]
----
{
"type": "record",
"namespace": "com.example",
"name": "FullName",
"fields": [
{ "name": "first", "type": "string" },
{ "name": "last", "type": "string" }
]}
----

. Click *Upload* to complete the operation and display the new artifact details:

* *Info*: Displays the artifact name, group, description, lifecycle status, when created, and last modified.
* *Content*: Displays a read-only view of the full artifact content.
* *Documentation*: (OpenAPI only): Displays automatically-generated REST API documentation.
* *Content Rules*: Displays artifact content rules that you can enable and configure. You can configure a *Validity Rule* or *Compatibility Rule* by selecting the appropriate rule configuration from the drop-down. For details on supported rules, see the https://access.redhat.com/documentation/en-us/red_hat_openshift_service_registry/1[{product-long-registry} user documentation^].
+
You can now use this schema to serialize and deserialize messages from Kafka client applications.

. On the right of the screen, you can click *Upload new version* to add a new artifact version.

. You can click *Delete* to delete an artifact as needed.
+
IMPORTANT: Deleting an artifact deletes the artifact and all of its versions, and cannot be undone. Artifact versions are immutable and cannot be deleted individually.

.Verification
ifdef::qs[]
* Is the new schema in the *Artifacts* table?
endif::[]
ifndef::qs[]
* Verify that the new schema is listed in the *Artifacts* table.
endif::[]

[id="proc-connecting-registry-clients_{context}"]
== Connecting client applications to {registry}

[role="_abstract"]
To connect your applications or services to a {registry} instance in the web console, you must copy and save the {registry} instance URL, create a service account, and copy and save the generated credentials. You'll use these details later when you configure your application for {registry}.

.Prerequisites
* You've created a {registry} instance and the instance is in *Ready* state.

.Procedure
. In the *{registry} Instances* page of the web console, for the instance that you want to connect to, select the options icon (three vertical dots), and click *Connection*.
. Depending on the client libraries that you want to use, chose the API for your needs:
+
 * *Core Registry API* is the most powerful and works with Apicurio client libraries
 * *Schema Registry compatibility API* provides compatibility with the Confluent Schema Registry API
 * *CNCF Schema Registry API* provides compatibility with the CNCF specification

. In the *Connection* page, copy the *Core Registry API* URL, or one of the other API URLs if you are using a different client, to a secure location. This is the server endpoint that you'll need to connect to this {registry} instance.
+
ifdef::qs[]
The remainder of this task describes how to create a service account and copy the generated credentials.
If you want to use the credentials of an _existing_ service account, you can skip to the next task.
endif::[]
ifndef::qs[]
The remainder of this section describes how to create a service account and copy the generated credentials.
If you want to use the credentials of an _existing_ service account, you can skip to the next section.
endif::[]


.  Under *Service Accounts*, click *Create service account* to generate the credentials that you can use to connect applications to {registry} and Kafka instances.


. Copy the generated *Client ID* and *Client Secret* to a secure location.
+
IMPORTANT: The generated credentials are displayed only one time. Ensure that you've successfully and securely saved the copied credentials before closing the credentials window.

. After you save the generated credentials to a secure location, select the confirmation check box in the credentials window and close the window.

. For the *Authentication method*, copy the OAuth *Token endpoint URL* to a secure location. This is the endpoint that you’ll use with your service account credentials to authenticate the connection to this {registry} instance.
+
NOTE: HTTP Basic authentication is also available for tools and libraries that don't support OAuth, but OAuth is recommended whenever possible. With HTTP Basic, you use only the service account credentials to authenticate the connection to the {registry} instance.

+
You’ll use the service account information that you saved to configure your applications to connect to your {registry} instances later when you're ready.
+
For example, if you plan to use https://github.com/edenhill/kcat[Kcat^] to interact with your Kafka instance and deserialize Avro messages using {registry}, you'll use this information to set your {registry} URL in the client environment variables.
+
To review your service account information, reset your credentials, or delete the service account, use the left navigation menu to go to the *Service Accounts* page.

.Verification
ifdef::qs[]
* Did you save the {registry} instance URL to a secure location?
* Did you save the client credentials to a secure location?
* Did you verify that your service account was successfully created in the *Service Accounts* page?
endif::[]
ifndef::qs[]
. Verify that the {registry} instance URL is saved to a secure location.
. Verify that the client credentials are saved to a secure location.
. Verify that your service account was successfully created in the *Service Accounts* page.
endif::[]


[id="proc-setting-service-account-user-roles_{context}"]
== Assigning a role for a service account to access a {registry} instance

[role="_abstract"]
After you create a service account for applications to connect to a {registry} instance, you must also set the appropriate level of access for the new account in the *Access* tab of the {registry} instance. {registry} uses role-based access to enable you to manage how other user accounts and service accounts can interact with the {registry} instance that you create.

.Prerequisites
* You've created a {registry} instance and the instance is in *Ready* state.
* You've created a service account that you want to allow to access the running {registry} instance.

.Procedure
. In the *{registry} Instances* page of the web console, click the name of the {registry} instance that you want the service account to access.
. Click the *Access* tab to view the accounts and roles already assigned for this instance.
. Click *Grant access* to assign a role to the service account.
. In the *Account* field, select or enter the service account name that you want to assign the role to.
. Select the *Role* that you want to assign to the account, for example, *Manager* for write access to this instance.
. Click *Save* to finish.

.Verification
ifdef::qs[]
* Is the new role for the service account listed in the *Access* page of the {registry} instance?
endif::[]
ifndef::qs[]
* Verify that the new role for the service account is listed in the *Access* page of the {registry} instance.
endif::[]

[role="_additional-resources"]
== Additional resources
* {base-url}{access-mgmt-url-registry}[Managing account access in Red Hat OpenShift Service Registry^]
* https://access.redhat.com/documentation/en-us/red_hat_openshift_service_registry/1[{product-long-registry} user documentation^]
* https://access.redhat.com/documentation/en-us/red_hat_openshift_streams_for_apache_kafka/1[OpenShift Streams for Apache Kafka user documentation^]

ifdef::qs[]
[#conclusion]
====
Congratulations! You successfully completed the {registry} Getting Started quick start, and are now ready to use the service.
====
endif::[]

ifdef::parent-context[:context: {parent-context}]
ifndef::parent-context[:!context:]
