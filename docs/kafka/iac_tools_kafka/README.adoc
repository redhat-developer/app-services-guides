////
START GENERATED ATTRIBUTES
WARNING: This content is generated by running npm --prefix .build run generate:attributes
////

//All OpenShift Application Services
:org-name: Application Services
:product-long-rhoas: OpenShift Application Services
:community:
:imagesdir: ./images
:property-file-name: app-services.properties
:samples-git-repo: https://github.com/redhat-developer/app-services-guides
:base-url: https://github.com/redhat-developer/app-services-guides/tree/main/docs/
:sso-token-url: https://sso.redhat.com/auth/realms/redhat-external/protocol/openid-connect/token
:cloud-console-url: https://console.redhat.com/
:service-accounts-url: https://console.redhat.com/application-services/service-accounts

//OpenShift Application Services CLI
:base-url-cli: https://github.com/redhat-developer/app-services-cli/tree/main/docs/
:command-ref-url-cli: commands
:installation-guide-url-cli: rhoas/rhoas-cli-installation/README.adoc
:service-contexts-url-cli: rhoas/rhoas-service-contexts/README.adoc

//OpenShift Streams for Apache Kafka
:product-long-kafka: OpenShift Streams for Apache Kafka
:product-kafka: Streams for Apache Kafka
:product-version-kafka: 1
:service-url-kafka: https://console.redhat.com/application-services/streams/
:getting-started-url-kafka: kafka/getting-started-kafka/README.adoc
:kafka-bin-scripts-url-kafka: kafka/kafka-bin-scripts-kafka/README.adoc
:kafkacat-url-kafka: kafka/kcat-kafka/README.adoc
:quarkus-url-kafka: kafka/quarkus-kafka/README.adoc
:nodejs-url-kafka: kafka/nodejs-kafka/README.adoc
:getting-started-rhoas-cli-url-kafka: kafka/rhoas-cli-getting-started-kafka/README.adoc
:topic-config-url-kafka: kafka/topic-configuration-kafka/README.adoc
:consumer-config-url-kafka: kafka/consumer-configuration-kafka/README.adoc
:access-mgmt-url-kafka: kafka/access-mgmt-kafka/README.adoc
:metrics-monitoring-url-kafka: kafka/metrics-monitoring-kafka/README.adoc
:service-binding-url-kafka: kafka/service-binding-kafka/README.adoc
:message-browsing-url-kafka: kafka/message-browsing-kafka/README.adoc

//OpenShift Service Registry
:product-long-registry: OpenShift Service Registry
:product-registry: Service Registry
:registry: Service Registry
:product-version-registry: 1
:service-url-registry: https://console.redhat.com/application-services/service-registry/
:getting-started-url-registry: registry/getting-started-registry/README.adoc
:quarkus-url-registry: registry/quarkus-registry/README.adoc
:getting-started-rhoas-cli-url-registry: registry/rhoas-cli-getting-started-registry/README.adoc
:access-mgmt-url-registry: registry/access-mgmt-registry/README.adoc
:content-rules-registry: https://access.redhat.com/documentation/en-us/red_hat_openshift_service_registry/1/guide/9b0fdf14-f0d6-4d7f-8637-3ac9e2069817[Supported Service Registry content and rules]
:service-binding-url-registry: registry/service-binding-registry/README.adoc

//OpenShift Connectors
:connectors: Connectors
:product-long-connectors: OpenShift Connectors
:product-connectors: Connectors
:product-version-connectors: 1
:service-url-connectors: https://console.redhat.com/application-services/connectors
:getting-started-url-connectors: connectors/getting-started-connectors/README.adoc
:getting-started-rhoas-cli-url-connectors: connectors/rhoas-cli-getting-started-connectors/README.adoc

//OpenShift API Designer
:product-long-api-designer: OpenShift API Designer
:product-api-designer: API Designer
:product-version-api-designer: 1
:service-url-api-designer: https://console.redhat.com/application-services/api-designer/
:getting-started-url-api-designer: api-designer/getting-started-api-designer/README.adoc

//OpenShift API Management
:product-long-api-management: OpenShift API Management
:product-api-management: API Management
:product-version-api-management: 1
:service-url-api-management: https://console.redhat.com/application-services/api-management/

////
END GENERATED ATTRIBUTES
////

[id="chap-using-iac-tools"]
= Using Infrastructure as Code tools with Kafka instances in {product-long-kafka}
:context: using-iac-tools

[role="_abstract"]
Learn how to use different IaC tools to manage OpenShift Streams for Apache Kafka.

As a developer of applications and services, you can use Infrastructure as Code (IaC) tools to automate deployment and management of architectures.

This guide describes how to use different IaC tools to provision and manage your {product-long-kafka} instances.

//Additional line break to resolve mod docs generation error

[id="Ansible_{context}"]
== Ansible

[role="_abstract"]
Ansible is an open source configuration management and automation tool. To learn more about Ansible, including how to install it, see Learning Ansible Basics.

Ansible uses modules to execute tasks. One or more Ansible modules can be combined to make a play. Two or more plays can be combined to create an Ansible Playbook. Ansible Playbooks are lists of tasks (written in YAML) that automatically execute against hosts. Groups of hosts form your Ansible inventory.

Use the Ansible Playbook from the RHOAS Ansible collection to fully manage your Kafka environment by completing the following tasks:

* Create and delete OpenShift Streams instance from your Ansible Automation or GitOps workflow.
* Create and delete service accounts using an Ansible module.
* Create, configure, and delete Kafka topics.
* Create, retrieve info on, and delete Access Control Lists (ACLs) on your Kafka instance.

//Additional line break to resolve mod docs generation error

[id="proc-install-rhoas-ansible-collection_{context}"]
=== Installing the RHOAS Ansible collection

[role="_abstract"]
The RHOAS Ansible collection is available on Ansible Galaxy.

.Prerequisites

* You have installed the latest supported version of Ansible for your operating system.

.Procedure

. Open a terminal and enter the following command:
+
[source,shell]
----
$ ansible-galaxy collection install redhat_cloud.services
----

. This collection works best if used in a Python virtual environment. To create and activate a Python virtual environment, enter the following command:
+
[source,shell]
----
$ python3 -m venv rhoas
rhoas/bin/activate
----
. This collection requires some additional dependencies to be installed. Enter the following command to make sure that the most up to date version of the SDKs are installed.
+
[source,shell]
----
$ pip install rhoas-sdks --force-reinstall
----

=== Using the RHOAS Ansible collection

.Prerequisites
* You have a Red Hat account.
* You have an offline token that is accessible to Ansible.

[NOTE]
The offline token is a refresh token with no expiry and can be used by non-interactive processes to provide an access token for Red Hat OpenShift Application Services to authenticate the user. The token is an OpenShift Cluster Manager API Token and can be found at https://cloud.redhat.com/openshift/token. If the token is not passed in as an argument per task, the module attempts to read it from the environment variable OFFLINE_TOKEN.

* Two further environment variables are used for the collection to work. These environment variables can be placed in a `.env` file. If neither of these environment variables are set, the collection will default to the URLs shown in the examples.
- API_BASE_HOST - The base host for the API. This is the base URL for the API. For example, https://api.openshift.com.
- SSO_BASE_HOST - The base host for the SSO. This is the base URL for the SSO. For example, https://sso.redhat.com/auth/realms/redhat-external

.Procedure

. Create a

[id="Terraform_{context}"]
== Terraform

link:https://www.terraform.io/[Terraform^] is an infrastructure as code tool that lets you build, change, and version infrastructure safely and efficiently through human-readable configuration files that you can version, reuse, and share. You can then use a consistent workflow to provision and manage all of your infrastructure throughout its lifecycle.

The link:https://registry.terraform.io/providers/redhat-developer/rhoas/latest[RHOAS Terraform^] provider is available in the official link:https://www.terraform.io/[Terraform provider registry^] provider registry and includes resources to interact with Red Hat OpenShift Application Services.

Streams for Apache Kafka provides two REST APIs, one for accessing the Kafka instance and one for managing resources such as Kafka instances and services accounts. The RHOAS Terraform provider takes information from these REST APIs. You can fully manage your Kafka environment through your Terraform system using the RHOAS Terraform provider to complete the following tasks:

* Create, configure, deploy, and delete multiple OpenShift for Apache Kafka Streams instances.
* Create, retrieve info on,  and delete service accounts.
* Reference a Kafka instance to create, configure, and delete Kafka topics.
* Create, retrieve info on, and delete ACLs on your Kafka instance.


[id="proc-using-rhoas-terraform-provider_{context}"]
=== Using the RHOAS Terraform provider

.Prerequisites
* You have a Red Hat account.
* You have installed the latest supported version of link:https://www.terraform.io/downloads[Terraform^] for your operating system.
* You have an offline token that is accessible to Terraform.

[NOTE]
The offline token is a refresh token with no expiry and can be used by non-interactive processes to provide an access token for Red Hat OpenShift Application Services to authenticate the user. The token is an OpenShift Cluster Manager API token and can be found at https://cloud.redhat.com/openshift/token.

.Procedure
. Open your browser of choice and navigate to the RHOAS Terraform provider.
. Click *Use Provider*.
. Copy the code provided.
+

.Example rhoas provider configuration
[source,shell]
----
$ terraform {
  required_providers {
    rhoas = {
      source = "redhat-developer/rhoas"
      version = "0.2.1"
    }
  }
}

provider "rhoas" {
  offline_token = "<offline_token>"
}
----
. Open your IDE of choice and paste the code into it.  Replace <offline_token> with your own offline token.
+
[NOTE]
You can also enter the offline token through the environment variables in the terminal when running terraform apply with OFFLINE_TOKEN.
+

. Save the file as a .tf file.
. Open a terminal and enter the following command:
+
[source,shell]
----
$ terraform init
----
This command initializes the working directory containing Terraform configuration files and installs any required plug-ins.

The next steps show what resources you can add to your Terraform configuration file to provision your Kafka instance.

[id="proc-creating-kafka-instance-terraform_{context}"]
=== Creating a Kafka instance

[role="_abstract"]
To manage a Kafka instance using Terraform, use the `rhoas_kafka` resource.

.Prerequisites

* You have an offline token that is accessible to Terraform.

.Procedure

. Enter the following command to create a Kafka instance. This example creates a Kafka instance called `my-instance`. The `name`, `plan`, and `billing model` fields are required fields. The following are default fields:
+
.. `cloud provider`: A list of available cloud providers can be obtained using `data.rhoas_cloud_providers`.
.. `region`: A list of available regions can be obtained using
`data.rhoas_cloud_providers_regions`

+
.Creating a Kafka instance
[source,shell]
----
$ terraform {
  required_providers {
    rhoas = {
      source  = "registry.terraform.io/redhat-developer/rhoas"
      version = "0.1"
    }
  }
}

provider "rhoas" {}

resource "rhoas_kafka" "my-instance" {
  name = "my-instance"
}

output "bootstrap_server_my-instance" {
  value = rhoas_kafka.my-instance.bootstrap_server_host
}
----
. Open a terminal and initilize Terraform by entering the following command.
+
[source,shell]
----
$ terraform init
----
. Apply the changes by entering the following command.
+
[source,shell]
----
$ terraform apply
----
. Verify that the instance has been created in the the table on the *Kafka Instances* page {product-long-kafka}{service-url-kafka}[web console^].

[id="proc-creating-service-account-terraform_{context}"]
=== Creating a service account

[role="_abstract"]
To connect your applications or services to a Kafka instance in Red Hat OpenShift Streams for Apache Kafka, you need to create a service account...

.Prerequisites

* You have an offline token that is accessible to Terraform.
*  You have a running Kafka instance in {product-kafka}.

.Procedure

. Enter the following command to create a service account.
+

.Creating a service account
[source,shell]
----
$ resource "rhoas_service_account" "my-instance" {
  name        = "<name of service account>"
  description = "<description of service account>"
}
----
. Apply the changes by entering the following command.
+
[source,shell]
----
$ terraform apply
----
these values are just populated after apply in the client_id and client_secret field., w

[id="proc-creating-kafka-topic-cli_{context}"]
=== Creating a Kafka topic

[role="_abstract"]
After creating a Kafka instance, you can create Kafka topics to start producing and consuming messages in your services.

.Prerequisites

* You have an offline token that is accessible to Terraform.
* You have created a Kafka instance.


.Procedure

. Create a Kafka topic with default values.
+
--
This example creates the `my-topic` Kafka topic.

.Creating a Kafka topic with default values
[source,shell]
----
$ resource ‘rhoas_topic’ “topic” {
		name = “my-topic”
		partitions = 1
		Kafka_id = rhoas_kafka.instance.id
	}

----

[NOTE]
====
If you do not want to use the default values,
you can specify the number of partitions (`--partitions`) and message retention time (`--retention-
====
--

. If necessary, you can edit or delete the topic by using the `rhoas kafka topic update` and `rhoas kafka topic delete` commands.

[id="proc-creating-acl-binding-terraform_{context}"]
=== Creating an ACL binding

[role="_abstract"]
Use the `rhoas_acl` resource to manage an ACL binding for a Kafka instance.

.Prerequisites

* You have an offline token that is accessible to Terraform.
* You have created a Kafka instance and a topic.
* You have created a service account and know the client ID.

.Procedure

. Enter the following command to create an ACL binding.

+
.Creating an ACL binding
[source,shell]
----
$ resource "resource_acl" "acl" {
  kafka_id = rhoas_kafka.instance.id
  resource_type = "TOPIC"
  resource_name = "my-topic"
  pattern_type = "LITERAL"
  principal = rhoas_service_account.srvcaccnt.client_id
  operation = "ALL"
  permission = "ALLOW"
}

----
. Verify that the instance has been created in the the table on the *Kafka Instances* page {product-long-kafka}{service-url-kafka}[web console^].

[id="proc-performing-all-actions_{context}"]
=== Performing all actions

[role="_abstract"]
The following example shows a Terraform configuration file that puts together all the previous tasks. It provisions a Kafka instance, creates a service account and topics, and creates an ACL binding.

.Example all actions Terraform configuration file
[source,shell]
----
$ terraform {
  required_providers {
    rhoas = {
        source  = "registry.terraform.io/redhat-developer/rhoas"
        version = "0.1.0"
    }
  }
}

provider "rhoas" {
    offline_token = "..."
}

resource "rhoas_service_account" "srvcaccnt" {
  name = "service_account"
}

resource "rhoas_kafka" "instance" {
  name = "instance"
  plan = "developer.x1"
  billing_model = "standard"
  acl = [
    {
      principal = rhoas_service_account.srvcaccnt.client_id,
      resource_type = "TOPIC",
      resource_name = "topic-1",
      pattern_type = "LITERAL",
      operation_type = "ALL",
      permission_type = "ALLOW",
    },
  ]
}

resource "rhoas_topic" "topic-1" {
  kafka_id = rhoas_kafka.instance.id
  name = "topic-1"
  partitions = 1
}

resource "rhoas_topic" "topic-2" {
  kafka_id = rhoas_kafka.instance.id
  name = "topic-2"
  partitions = 1
}

resource "rhoas_acl" "acl" {
  kafka_id = rhoas_kafka.instance.id
  principal = rhoas_service_account.srvcaccnt.client_id
  resource_type = "TOPIC"
  resource_name = "topic-2"
  pattern_type = "LITERAL"
  operation_type = "ALL"
  permission_type = "ALLOW"
}

data "rhoas_kafka" "instance_data" {
  id = rhoas_kafka.instance.id
}

data "rhoas_service_account" "srvcaccnt_data" {
  id = rhoas_service_account.srvcaccnt.id
}

----

.Additional resources
* {base-url-cli}{command-ref-url-cli}[_CLI command reference (rhoas)_^]
