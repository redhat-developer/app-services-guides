////
START GENERATED ATTRIBUTES
WARNING: This content is generated by running npm --prefix .build run generate:attributes
////

//All OpenShift Application Services
:org-name: Application Services
:product-long-rhoas: OpenShift Application Services
:community:
:imagesdir: ./images
:property-file-name: app-services.properties
:samples-git-repo: https://github.com/redhat-developer/app-services-guides
:base-url: https://github.com/redhat-developer/app-services-guides/tree/main/docs/
:sso-token-url: https://sso.redhat.com/auth/realms/redhat-external/protocol/openid-connect/token
:cloud-console-url: https://console.redhat.com/
:service-accounts-url: https://console.redhat.com/application-services/service-accounts

//to avoid typos
:openshift: OpenShift
:openshift-dedicated: OpenShift Dedicated

//OpenShift Application Services CLI
:base-url-cli: https://github.com/redhat-developer/app-services-cli/tree/main/docs/
:command-ref-url-cli: commands
:installation-guide-url-cli: rhoas/rhoas-cli-installation/README.adoc
:service-contexts-url-cli: rhoas/rhoas-service-contexts/README.adoc

//OpenShift Streams for Apache Kafka
:product-long-kafka: OpenShift Streams for Apache Kafka
:product-kafka: Streams for Apache Kafka
:product-version-kafka: 1
:service-url-kafka: https://console.redhat.com/application-services/streams/
:getting-started-url-kafka: kafka/getting-started-kafka/README.adoc
:kafka-bin-scripts-url-kafka: kafka/kafka-bin-scripts-kafka/README.adoc
:kafkacat-url-kafka: kafka/kcat-kafka/README.adoc
:quarkus-url-kafka: kafka/quarkus-kafka/README.adoc
:nodejs-url-kafka: kafka/nodejs-kafka/README.adoc
:getting-started-rhoas-cli-url-kafka: kafka/rhoas-cli-getting-started-kafka/README.adoc
:topic-config-url-kafka: kafka/topic-configuration-kafka/README.adoc
:consumer-config-url-kafka: kafka/consumer-configuration-kafka/README.adoc
:access-mgmt-url-kafka: kafka/access-mgmt-kafka/README.adoc
:metrics-monitoring-url-kafka: kafka/metrics-monitoring-kafka/README.adoc
:service-binding-url-kafka: kafka/service-binding-kafka/README.adoc
:message-browsing-url-kafka: kafka/message-browsing-kafka/README.adoc

//OpenShift Service Registry
:product-long-registry: OpenShift Service Registry
:product-registry: Service Registry
:registry: Service Registry
:product-version-registry: 1
:service-url-registry: https://console.redhat.com/application-services/service-registry/
:getting-started-url-registry: registry/getting-started-registry/README.adoc
:quarkus-url-registry: registry/quarkus-registry/README.adoc
:getting-started-rhoas-cli-url-registry: registry/rhoas-cli-getting-started-registry/README.adoc
:access-mgmt-url-registry: registry/access-mgmt-registry/README.adoc
:content-rules-registry: https://access.redhat.com/documentation/en-us/red_hat_openshift_service_registry/1/guide/9b0fdf14-f0d6-4d7f-8637-3ac9e2069817[Supported Service Registry content and rules]
:service-binding-url-registry: registry/service-binding-registry/README.adoc

//OpenShift Connectors
:connectors: Connectors
:product-long-connectors: OpenShift Connectors
:product-connectors: Connectors
:product-version-connectors: 1
:service-url-connectors: https://console.redhat.com/application-services/connectors
:getting-started-url-connectors: connectors/getting-started-connectors/README.adoc
:getting-started-rhoas-cli-url-connectors: connectors/rhoas-cli-getting-started-connectors/README.adoc

//OpenShift API Designer
:product-long-api-designer: OpenShift API Designer
:product-api-designer: API Designer
:product-version-api-designer: 1
:service-url-api-designer: https://console.redhat.com/application-services/api-designer/
:getting-started-url-api-designer: api-designer/getting-started-api-designer/README.adoc

//OpenShift API Management
:product-long-api-management: OpenShift API Management
:product-api-management: API Management
:product-version-api-management: 1
:service-url-api-management: https://console.redhat.com/application-services/api-management/

////
END GENERATED ATTRIBUTES
////

[id="chap-using-kafkacat"]
= Configuring and connecting Kcat with {product-long-kafka}
ifdef::context[:parent-context: {context}]
:context: using-kafkacat

// Purpose statement for the assembly
[role="_abstract"]
As a developer of applications and services, you can use https://github.com/edenhill/kcat[Kcat^] to test and debug your Kafka instances in {product-long-kafka}.
Kcat is a command-line utility for messaging in Apache Kafka 0.8 and later.
With Kcat, you can produce and consume messages directly from the command line. You can also list topic and partition information for your Kafka instances.

ifndef::community[]
NOTE: Kcat is an open source community tool. Kcat is not a part of {product-kafka} and is therefore not supported by Red Hat.
endif::[]

.Prerequisites
* You have a running Kafka instance in {product-kafka}.
* You have a command-line terminal application.
* https://adoptopenjdk.net/[JDK^] 11 or later is installed. (The latest LTS version of OpenJDK is recommended.)
* You've installed the latest supported version of https://github.com/edenhill/kcat[Kcat^] for your operating system. To verify your Kcat version, enter the following command:
+
[source]
----
$ kcat -V
----
+
You see output like the following example:
+
[source]
----
kcat - Apache Kafka producer and consumer tool
https://github.com/edenhill/kcat
Copyright (c) 2014-2021, Magnus Edenhill
Version 1.7.0 (librdkafka 1.3.0 builtin.features=gzip,snappy,ssl,sasl,regex,lz4,sasl_gssapi,sasl_plain,sasl_scram,plugins,zstd,sasl_oauthbearer)
----

// Condition out QS-only content so that it doesn't appear in docs.
// All QS anchor IDs must be in this alternate anchor ID format `[#anchor-id]` because the ascii splitter relies on the other format `[id="anchor-id"]` to generate module files.
ifdef::qs[]
[#description]
====
Learn how to use Kcat to interact with a Kafka instance in {product-long-kafka}.
====

[#introduction]
====
Welcome to the quick start for {product-long-kafka} with Kcat. In this quick start, you'll learn how to use https://github.com/edenhill/kcat[Kcat^] to produce and consume messages for your Kafka instances in {product-kafka}.
====
endif::[]

[id="proc-configuring-kafkacat_{context}"]
== Configuring Kcat to connect to a Kafka instance

[role="_abstract"]
To enable Kcat to access a Kafka instance, you must configure a connection. The configuration must include the bootstrap server endpoint for the Kafka instance and the credentials for your {product-long-kafka} service account.

You can either pass these values to the `kcat` command or use a configuration file. In this task, you set environment variable values and then pass them to the `kcat` command.

For more information about Kcat configuration options, see https://github.com/edenhill/kcat#configuration[Configuration^] in the Kcat documentation.

NOTE: Kcat does not yet fully support SASL/OAUTHBEARER authentication, which requires you to specify an access token in addition to service account credentials. Therefore, you use SASL/PLAIN authentication to connect to your Kafka instance with just service account credentials.

.Prerequisites
* You have the bootstrap server endpoint for your Kafka instance. To get the server endpoint, select your Kafka instance in the {product-long-kafka} web console, select the options icon (three vertical dots), and click *Connection*.
* You have the generated credentials for your service account. To reset the credentials, use the {service-accounts-url}[Service Accounts^] page.
* You've set permissions for your service account to access resources in the Kafka instance. To verify the current permissions, select your Kafka instance in the {product-long-kafka} web console and click the *Access* tab. To learn more about setting permissions, see {base-url}{access-mgmt-url-kafka}[Managing account access in {product-long-kafka}^].

.Procedure
* On the command line, set the Kafka instance bootstrap server and client credentials as environment variables to be used by Kcat. Replace the values with your own server and credential information.
+
.Setting environment variables for bootstrap server and client credentials
[source,subs="+quotes"]
----
$ export KAFKA_HOST=__<bootstrap_server>__
$ export RHOAS_SERVICE_ACCOUNT_CLIENT_ID=__<client_id>__
$ export RHOAS_SERVICE_ACCOUNT_CLIENT_SECRET=__<client_secret>__
----

[id="proc-producing-messages-kafkacat_{context}"]
== Producing messages in Kcat

[role="_abstract"]
You can use Kcat to produce messages to Kafka topics in several ways, such as reading them from standard input (`stdin`) on the command line, or from a file. In this task, you produce messages from input on the command line. For more examples of Kcat producer messaging, see https://github.com/edenhill/kcat#examples[Examples^] in the Kcat documentation.

.Prerequisites
* Kcat is installed.
* You have a running Kafka instance in {product-long-kafka}.
* You have a topic in your Kafka instance that you can use to produce and consume messages.
* You've set the Kafka bootstrap server endpoint and your service account credentials as environment variables.

.Procedure
. On the command line, enter the following command to start Kcat in producer mode. This mode enables you to produce messages to your Kafka topic. Replace `_<kafka-topic>_` with your own topic name.
+
--
.Starting Kcat in producer mode
[source,subs="+quotes"]
----
$ kcat -t _<kafka-topic>_ -b "$KAFKA_HOST" \
 -X security.protocol=SASL_SSL -X sasl.mechanisms=PLAIN \
 -X sasl.username="$RHOAS_SERVICE_ACCOUNT_CLIENT_ID" \
 -X sasl.password="$RHOAS_SERVICE_ACCOUNT_CLIENT_SECRET" -P
----

NOTE: Kcat does not yet fully support SASL/OAUTHBEARER authentication, which requires you to specify an access token in addition to service account credentials. Therefore, you use SASL/PLAIN authentication to connect to your Kafka instance with just service account credentials.

NOTE: A Kcat producer might behave differently based on the operating system. For example, on Mac operating systems, messages are sent by redirecting them to the Kcat binary in the format `echo "message" | kcat ...`.

--
. With Kcat running in producer mode, enter messages that you want to produce to the Kafka topic, as shown in the following example:
+
[source]
----
First message
Second message
Third message
----
. To finish producing the messages you entered, press `CTRL+D`.
. Keep the producer running so that you can use it again later, when you create a consumer.
+
NOTE: On Mac operating systems, pressing `CTRL+D` produces the messages you entered and then stops the producer. To use the producer again, you must restart it, as shown earlier in this task.

.Verification
ifdef::qs[]
* Is your producer still running without any errors in the terminal?
endif::[]
ifndef::qs[]
* Verify that your producer is still running without any errors in the terminal.
endif::[]

[id="proc-consuming-messages-kafkacat_{context}"]
== Consuming messages in Kcat

[role="_abstract"]
You can also use Kcat to consume messages from Kafka topics. In this task, you use Kcat to consume the messages that you previously produced to your topic.

.Prerequisites
* Kcat is installed.
* You have a running Kafka instance in {product-long-kafka}.
* You used Kcat to produce example messages to a topic in your Kafka instance.

.Procedure
. Open a second terminal window or tab, separate from your producer.
. On the command line, enter the following command to start Kcat in _consumer_ mode. This mode enables you to consume messages from your Kafka topic. Replace `_<kafka-topic>_` with the name of the topic that you previously produced messages to.
+
--
.Starting Kcat in consumer mode
[source,subs="+quotes"]
----
$ kcat -t _<kafka-topic>_ -b "$KAFKA_HOST" \
 -X security.protocol=SASL_SSL -X sasl.mechanisms=PLAIN \
 -X sasl.username="$RHOAS_SERVICE_ACCOUNT_CLIENT_ID" \
 -X sasl.password="$RHOAS_SERVICE_ACCOUNT_CLIENT_SECRET" -C
----

You see output that looks like the following example. The message values are the ones you previously sent using the producer.

[source,subs="+quotes"]
----
First message
Second message
Third message
% Reached end of topic _<kafka-topic>_ [0] at offset 3
----
--
. If your producer is still running in a separate terminal, continue entering messages in the producer terminal and observe the messages being consumed in the consumer terminal.

NOTE: You can also use the {product-kafka} web console to browse messages in the Kafka topic. For more information, see {base-url}{message-browsing-url-kafka}[Browsing messages in the {product-long-kafka} web console^].

.Verification
ifdef::qs[]
* Is your consumer running without any errors in the terminal?
* Did the consumer display the messages from your Kafka topic?
endif::[]
ifndef::qs[]
. Verify that your consumer is running without any errors in the terminal.
. Verify that the consumer displays the messages from your Kafka topic.
endif::[]

ifdef::qs[]
[#conclusion]
====
Congratulations! You successfully completed the {product-kafka} Kcat quick start, and are now ready to produce and consume messages in the service.
====
endif::[]

ifdef::parent-context[:context: {parent-context}]
ifndef::parent-context[:!context:]
