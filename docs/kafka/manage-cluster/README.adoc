////
START GENERATED ATTRIBUTES
WARNING: This content is generated by running npm --prefix .build run generate:attributes
////

//All OpenShift Application Services
:org-name: Application Services
:product-long-rhoas: OpenShift Application Services
:product-rhoas: OpenShift Application Services
:community:
:imagesdir: ./images
:property-file-name: app-services.properties
:samples-git-repo: https://github.com/redhat-developer/app-services-guides
:base-url: https://github.com/redhat-developer/app-services-guides/tree/main/docs/
:sso-token-url: https://sso.redhat.com/auth/realms/redhat-external/protocol/openid-connect/token
:cloud-console-url: https://console.redhat.com/
:service-accounts-url: https://console.redhat.com/application-services/service-accounts
:rh-sso-url: https://sso.redhat.com
:rh-customer-portal: Red Hat Customer Portal

//OpenShift
:openshift: OpenShift
:osd-name: OpenShift Dedicated
:osd-name-short: OpenShift Dedicated
:rosa-name: OpenShift Service for AWS
:rosa-name-short: OpenShift Service for AWS

//OpenShift Application Services CLI
:base-url-cli: https://github.com/redhat-developer/app-services-cli/tree/main/docs/
:command-ref-url-cli: commands
:installation-guide-url-cli: rhoas/rhoas-cli-installation/README.adoc
:service-contexts-url-cli: rhoas/rhoas-service-contexts/README.adoc

//OpenShift Streams for Apache Kafka
:product-long-kafka: OpenShift Streams for Apache Kafka
:product-kafka: Streams for Apache Kafka
:product-version-kafka: 1
:service-url-kafka: https://console.redhat.com/application-services/streams/
:getting-started-url-kafka: kafka/getting-started-kafka/README.adoc
:kafka-bin-scripts-url-kafka: kafka/kafka-bin-scripts-kafka/README.adoc
:kafkacat-url-kafka: kafka/kcat-kafka/README.adoc
:quarkus-url-kafka: kafka/quarkus-kafka/README.adoc
:nodejs-url-kafka: kafka/nodejs-kafka/README.adoc
:getting-started-rhoas-cli-url-kafka: kafka/rhoas-cli-getting-started-kafka/README.adoc
:topic-config-url-kafka: kafka/topic-configuration-kafka/README.adoc
:consumer-config-url-kafka: kafka/consumer-configuration-kafka/README.adoc
:access-mgmt-url-kafka: kafka/access-mgmt-kafka/README.adoc
:metrics-monitoring-url-kafka: kafka/metrics-monitoring-kafka/README.adoc
:service-binding-url-kafka: kafka/service-binding-kafka/README.adoc
:message-browsing-url-kafka: kafka/message-browsing-kafka/README.adoc

//OpenShift Service Registry
:product-long-registry: OpenShift Service Registry
:product-registry: Service Registry
:registry: Service Registry
:product-version-registry: 1
:service-url-registry: https://console.redhat.com/application-services/service-registry/
:getting-started-url-registry: registry/getting-started-registry/README.adoc
:quarkus-url-registry: registry/quarkus-registry/README.adoc
:getting-started-rhoas-cli-url-registry: registry/rhoas-cli-getting-started-registry/README.adoc
:access-mgmt-url-registry: registry/access-mgmt-registry/README.adoc
:content-rules-registry: https://access.redhat.com/documentation/en-us/red_hat_openshift_service_registry/1/guide/9b0fdf14-f0d6-4d7f-8637-3ac9e2069817[Supported Service Registry content and rules]
:service-binding-url-registry: registry/service-binding-registry/README.adoc

//OpenShift Connectors
:connectors: Connectors
:product-long-connectors: OpenShift Connectors
:product-connectors: Connectors
:product-version-connectors: 1
:service-url-connectors: https://console.redhat.com/application-services/connectors
:getting-started-url-connectors: connectors/getting-started-connectors/README.adoc
:getting-started-rhoas-cli-url-connectors: connectors/rhoas-cli-getting-started-connectors/README.adoc
:addon-url-connectors: https://access.redhat.com/documentation/en-us/openshift_connectors/1/guide/15a79de0-8827-4bf1-b445-8e3b3eef7b01


//OpenShift API Designer
:product-long-api-designer: OpenShift API Designer
:product-api-designer: API Designer
:product-version-api-designer: 1
:service-url-api-designer: https://console.redhat.com/application-services/api-designer/
:getting-started-url-api-designer: api-designer/getting-started-api-designer/README.adoc

//OpenShift API Management
:product-long-api-management: OpenShift API Management
:product-api-management: API Management
:product-version-api-management: 1
:service-url-api-management: https://console.redhat.com/application-services/api-management/

////
END GENERATED ATTRIBUTES
////

[id="chap-managing-cluster"]
= Managing {product-long-kafka} on a ROSA cluster
ifdef::context[:parent-context: {context}]
:context: deploying-cluster

// Purpose statement for the assembly
[role="_abstract"]

As an organization administrator, you can deploy {product-long-kafka} within your own controlled environment on your own ROSA cluster.

//Additional line break to resolve mod docs generation error.

[id="proc-installing-on-your-rosa-cluster_{context}"]
== Installing {product-kafka} on your ROSA cluster

You must install {product-long-kafka} on your {rosa-name} ROSA cluster before users in your organization can create Kafka resources. Use the {product-long-rhoas} `rhoas` command-line interface (CLI) to register your (ROSA) cluster.  Registering your ROSA cluster allows {product-kafka} to install certain necessary add-ons to your cluster so users can provision their Kafka instances.

.Prerequisites

* You have a Red Hat account.
* You are an organization administrator.
* You've installed the latest version of the `rhoas` CLI (see {base-url}{installation-guide-url-cli}[Installing and configuring the rhoas CLI^]).
* You have a supported version of {openshift} and have created a ROSA cluster. If you have configured bring-your-own-key (BYOK) encryption in your ROSA cluster, {product-long-kafka} automatically encrypts volumes using your key. If you have not configured BYOK, {product-kafka} uses a platform owned key instead. For more information see https://docs.openshift.com/rosa/rosa_install_access_delete_clusters/rosa-sts-creating-a-cluster-with-customizations.html[Creating a ROSA cluster with STS using customizations^].

.Procedure

. In a terminal, log in to `rhoas`.
+
--
[source,shell]
----
$ rhoas login
----

Your web browser opens the {rh-sso-url}[Red Hat Single Sign-On page^].
--

. Enter your credentials to log in to your Red Hat account.
+
--
Welcome pages in the browser notify you that you're logged in to `rhoas` successfully.

In your terminal, the `rhoas login` command indicates that you're logged in.
--
. In your terminal, register your ROSA cluster using the `openshift-cluster (oc) register-cluster` command.
+
--
[source,shell]
----
$ rhoas kafka oc register-cluster
----

This command installs the following add-ons to the cluster:

* Managed Kafka kas-fleetshard Operator: Required for provisioning and managing instances of Apache Kafka on your {openshift} cluster.
* Managed Kafka Operator: Required to manage Apache Kafka clusters and related components on your {openshift} cluster.
* Observability Operator: Required for metrics collection on the Kafka instance. Unlike the previous two, this add-on is displayed on the *Projects* page instead of the *Add-ons* page of the https://console.redhat.com/openshift[OpenShift Cluster Manager Hybrid Cloud Console^].
--
+
[NOTE]
--
These add-ons are required by and managed by {product-kafka} only and must not be adapted or changed in any way.
--
+
. The CLI lists the available {openshift} clusters in your organization  and prompts you to select a ready cluster to register. Use the arrows on your keyboard to select the required cluster.
. The CLI prompts you to create a machine pool with a specified node count. The required node count is calculated by identifying the number of requested Kafka streaming units and multiplying by three:
+
----
required_node_count = requested_Kafka_streaming_units × 3
----
+
For example, a Kafka instance of 2 streaming units requires a machine pool of 6 nodes. A streaming unit determines the default maximum capacity of a Kafka instance. An instance with a larger size can handle higher loads and process more events, has more storage, and can handle more clients and connections.
+
For more information on streaming units and for pricing details, see https://www.redhat.com/en/technologies/cloud-computing/openshift/openshift-streams-for-apache-kafka/pricing[Pricing for Red Hat OpenShift Streams for Apache Kafka^].
+
Enter `6` as the required node count to create a machine pool with 6 nodes called `kafka-standard`.
+
[NOTE]
--
This kafka-standard machine pool is for use with {product-kafka} only. Do not assign your own production workloads to run within it.
--
. Enter `y` to confirm you want your Kafka instances to be accessible through a public network.

.Verification

. Verify the registration is successful by logging in to the https://console.redhat.com/openshift[OpenShift Cluster Manager Hybrid Cloud Console^], clicking *Clusters*, and clicking the name of your cluster.
. On your cluster page, click the *Machine pools* tab.
.. Expand *kafka-standard* to view more details of the newly created machine pool including the labels and taints required by {product-kafka} that have automatically been included as part of the registration process.
. Click the *Add-ons* tab.
+
On the *Add-ons* page, an installing icon is displayed, indicating that the services have begun installing. A green check mark is displayed in the service option when the installation is complete. You might have to refresh your browser to see the installation status.
. (Optional) In the terminal, enter the list command to see the status of the cluster.
+
--
[source,shell]
----
$ rhoas kafka oc list
----
--
+
During the add-on installation process, the cluster status displays as `waiting for kas-fleet-shard operator` for example. A `ready` status indicates the cluster is ready for use.

[id="proc-uninstalling-from-your-rosa-cluster_{context}"]
== Uninstalling {product-kafka} from your ROSA cluster

[role="_abstract"]
You can uninstall {product-long-kafka} from your ROSA cluster using the `rhoas kafka oc deregister-cluster` command. This command removes all Kafka instances from the cluster first, unregisters the cluster from {product-kafka}, and also deletes the `kafka-standard` machine pool that was created during the registration process.

.Prerequisites

* You're logged in to the `rhoas` CLI.
* You have registered a ROSA cluster.
* You are an organization administrator.

.Procedure

. In the terminal, view your registered clusters.
+
--
[source,shell]
----
$ rhoas kafka oc list
----
--
+
The CLI lists the registered clusters in your organization.
. View your Kafka instances.
+
--
[source,shell]
----
$ rhoas kafka list
----
--
+
. Unregister the cluster.
+
--
[source,shell]
----
$ rhoas kafka oc deregister-cluster
----
--
+
. The CLI prompts you to select a cluster to unregister. Use the arrows on your keyboard to select the required cluster.
+
. You must remove all Kafka instances from the ROSA cluster in order to unregister the cluster. The CLI asks you to confirm the name of the Kafka instance you want to delete. Confirm you want to delete each Kafka instance by entering the name of each one.
+
The terminal displays a message confirming that all Kafka instances and add-ons have been deleted.

.Verification

. Verify that the Kafka instances are no longer listed on the *Kafka Instances* page of the {product-kafka} {service-url-kafka}[web console^].
. Navigate to the *Clusters* page of the https://console.redhat.com/openshift[OpenShift Cluster Manager Hybrid Cloud Console^].
.. Click the *Add-ons* tab.
+
Verify that an uninstalling state icon is present on the service options you deleted.

ifdef::parent-context[:context: {parent-context}]
ifndef::parent-context[:!context:]
