////
START GENERATED ATTRIBUTES
WARNING: This content is generated by running npm --prefix .build run generate:attributes
////

//OpenShift Application Services
:org-name: Application Services
:product-long-rhoas: OpenShift Application Services
:community:
:imagesdir: ./images
:property-file-name: app-services.properties
:samples-git-repo: https://github.com/redhat-developer/app-services-guides
:base-url: https://github.com/redhat-developer/app-services-guides/tree/main/docs/

//OpenShift Application Services CLI
:rhoas-cli-base-url: https://github.com/redhat-developer/app-services-cli/tree/main/docs/
:rhoas-cli-ref-url: commands
:rhoas-cli-installation-url: rhoas/rhoas-cli-installation/README.adoc

//OpenShift Streams for Apache Kafka
:product-long-kafka: OpenShift Streams for Apache Kafka
:product-kafka: Streams for Apache Kafka
:product-version-kafka: 1
:service-url-kafka: https://console.redhat.com/application-services/streams/
:getting-started-url-kafka: kafka/getting-started-kafka/README.adoc
:kafka-bin-scripts-url-kafka: kafka/kafka-bin-scripts-kafka/README.adoc
:kafkacat-url-kafka: kafka/kcat-kafka/README.adoc
:quarkus-url-kafka: kafka/quarkus-kafka/README.adoc
:nodejs-url-kafka: kafka/nodejs-kafka/README.adoc
:rhoas-cli-getting-started-url-kafka: kafka/rhoas-cli-getting-started-kafka/README.adoc
:topic-config-url-kafka: kafka/topic-configuration-kafka/README.adoc
:consumer-config-url-kafka: kafka/consumer-configuration-kafka/README.adoc
:access-mgmt-url-kafka: kafka/access-mgmt-kafka/README.adoc
:metrics-monitoring-url-kafka: kafka/metrics-monitoring-kafka/README.adoc
:service-binding-url-kafka: kafka/service-binding-kafka/README.adoc

//OpenShift Service Registry
:product-long-registry: OpenShift Service Registry
:product-registry: Service Registry
:registry: Service Registry
:product-version-registry: 1
:service-url-registry: https://console.redhat.com/application-services/service-registry/
:getting-started-url-registry: registry/getting-started-registry/README.adoc
:quarkus-url-registry: registry/quarkus-registry/README.adoc
:rhoas-cli-getting-started-url-registry: registry/rhoas-cli-getting-started-registry/README.adoc
:access-mgmt-url-registry: registry/access-mgmt-registry/README.adoc
:content-rules-registry: https://access.redhat.com/documentation/en-us/red_hat_openshift_service_registry/1/guide/9b0fdf14-f0d6-4d7f-8637-3ac9e2069817[Supported Service Registry content and rules]
:service-binding-url-registry: registry/service-binding-registry/README.adoc

//OpenShift Connectors
:product-long-connectors: OpenShift Connectors
:service-url-connectors: https://console.redhat.com/application-services/connectors
////
END GENERATED ATTRIBUTES
////

[id="chap-using-quarkus"]
= Using Quarkus applications with Kafka instances in {product-long-kafka}
ifdef::context[:parent-context: {context}]
:context: using-quarkus

// Purpose statement for the assembly
[role="_abstract"]
As a developer of applications and services, you can connect Quarkus applications to Kafka instances in {product-long-kafka}. https://quarkus.io/[Quarkus^] is a Kubernetes-native Java framework made for Java virtual machines (JVMs) and native compilation, and optimized for serverless, cloud, and Kubernetes environments. Quarkus is designed to work with popular Java standards, frameworks, and libraries like Eclipse MicroProfile and Spring, as well as Apache Kafka, RESTEasy (JAX-RS), Hibernate ORM (JPA), Infinispan, Camel, and many more.

.Prerequisites
ifndef::community[]
* You have a Red Hat account.
endif::[]
* You have a running Kafka instance in {product-kafka}.
* https://github.com/git-guides/[Git^] is installed.
* You have an IDE such as https://www.jetbrains.com/idea/download/[IntelliJ IDEA^], https://www.eclipse.org/downloads/[Eclipse^], or https://code.visualstudio.com/Download[VSCode^].
* https://adoptopenjdk.net/[JDK^] 11 or later is installed. (The latest LTS version of OpenJDK is recommended.)
* https://maven.apache.org/[Apache Maven^] 3.6.2 or later is installed.

// Condition out QS-only content so that it doesn't appear in docs.
// All QS anchor IDs must be in this alternate anchor ID format `[#anchor-id]` because the ascii splitter relies on the other format `[id="anchor-id"]` to generate module files.
ifdef::qs[]
[#description]
Learn how to use Quarkus applications to produce messages to and consume messages from a Kafka instance in {product-long-kafka}.

[#introduction]
Welcome to the quick start for {product-long-kafka} with Quarkus. In this quick start, you'll learn how to use https://quarkus.io/[Quarkus^] to produce messages to and consume messages from your Kafka instances in {product-kafka}.
endif::[]

[id="proc-importing-quarkus-sample-code_{context}"]
== Importing the Quarkus sample code

[role="_abstract"]
For this quick start, you'll use the Quarkus sample code from the {product-kafka} {samples-git-repo}[Guides and Samples^] repository in GitHub. After you understand the concepts and tasks in this quick start, you can use your own Quarkus applications with {product-kafka} in the same way.

.Procedure
. On the command line, clone the {product-kafka} {samples-git-repo}[Guides and Samples^] repository from GitHub.
+
.Cloning the guides and samples repository
[source,subs="+attributes"]
----
git clone {samples-git-repo} app-services-guides
----
. In your IDE, open the `code-examples/quarkus-kafka-quickstart` directory from the repository that you cloned.

ifdef::qs[]
.Verification
* Is the Quarkus example application accessible in your IDE?
endif::[]

[id="proc-configuring-quarkus_{context}"]
== Configuring the Quarkus example application to connect to a Kafka instance

[role="_abstract"]
To enable your Quarkus application to access a Kafka instance, configure the connection using the bootstrap server endpoint, the generated credentials for your {product-kafka} service account, and the SASL/OAUTHBEARER token endpoint for the Kafka instance. For Quarkus, you can configure connection information by using the `application.properties` configuration file. The example in this task sets environment variables and then references them in the  `application.properties` file.

Quarkus applications use https://github.com/eclipse/microprofile-reactive-messaging[MicroProfile Reactive Messaging^] to produce messages to and consume messages from your Kafka instances in {product-kafka}. For more information about Quarkus configuration options for Kafka and Reactive Messaging, see https://quarkus.io/guides/kafka[Using Apache Kafka with Reactive Messaging^] in the Quarkus documentation.

.Prerequisites
ifndef::qs[]
* You have the bootstrap server endpoint and the SASL/OAUTHBEARER token endpoint for the Kafka instance. To relocate the server endpoint and the SASL/OAUTHBEARER token endpoint, select your Kafka instance in the {product-kafka} web console, select the options menu (three vertical dots), and click *Connection*.
* You have the generated credentials for your service account. To regenerate the credentials, use the *Service Accounts* page in the {product-kafka} web console to find your service account and update the credentials.
* You've set the permissions for your service account to access the Kafka instance resources. To verify the current permissions, select your Kafka instance in the {product-kafka} web console and use the *Access* page to find your service account permission settings.
endif::[]

.Procedure
. On the command line, set the Kafka instance bootstrap server and client credentials as environment variables to be used by Quarkus or other applications. Replace the values with your own server and credential information.
+
--
ifdef::qs[]
The `<bootstrap_server>` is the bootstrap server endpoint for your Kafka instance. The `<oauth_token_endpoint_uri>` is the SASL/OAUTHBEARER token endpoint for the Kafka instance. The `<client_id>` and `<client_secret>` are the generated credentials for your service account. You copied this information previously for the Kafka instance in {product-kafka} by selecting the options menu (three vertical dots) and clicking *Connection*.
endif::[]

.Setting environment variables for server and credentials
[source,subs="+quotes"]
----
$ export KAFKA_URL=__<bootstrap_server>__
$ export RHOAS_CLIENT_ID=__<client_id>__
$ export RHOAS_CLIENT_SECRET=__<client_secret>__
$ export RHOAS_OAUTH_TOKEN_URL=__<oauth_token_endpoint_uri>__
----
--
. In the Quarkus example application, review the `src/main/resources/application.properties` file to understand how the environment variables you set in the previous step are used in your application. This example uses the `dev` configuration profile in the `application.properties` file.

ifdef::qs[]
.Verification
* Did you set environment variables for the Kafka instance?
endif::[]

[id="proc-create-prices-topic_{context}"]
== Creating the prices Kafka topic in {product-kafka}

[role="_abstract"]
For this quick start, the Kafka topic that the Quarkus example application references is called `prices`. You need to create this topic in {product-kafka} so that the Quarkus application can interact with it.

.Prerequisites
* You've created a Kafka instance in {product-kafka} and the instance is in *Ready* state.

.Procedure
. In the {product-kafka} web console, go to *Streams for Apache Kafka* > *Kafka Instances* and click the name of the Kafka instance that you want to add a topic to.
. Select the *Topics* tab, click *Create topic*, and follow the guided steps to define the topic details. Click *Next* to complete each step and click *Finish* to complete the setup.
+
[.screencapture]
.Guided steps to define topic details
image::sak-create-topic.png[Image of wizard to create a topic]

* *Topic name*: Enter `prices` as the topic name.
* *Partitions*: Set the number of partitions for this topic. This example sets the partition to `1` for a single partition. Partitions are distinct lists of messages within a topic and enable parts of a topic to be distributed over multiple brokers in the cluster. A topic can contain one or more partitions, enabling producer and consumer loads to be scaled.
* *Message retention*: Set the message retention time and size to the relevant value and increment. This example sets the retention time to `A week` and the retention size to `Unlimited`. Message retention time is the amount of time that messages are retained in a topic before they are deleted or compacted, depending on the cleanup policy. Retention size is the maximum total size of all log segments in a partition before they are deleted or compacted.
* *Replicas*: For this release of {product-kafka}, the replicas are preconfigured. The number of partition replicas for the topic is set to `3` and the minimum number of follower replicas that must be in sync with a partition leader is set to `2`. Replicas are copies of partitions in a topic. Partition replicas are distributed over multiple brokers in the cluster to ensure topic availability if a broker fails. When a follower replica is in sync with a partition leader, the follower replica can become the new partition leader if needed.
+
After you complete the topic setup, the new Kafka topic is listed in the topics table. You can now run the Quarkus application to start producing and consuming messages to and from this topic.

.Verification
ifdef::qs[]
* Is the new Kafka topic `prices` listed in the topics table?
endif::[]
ifndef::qs[]
* Verify that the new Kafka topic `prices` is listed in the topics table.
endif::[]

[id="proc-running-quarkus-example-application_{context}"]
== Running the Quarkus example application

[role="_abstract"]
After you configure your Quarkus application to connect to a Kafka instance and you create the Kafka topic, you can run the Quarkus application to start producing and consuming messages to and from the topic.

The Quarkus example application in this quick start has three application-scoped Java classes:

* One class generates a random number between 0 and 100 and produces it to a Kafka topic.
* Another class consumes the number from the Kafka topic.
* A final class exposes the number as a REST UI (using Server Sent events).

.Prerequisites
* You've configured the Quarkus example application to connect to the Kafka instance.
* You've created the `prices` example Kafka topic.

.Procedure
. On the command line, navigate to the `code-examples/quarkus-kafka-quickstart` directory that you imported and run the Quarkus example application in developer mode.
+
.Running the Quarkus example application
[source]
----
$ cd ~/code-examples/quarkus-kafka-quickstart
$ ./mvnw quarkus:dev
----
. After the application is running, in a web browser, go to http://localhost:8080/prices.html[^] and verify that the `Last price` is updated.
+
If the Quarkus application fails to run, review the error log in the terminal and address any problems. Also review the steps in this quick start to ensure that the Quarkus application and Kafka topic are configured correctly.

ifdef::qs[]
.Verification
* Did the Quarkus example application run without any errors?
* At http://localhost:8080/prices.html[^], is the `Last price` updated?
endif::[]

ifdef::qs[]
[#conclusion]
Congratulations! You successfully completed the {product-kafka} Quarkus quick start, and are now ready to use your own Quarkus applications with {product-kafka}.
endif::[]

ifdef::parent-context[:context: {parent-context}]
ifndef::parent-context[:!context:]
