////
START GENERATED ATTRIBUTES
WARNING: This content is generated by running npm --prefix .build run generate:attributes
////

//All OpenShift Application Services
:org-name: Application Services
:product-long-rhoas: OpenShift Application Services
:community:
:imagesdir: ./images
:property-file-name: app-services.properties
:samples-git-repo: https://github.com/redhat-developer/app-services-guides
:base-url: https://github.com/redhat-developer/app-services-guides/tree/main/docs/
:sso-token-url: https://sso.redhat.com/auth/realms/redhat-external/protocol/openid-connect/token
:cloud-console-url: https://console.redhat.com/
:service-accounts-url: https://console.redhat.com/application-services/service-accounts

//OpenShift
:openshift: OpenShift
:osd-name: OpenShift Dedicated
:osd-name-short: OpenShift Dedicated
:rosa-name: OpenShift Service for AWS
:rosa-name-short: OpenShift Service for AWS

//OpenShift Application Services CLI
:base-url-cli: https://github.com/redhat-developer/app-services-cli/tree/main/docs/
:command-ref-url-cli: commands
:installation-guide-url-cli: rhoas/rhoas-cli-installation/README.adoc
:service-contexts-url-cli: rhoas/rhoas-service-contexts/README.adoc

//OpenShift Streams for Apache Kafka
:product-long-kafka: OpenShift Streams for Apache Kafka
:product-kafka: Streams for Apache Kafka
:product-version-kafka: 1
:service-url-kafka: https://console.redhat.com/application-services/streams/
:getting-started-url-kafka: kafka/getting-started-kafka/README.adoc
:kafka-bin-scripts-url-kafka: kafka/kafka-bin-scripts-kafka/README.adoc
:kafkacat-url-kafka: kafka/kcat-kafka/README.adoc
:quarkus-url-kafka: kafka/quarkus-kafka/README.adoc
:nodejs-url-kafka: kafka/nodejs-kafka/README.adoc
:getting-started-rhoas-cli-url-kafka: kafka/rhoas-cli-getting-started-kafka/README.adoc
:topic-config-url-kafka: kafka/topic-configuration-kafka/README.adoc
:consumer-config-url-kafka: kafka/consumer-configuration-kafka/README.adoc
:access-mgmt-url-kafka: kafka/access-mgmt-kafka/README.adoc
:metrics-monitoring-url-kafka: kafka/metrics-monitoring-kafka/README.adoc
:service-binding-url-kafka: kafka/service-binding-kafka/README.adoc
:message-browsing-url-kafka: kafka/message-browsing-kafka/README.adoc

//OpenShift Service Registry
:product-long-registry: OpenShift Service Registry
:product-registry: Service Registry
:registry: Service Registry
:product-version-registry: 1
:service-url-registry: https://console.redhat.com/application-services/service-registry/
:getting-started-url-registry: registry/getting-started-registry/README.adoc
:quarkus-url-registry: registry/quarkus-registry/README.adoc
:getting-started-rhoas-cli-url-registry: registry/rhoas-cli-getting-started-registry/README.adoc
:access-mgmt-url-registry: registry/access-mgmt-registry/README.adoc
:content-rules-registry: https://access.redhat.com/documentation/en-us/red_hat_openshift_service_registry/1/guide/9b0fdf14-f0d6-4d7f-8637-3ac9e2069817[Supported Service Registry content and rules]
:service-binding-url-registry: registry/service-binding-registry/README.adoc

//OpenShift Connectors
:connectors: Connectors
:product-long-connectors: OpenShift Connectors
:product-connectors: Connectors
:product-version-connectors: 1
:service-url-connectors: https://console.redhat.com/application-services/connectors
:getting-started-url-connectors: connectors/getting-started-connectors/README.adoc
:getting-started-rhoas-cli-url-connectors: connectors/rhoas-cli-getting-started-connectors/README.adoc

//OpenShift API Designer
:product-long-api-designer: OpenShift API Designer
:product-api-designer: API Designer
:product-version-api-designer: 1
:service-url-api-designer: https://console.redhat.com/application-services/api-designer/
:getting-started-url-api-designer: api-designer/getting-started-api-designer/README.adoc

//OpenShift API Management
:product-long-api-management: OpenShift API Management
:product-api-management: API Management
:product-version-api-management: 1
:service-url-api-management: https://console.redhat.com/application-services/api-management/

////
END GENERATED ATTRIBUTES
////

[id="chap-using-quarkus"]
= Using Quarkus applications with Kafka instances in {product-long-kafka}
ifdef::context[:parent-context: {context}]
:context: using-quarkus

// Purpose statement for the assembly
[role="_abstract"]
As a developer of applications and services, you can connect Quarkus applications to Kafka instances in {product-long-kafka}. https://quarkus.io/[Quarkus^] is a Kubernetes-native Java framework made for Java virtual machines (JVMs) and native compilation, and optimized for serverless, cloud, and Kubernetes environments. Quarkus is designed to work with popular Java standards, frameworks, and libraries like Eclipse MicroProfile and Spring, as well as Apache Kafka, RESTEasy (JAX-RS), Hibernate ORM (JPA), Infinispan, Camel, and many more.

In this quick start, you'll use the {product-kafka} web console to collect connection information for a Kafka instance. Then you'll manually configure a connection from an example Quarkus application to the Kafka instance and start producing and consuming messages.

NOTE: When you've completed this quick start and understand the required connection configuration for a Kafka instance, you can use the {product-long-rhoas} command-line interface (CLI) to generate this type of configuration in a more automated way. To learn more, see {base-url}{service-contexts-url-cli}[Connecting client applications to {product-long-rhoas} using the rhoas CLI^].

.Prerequisites
ifndef::community[]
* You have a {org-name} account.
endif::[]
* You have a running Kafka instance in {product-kafka} (see {base-url}{getting-started-url-kafka}[Getting started with {product-long-kafka}^]).
* You have a command-line terminal application.
* https://github.com/git-guides/[Git^] is installed.
* You have an IDE such as https://www.jetbrains.com/idea/download/[IntelliJ IDEA^], https://www.eclipse.org/downloads/[Eclipse^], or https://code.visualstudio.com/Download[Visual Studio Code^].
* https://adoptopenjdk.net/[JDK^] 11 or later is installed. (The latest LTS version of OpenJDK is recommended.)

* https://maven.apache.org/[Apache Maven^] 3.6.2 (or a later Maven 3 release) is installed.

// Condition out QS-only content so that it doesn't appear in docs.
// All QS anchor IDs must be in this alternate anchor ID format `[#anchor-id]` because the ascii splitter relies on the other format `[id="anchor-id"]` to generate module files.
ifdef::qs[]
[#description]
====
Manually connect a Quarkus application to a Kafka instance and then produce and consume messages.
====

[#introduction]
====
Welcome to the quick start for {product-long-kafka} with Quarkus. In this quick start, you'll use the web console to collect connection information for a Kafka instance in {product-kafka}. Then you'll manually configure a connection from an example https://quarkus.io/[Quarkus^] application to the Kafka instance and start producing and consuming messages.
====
endif::[]

[id="proc-importing-quarkus-sample-code_{context}"]
== Importing the Quarkus sample code

[role="_abstract"]
For this quick start, you'll use the Quarkus sample code from the {product-long-kafka} {samples-git-repo}[Guides and Samples^] repository in GitHub.

.Procedure
. On the command line, clone the {product-kafka} {samples-git-repo}[Guides and Samples^] repository from GitHub.
+
[source,subs="+attributes"]
----
git clone {samples-git-repo} app-services-guides
----
. In your IDE, open the `code-examples/quarkus-kafka-quickstart` directory from the repository that you cloned.

ifdef::qs[]
.Verification
* Is the Quarkus example application accessible in your IDE?
endif::[]

[id="proc-configuring-quarkus_{context}"]
== Configuring the Quarkus example application to connect to a Kafka instance

[role="_abstract"]
To enable your Quarkus application to access a Kafka instance, configure the connection using the bootstrap server endpoint, the generated credentials for your {product-long-kafka} service account, and the SASL/OAUTHBEARER token endpoint for the Kafka instance. For Quarkus, you can configure connection information by using the `application.properties` configuration file. The example in this task sets environment variables and then references them in the  `application.properties` file.

Quarkus applications use https://github.com/eclipse/microprofile-reactive-messaging[MicroProfile Reactive Messaging^] to produce messages to and consume messages from your Kafka instances in {product-kafka}. For more information about Quarkus configuration options for Kafka and Reactive Messaging, see https://quarkus.io/guides/kafka[Using Apache Kafka with Reactive Messaging^] in the Quarkus documentation.

.Prerequisites
* You have the bootstrap server endpoint and the SASL/OAUTHBEARER token endpoint for the Kafka instance. To get the server endpoint and the SASL/OAUTHBEARER token endpoint, select your Kafka instance in the {product-kafka} {service-url-kafka}[web console^], select the options icon (three vertical dots), and click *Connection*.
* You have the generated credentials for your service account. To reset the credentials, use the {service-accounts-url}[Service Accounts^] page in the *Application Services* section of the Red Hat Hybrid Cloud Console.
* You've set the permissions for your service account to access the Kafka instance resources. To verify the current permissions, select your Kafka instance in the {product-kafka} web console and use the *Access* page to find your service account permission settings.


.Procedure
. On the command line, set the Kafka instance bootstrap server and client credentials as environment variables to be used by Quarkus or other applications. Replace the values with your own server and credential information.
+
--
ifdef::qs[]
The `<bootstrap_server>` is the bootstrap server endpoint for your Kafka instance. The `<oauth_token_endpoint_uri>` is the SASL/OAUTHBEARER token endpoint for the Kafka instance. The `<client_id>` and `<client_secret>` are the generated credentials for your service account. You copied this information previously for the Kafka instance in {product-kafka} by selecting the options menu (three vertical dots) and clicking *Connection*.
endif::[]

.Setting environment variables for server and credentials
[source,subs="+quotes"]
----
$ export KAFKA_HOST=__<bootstrap_server>__
$ export RHOAS_SERVICE_ACCOUNT_CLIENT_ID=__<client_id>__
$ export RHOAS_SERVICE_ACCOUNT_CLIENT_SECRET=__<client_secret>__
$ export RHOAS_SERVICE_ACCOUNT_OAUTH_TOKEN_URL=__<oauth_token_endpoint_uri>__
----
--
. In the Quarkus example application, review the `src/main/resources/application.properties` file to understand how the environment variables you set in the previous step are used in your application. This example uses the `dev` configuration profile in the `application.properties` file.

ifdef::qs[]
.Verification
* Did you set environment variables for the Kafka instance?
endif::[]

[id="proc-create-prices-topic_{context}"]
== Creating a Kafka topic in {product-kafka}

[role="_abstract"]
The Quarkus application in this quick start uses a Kafka topic called `prices` to produce and consume messages. In this task, you'll create the `prices` topic in your Kafka instance.

.Prerequisites
* You have a running Kafka instance in {product-long-kafka}.

.Procedure
. In the {product-kafka} {service-url-kafka}[web console^], select *Kafka Instances* and then click the name of the Kafka instance that you want to add a topic to.
. Select the *Topics* tab.
. Click *Create topic* and follow the guided steps to define the topic details.
+
--
You must specify the following topic properties:

* *Topic name*: For this quick start, enter `prices` as the topic name.
* *Partitions*: Set the number of partitions for the topic. For this quick start, set the value to `1`.
* *Message retention*: Set the message retention time and size. For this quick start, set the retention time to `A week` and the retention size to `Unlimited`.
* *Replicas*: For this release of {product-kafka}, the replica values are preconfigured. The number of partition replicas for the topic is set to `3` and the minimum number of follower replicas that must be in sync with a partition leader is set to `2`. For a trial Kafka instance, the number of replicas and the minimum in-sync replica factor are both set to `1`.

After you complete the setup, the new topic appears on the *Topics* page. You can now run the Quarkus application to start producing and consuming messages to and from this topic.
--

.Verification
ifdef::qs[]
* Is the `prices` topic listed on the *Topics* page?
endif::[]
ifndef::qs[]
* Verify that the `prices` topic is listed on the *Topics* page.
endif::[]

[id="proc-running-quarkus-example-application_{context}"]
== Running the Quarkus example application

[role="_abstract"]
After you configure your Quarkus application to connect to a Kafka instance and you create the Kafka topic, you can run the Quarkus application to start producing and consuming messages to and from the topic.

The Quarkus example application in this quick start has the following application-scoped Java classes:

* A class that generates a random number between 0 and 100 and produces it to a Kafka topic.
* Another class that consumes the number from the Kafka topic.
* A final class that exposes the number as a REST UI (using Server Sent events).

.Prerequisites
* You've configured the Quarkus example application to connect to the Kafka instance.
* You've created the `prices` topic.

.Procedure
. On the command line, navigate to the `code-examples/quarkus-kafka-quickstart` directory that you imported and run the Quarkus example application in developer mode.
+
.Running the Quarkus example application
[source]
----
$ cd ~/code-examples/quarkus-kafka-quickstart
$ ./mvnw quarkus:dev
----
. When the application is running, perform the following actions:
.. In a web browser, go to http://localhost:8080/prices.html[^].
.. Verify that the `Last price` value is updated.
+
NOTE: You can also use the {product-long-kafka} web console to browse messages in the Kafka topic. For more information, see {base-url}{message-browsing-url-kafka}[Browsing messages in the {product-long-kafka} web console^].
+
If the Quarkus application fails to run, review the error log in the terminal and address any problems. Also review the steps in this quick start to ensure that the Quarkus application and Kafka topic are configured correctly.

ifdef::qs[]
.Verification
* Did the Quarkus example application run without any errors?
* At http://localhost:8080/prices.html[^], is the `Last price` updated?
endif::[]

ifdef::qs[]
[#conclusion]
====
Congratulations! You successfully completed the {product-kafka} Quarkus quick start, and are now ready to connect your own Quarkus applications to {product-kafka}.
====
endif::[]

ifdef::parent-context[:context: {parent-context}]
ifndef::parent-context[:!context:]
