////
START GENERATED ATTRIBUTES
WARNING: This content is generated by running npm --prefix .build run generate:attributes
////

//All OpenShift Application Services
:org-name: Application Services
:product-long-rhoas: OpenShift Application Services
:product-rhoas: OpenShift Application Services
:community:
:imagesdir: ./images
:property-file-name: app-services.properties
:samples-git-repo: https://github.com/redhat-developer/app-services-guides
:base-url: https://github.com/redhat-developer/app-services-guides/tree/main/docs/
:sso-token-url: https://sso.redhat.com/auth/realms/redhat-external/protocol/openid-connect/token
:cloud-console-url: https://console.redhat.com/
:service-accounts-url: https://console.redhat.com/application-services/service-accounts
:rh-sso-url: https://sso.redhat.com
:rh-customer-portal: Red Hat Customer Portal

//OpenShift
:openshift: OpenShift
:osd-name: OpenShift Dedicated
:osd-name-short: OpenShift Dedicated
:rosa-name: OpenShift Service for AWS
:rosa-name-short: OpenShift Service for AWS

//OpenShift Application Services CLI
:base-url-cli: https://github.com/redhat-developer/app-services-cli/tree/main/docs/
:command-ref-url-cli: commands
:installation-guide-url-cli: rhoas/rhoas-cli-installation/README.adoc
:service-contexts-url-cli: rhoas/rhoas-service-contexts/README.adoc

//OpenShift Streams for Apache Kafka
:product-long-kafka: OpenShift Streams for Apache Kafka
:product-kafka: Streams for Apache Kafka
:product-version-kafka: 1
:service-url-kafka: https://console.redhat.com/application-services/streams/
:getting-started-url-kafka: kafka/getting-started-kafka/README.adoc
:kafka-bin-scripts-url-kafka: kafka/kafka-bin-scripts-kafka/README.adoc
:kafkacat-url-kafka: kafka/kcat-kafka/README.adoc
:quarkus-url-kafka: kafka/quarkus-kafka/README.adoc
:nodejs-url-kafka: kafka/nodejs-kafka/README.adoc
:getting-started-rhoas-cli-url-kafka: kafka/rhoas-cli-getting-started-kafka/README.adoc
:topic-config-url-kafka: kafka/topic-configuration-kafka/README.adoc
:consumer-config-url-kafka: kafka/consumer-configuration-kafka/README.adoc
:access-mgmt-url-kafka: kafka/access-mgmt-kafka/README.adoc
:metrics-monitoring-url-kafka: kafka/metrics-monitoring-kafka/README.adoc
:service-binding-url-kafka: kafka/service-binding-kafka/README.adoc
:message-browsing-url-kafka: kafka/message-browsing-kafka/README.adoc

//OpenShift Service Registry
:product-long-registry: OpenShift Service Registry
:product-registry: Service Registry
:registry: Service Registry
:product-version-registry: 1
:service-url-registry: https://console.redhat.com/application-services/service-registry/
:getting-started-url-registry: registry/getting-started-registry/README.adoc
:quarkus-url-registry: registry/quarkus-registry/README.adoc
:getting-started-rhoas-cli-url-registry: registry/rhoas-cli-getting-started-registry/README.adoc
:access-mgmt-url-registry: registry/access-mgmt-registry/README.adoc
:content-rules-registry: https://access.redhat.com/documentation/en-us/red_hat_openshift_service_registry/1/guide/9b0fdf14-f0d6-4d7f-8637-3ac9e2069817[Supported Service Registry content and rules]
:service-binding-url-registry: registry/service-binding-registry/README.adoc

//OpenShift Connectors
:connectors: Connectors
:product-long-connectors: OpenShift Connectors
:product-connectors: Connectors
:product-version-connectors: 1
:service-url-connectors: https://console.redhat.com/application-services/connectors
:getting-started-url-connectors: connectors/getting-started-connectors/README.adoc
:getting-started-rhoas-cli-url-connectors: connectors/rhoas-cli-getting-started-connectors/README.adoc
:addon-url-connectors: https://access.redhat.com/documentation/en-us/openshift_connectors/1/guide/15a79de0-8827-4bf1-b445-8e3b3eef7b01


//OpenShift API Designer
:product-long-api-designer: OpenShift API Designer
:product-api-designer: API Designer
:product-version-api-designer: 1
:service-url-api-designer: https://console.redhat.com/application-services/api-designer/
:getting-started-url-api-designer: api-designer/getting-started-api-designer/README.adoc

//OpenShift API Management
:product-long-api-management: OpenShift API Management
:product-api-management: API Management
:product-version-api-management: 1
:service-url-api-management: https://console.redhat.com/application-services/api-management/

////
END GENERATED ATTRIBUTES
////

[id="chap-configuring-consumer-groups"]
= Configuring consumer groups in {product-long-kafka}
ifdef::context[:parent-context: {context}]
:context: configuring-consumer-groups

// Purpose statement for the assembly
[role="_abstract"]
Consumer groups share large data streams generated by producers from a given topic in a Kafka instance.
Grouping consumers scales consumption to keep up with the rate of data produced.
Consumers within a group don’t read data from the same partition, but can read data from one or more partitions.

As a developer of applications and services, you can view all the consumer groups that have access to a particular Kafka instance in {product-long-kafka}.
If required, use the {product-kafka} web console to reset the offsets of consumer groups or delete consumer groups.

//Additional line break to resolve mod docs generation error
[id="con-consumer-group-list_{context}"]
== Listing consumer groups

[role="_abstract"]
In addition to the {product-kafka} {service-url-kafka}[web console^], you can use the `rhoas` command-line interface (CLI) or the Kafka `kafka-consumer-groups.sh` script to list consumer groups for your Kafka instance. The following subsections describe how to use these methods to list consumer groups.

ifndef::community[]
NOTE: The Kafka scripts are part of the open source community version of Apache Kafka. The scripts are not a part of {product-kafka} and are therefore not supported by Red Hat.
endif::[]


[id="con-consumer-group-list-using-CLI_{context}"]
=== Listing consumer groups using the CLI

To use the `rhoas` command-line interface (CLI) to list the consumer groups defined for your Kafka instance, enter the following command:


[source,subs="+quotes,+attributes"]
----
rhoas kafka consumer-group list
----

You now see output similar to the following example:

[source,subs="+quotes,+attributes"]
----
Consumer group ID    Active members    Partitions with lag    State
-------------------  ----------------  ---------------------  -------
consumergroup1                     2                     0    Empty
consumergroup2                     1                     0    Stable
----

[id="con-consumer-group-state_{context}"]
=== Consumer group states
Consumer group states displayed in the {product-kafka} web console and `rhoas` CLI can be one of the following values:

* *Empty*: The group exists but has no members.
* *Stable*: Rebalancing already occurred and consumers are consuming.
* *PreparingRebalance*: The group is waiting for consumers to join, which requires the reassignment of partitions, so the Kafka instance is currently rebalancing.
* *CompletingRebalance*: The Kafka instance is still rebalancing and reassigning partitions.
* *Dead*: The group is due to be removed from this Kafka instance soon. This deletion might be due to inactivity, or the group is being migrated to a different group coordinator.
* *Unknown*: The state is too new for it to be parsed.


[id="con-consumer-group-script_{context}"]
=== Connecting the Kafka consumer group script

[role="_abstract"]
You can list consumer groups using the `kafka-consumer-groups.sh` script. To use this or any other Kafka scripts, you need to specify the `--bootstrap-server` and `--command-config` flags to connect to your Kafka instance. To list consumer groups, enter the following command:

[source,subs="+quotes,+attributes"]
----
./kafka-consumer-groups.sh --bootstrap-server __<bootstrap_server>__ --command-config __<authentication_properties>__ --list
----

The `<bootstrap_server>` is the bootstrap server endpoint for your Kafka instance.
You copy this information for the Kafka instance in the {product-kafka} web console by selecting the options menu (three vertical dots) and clicking *Connection*.

Kafka scripts require SASL/PLAIN authentication.
Use an `<authentication_properties>` configuration file to configure the connection.
Include the client ID and client secret generated when creating a service account to access your Kafka instance.

.Authentication configuration properties
[source,subs="+quotes"]
----
sasl.mechanism=PLAIN
security.protocol=SASL_SSL

sasl.jaas.config=org.apache.kafka.common.security.plain.PlainLoginModule required \
  username="__<client_id>__" \
  password="__<client_secret>__" \;
----

[role="_additional-resources"]
.Additional resources
* {base-url}{getting-started-url-kafka}[Getting started with {product-long-kafka}] describes how to create a Kafka instance and service account, and how to set permissions in the instance for a service account.


[id="proc-adding-consumer-group-id_{context}"]
== Adding a consumer to a consumer group

[role="_abstract"]
To create a consumer group, you specify a consumer group ID in your consumer application. You do *not* create consumer groups in the {product-kafka} {service-url-kafka}[web console^], or using the CLI.

A group ID is required for a consumer to be able to join a consumer group.
The group ID is the name of the consumer group.
When you configure a consumer client application to access a Kafka instance, you assign a group ID to associate it with a consumer group.
All consumers with the same group ID belong to the consumer group with that ID.

Consumer groups connected to a Kafka instance are displayed in the {product-kafka} web console.

.Procedure
* Add the consumer group ID as a property to your consumer configuration. The group ID can't be null or empty.
+
--
.Example group ID property configuration for a consumer
[source,properties]
----
group.id=my-group-id
----

.Property attributes
[cols="25%,75%"]
|===

h|Type
|String

h|Default value
|None

h|Supported values
|Letters (Aa-Zz), numbers (0-9), underscores ( _ ), or hyphens ( - )
|===

If you're using Kafka scripts to consume messages, you can use the `kafka-console-consumer.sh` tool to create a group ID:
[source,subs="+quotes,+attributes"]
----
./kafka-console-consumer.sh --bootstrap-server __<bootstrap_server>__ --consumer.config __<authentication_properties>__ --topic test-topic --group my-consumer-group
----

The new consumer group is named `my-consumer-group`.

[NOTE]
====
If you add more consumers than the number of partitions in a consumer group, the additional consumers don't help throughput but they function as standby consumers that can replace any consumers that stop functioning. The fewer consumers you use in order to meet your throughput target, the more resources you save.
====

--

[role="_additional-resources"]
.Additional resources
* {base-url}{getting-started-url-kafka}[Getting started with {product-long-kafka}^]
* https://kafka.apache.org/documentation/#consumerconfigs[Consumer Configs^] in Kafka documentation

[id="proc-editing-consumer-group-properties_{context}"]
== Reviewing consumer group properties in {product-kafka}

[role="_abstract"]
Use the {product-kafka} {service-url-kafka}[web console^] to select a consumer group and review the consumer properties.
You can examine the consumer groups associated with a Kafka instance or a specific topic of the instance.

As an alternative to using the {product-kafka} web console, you can use the `rhoas` command-line interface (CLI) to return information about a consumer group, as shown in the following example command:

----
rhoas kafka consumer-group describe [flags]
----

For a list of consumer group commands that you can use with the CLI, see the {base-url-cli}{command-ref-url-cli}[CLI command reference (rhoas)^].

If you're using Kafka scripts, you can use the `kafka-consumer-groups.sh` tool to provide the same information:
[source,subs="+quotes,+attributes"]
----
./kafka-consumer-groups.sh --bootstrap-server __<bootstrap_server>__ --command-config __<authentication_properties>__ --describe --group my-consumer-group
----



.Prerequisites
* You have a running Kafka instance with at least one Kafka topic in {product-kafka} (see {base-url}{getting-started-url-kafka}[Getting started with {product-long-kafka}^]).
* Consumer client applications connected to the Kafka instance have a consumer group ID.

.Procedure
. On the {service-url-kafka}[Kafka Instances^] page of the {product-kafka} web console, click the name of the Kafka instance that contains the consumer groups that you want to review.
. Select the *Consumer groups* page.
. Select the options icon (three vertical dots) for the relevant consumer group and click *View partition offsets*.

NOTE: You can also view consumer groups for a specific topic. In your Kafka instance, select the *Topics* page and then click the name of a topic. Select the *Consumer groups* page. For a given consumer group, select the options icon (three vertical dots) and click *View partition offsets*.


[role="_additional-resources"]
.Additional resources
* {base-url}{getting-started-rhoas-cli-url-kafka}[Getting started with the rhoas CLI for OpenShift Streams for Apache Kafka^]
* {base-url-cli}{command-ref-url-cli}[CLI command reference (rhoas)^]

[id="ref-supported-consumer-group-properties_{context}"]
== Consumer group properties in {product-kafka}

[role="_abstract"]
The following consumer group properties are displayed in {product-long-kafka}.
Consumer group properties are used for monitoring in the {product-kafka} web console and are not editable.

=== Consumer groups

Consumer Group ID::
The consumer group ID is the unique identifier for the consumer group within the cluster. This is part of the consumer configuration for the application client.

Active Members::
Active members shows the number of consumers in the group that are assigned to a topic partition in the Kafka instance.
If you're viewing information about consumer groups for a topic, these are the active members for the topic.

Partitions with lag::
Partitions with lag shows the number of partitions where the assigned consumer has not caught up with the last message in the partition.
The lag reflects the position of the consumer offset in relation to the end of the partition log.

=== Consumer offset positions

When you click a consumer group, you see the details of each member.

Partition::
The partition number for the topic.

Client ID::
The unique ID of the client application used to identify active consumers.
If no client ID is shown, the partition is not currently being consumed.

Current offset::
The current offset number for the consumer in the partition log. This is the position of the consumer in the partition and the latest read position.

Log end offset::
The current offset number for the producer in the partition log. This is the end of the log and the latest write position.

Offset lag::
The difference (delta) between the consumer and producer offset positions in the log.

[id="con-reducing-consumer-lag_{context}"]
== Consumer lag indicators

[role="_abstract"]
Consumer lag for a given consumer group indicates the delay between the last message added in a partition and the message currently being picked up by that consumer.
The lag reflects the position of the consumer offset in relation to the end of the partition log.

When you're reviewing consumer group properties in the {product-kafka} {service-url-kafka}[web console^], look for the differences between *Current offset* and *Log end offset*.
The difference shows as the *Offset lag* value.

For applications that rely on the processing of (near) real-time data, it’s critical that consumer lag doesn't become too big.
Suppose a topic streams 100 messages per second.
A lag of 1000 messages between the producer offset (the topic partition head) and the last (current) offset that the consumer has read means a 10-second delay.
The offset lag shows that a gap is opening up between the write and read positions.

To reduce lag, you typically add new consumers to a group.
However, you can also increase the retention time for a message to remain in a topic.
Extending the retention of data in the log gives the consumer a chance to catch up before data is flushed from the message log.

For more information about increasing topic retention time, see {base-url}{topic-config-url-kafka}[Configuring topics in {product-kafka}^].

[role="_additional-resources"]
.Additional resources
* {base-url}{consumer-config-url-kafka}#ref-supported-consumer-group-properties_configuring-consumer-groups[Consumer group properties presented in {product-kafka}]
* {base-url}{getting-started-rhoas-cli-url-kafka}[Getting started with the rhoas CLI for OpenShift Streams for Apache Kafka^]
* {base-url}{topic-config-url-kafka}[Configuring topics in {product-kafka}^]


[id="proc-resetting-consumer-group-offset_{context}"]
== Resetting consumer group offset positions

[role="_abstract"]
Use the {product-kafka} {service-url-kafka}[web console^] to select consumer groups and reset partition offsets for a particular topic.
A reset changes the offset position from which consumers read from the message log of a topic partition.
To reset an offset position, the consumer group must have _NO MEMBERS_ connected to a topic.

Choose one of the following options for *New offset*:


* *absolute* resets to a specific offset in the message log.
* *latest* resets to the latest offset at the end of the message log.
* *earliest* resets to the earliest offset at the start of the message log.

[WARNING]
====
By resetting the offset position you risk clients skipping or duplicating messages.
====

As an alternative to using the {product-kafka} web console, you can use the `rhoas` command-line interface (CLI) to reset consumer group offsets, as shown in the following example command:

.Example CLI command to reset offsets for consumer groups
[source]
----
rhoas kafka consumer-group reset-offset --id my-consumer-group --offset earliest --topic topic1
----

The `reset-offset` CLI command has an additional reset option. You can use a timestamp value.

[source]
----
rhoas kafka consumer-group reset-offset --id my-consumer-group --offset timestamp --value "2021-06-23T09:07:21-07:00"
----

For a list of topic properties that you can update using the CLI, see the `rhoas kafka topic update` entry in the {base-url-cli}{command-ref-url-cli}[CLI command reference (rhoas)^].

If you're using Kafka scripts, you can use the `kafka-consumer-groups.sh` tool to reset offsets:
[source,subs="+quotes,+attributes"]
----
./kafka-consumer-groups.sh --bootstrap-server __<bootstrap_server>__ --command-config __<authentication_properties>__ --reset-offsets --group my-consumer-group --topic topic1 --to-latest
----

You can specify the reset for `--all-topics` or a single specified `--topic`.

.Prerequisites
* The consumer group you select must have no active members connected to the topic.
* Consumers in the consumer group must be shut down (not consuming partitions).

.Procedure
. On the {service-url-kafka}[Kafka Instances^] page of the {product-kafka} web console, click the name of the Kafka instance that contains the consumer group you're updating.
+
Alternatively, select a consumer group for a specific topic.
+
--
.. On the {service-url-kafka}[Kafka Instances^] page of the {product-kafka} web console, click the name of the Kafka instance that contains the topic.
.. On the *Topics* page, click the name of the topic.
--
. On the *Consumer groups* page, select the options icon (three vertical dots) for the relevant consumer group and click *Reset Offset*.
. Select a topic.
. Choose a new offset position from *Absolute*, *Latest*, or *Earliest*.
. Select one or more partitions to apply the offset reset.
. If you chose an absolute reset, enter the new custom offset number for the reset.
. Click *Reset offset* to finish.

[role="_additional-resources"]
.Additional resources
* {base-url}{getting-started-rhoas-cli-url-kafka}[Getting started with the rhoas CLI for OpenShift Streams for Apache Kafka^]
* {base-url-cli}{command-ref-url-cli}[CLI command reference (rhoas)^]

[id="proc-deleting-consumer-groups_{context}"]
== Deleting a consumer group

[role="_abstract"]
Use the {product-kafka} {service-url-kafka}[web console^] to delete consumer groups.
The consumer group must have no active members connected to a topic.
By deleting the consumer group, you remove the current state associated with the group.

As an alternative to using the {product-kafka} web console, you can use the `rhoas` command-line interface (CLI) to delete consumer groups, as shown in the following example command:

.Example CLI command to delete a consumer group
[source]
----
rhoas kafka consumer-group delete my-consumer-group
----

For a list of topic properties that you can update using the CLI, see the `rhoas kafka topic update` entry in the {base-url-cli}{command-ref-url-cli}[CLI command reference (rhoas)^].

If you're using Kafka scripts, you can use the `kafka-consumer-groups.sh` tool to delete consumer groups:
[source,subs="+quotes,+attributes"]
----
./kafka-consumer-groups.sh --bootstrap-server __<bootstrap_server>__ --command-config __<authentication_properties>__ --delete --group my-consumer-group
----

.Prerequisites
* The consumer group you select must have no active members.
* Consumers in the consumer group must be shut down (not consuming partitions).

.Procedure
. On the {service-url-kafka}[Kafka Instances^] page of the {product-kafka} web console, click the name of the Kafka instance that contains the consumer group you're updating.
+
Alternatively, select a consumer group for a specific topic.
+
--
.. On the {service-url-kafka}[Kafka Instances^] page of the {product-kafka} web console, click the name of the Kafka instance that contains the topic.
.. On the *Topics* page, click the name of the topic.
--
. On the *Consumer groups* page, select the options icon (three vertical dots) for the relevant consumer group and click *Delete*.
. Confirm the deletion by clicking *Delete*.

[role="_additional-resources"]
.Additional resources
* {base-url}{getting-started-rhoas-cli-url-kafka}[Getting started with the rhoas CLI for OpenShift Streams for Apache Kafka^]
* {base-url-cli}{command-ref-url-cli}[CLI command reference (rhoas)^]

ifdef::parent-context[:context: {parent-context}]
ifndef::parent-context[:!context:]
