////
START GENERATED ATTRIBUTES
WARNING: This content is generated by running npm --prefix .build run generate:attributes
////

//OpenShift Application Services
:org-name: Application Services
:product-long-rhoas: OpenShift Application Services
:community:
:imagesdir: ./images
:property-file-name: app-services.properties
:samples-git-repo: https://github.com/redhat-developer/app-services-guides
:base-url: https://github.com/redhat-developer/app-services-guides/tree/main/docs/

//OpenShift Application Services CLI
:rhoas-cli-base-url: https://github.com/redhat-developer/app-services-cli/tree/main/docs/
:rhoas-cli-ref-url: commands
:rhoas-cli-installation-url: rhoas/rhoas-cli-installation/README.adoc

//OpenShift Streams for Apache Kafka
:product-long-kafka: OpenShift Streams for Apache Kafka
:product-kafka: Streams for Apache Kafka
:product-version-kafka: 1
:service-url-kafka: https://console.redhat.com/application-services/streams/
:getting-started-url-kafka: kafka/getting-started-kafka/README.adoc
:kafka-bin-scripts-url-kafka: kafka/kafka-bin-scripts-kafka/README.adoc
:kafkacat-url-kafka: kafka/kcat-kafka/README.adoc
:quarkus-url-kafka: kafka/quarkus-kafka/README.adoc
:nodejs-url-kafka: kafka/nodejs-kafka/README.adoc
:rhoas-cli-getting-started-url-kafka: kafka/rhoas-cli-getting-started-kafka/README.adoc
:topic-config-url-kafka: kafka/topic-configuration-kafka/README.adoc
:consumer-config-url-kafka: kafka/consumer-configuration-kafka/README.adoc
:access-mgmt-url-kafka: kafka/access-mgmt-kafka/README.adoc
:metrics-monitoring-url-kafka: kafka/metrics-monitoring-kafka/README.adoc
:service-binding-url-kafka: kafka/service-binding-kafka/README.adoc

//OpenShift Service Registry
:product-long-registry: OpenShift Service Registry
:product-registry: Service Registry
:registry: Service Registry
:product-version-registry: 1
:service-url-registry: https://console.redhat.com/application-services/service-registry/
:getting-started-url-registry: registry/getting-started-registry/README.adoc
:quarkus-url-registry: registry/quarkus-registry/README.adoc
:rhoas-cli-getting-started-url-registry: registry/rhoas-cli-getting-started-registry/README.adoc
:access-mgmt-url-registry: registry/access-mgmt-registry/README.adoc

////
END GENERATED ATTRIBUTES
////

[id="chap-kafka-bin-scripts"]
= Configuring and connecting Kafka scripts with {product-long-kafka}
ifdef::context[:parent-context: {context}]
:context: using-kafka-bin-scripts

// Purpose statement for the assembly
[role="_abstract"]
As a developer of applications and services, you can use Kafka scripts to manage your Kafka instances in {product-long-kafka}.
The Kafka scripts are a set of shell scripts that are included with the https://kafka.apache.org/downloads[Apache Kafka distribution^].
With these scripts, you can produce and consume messages for your Kafka instances.

ifndef::community[]
NOTE: The Kafka scripts are part of the open source community version of Apache Kafka. The scripts are not a part of {product-kafka} and are therefore not supported by Red Hat.
endif::[]

When you download and extract the Apache Kafka distribution, the `bin/` directory (or the `bin\windows\` directory if you're using Windows) of the distribution contains a set of shell scripts that enable you to interact with your Kafka instance.
With the scripts, you can produce and consume messages using your Kafka instances. You can also perform various other operations against the Kafka APIs to administer topics, consumer groups, and other resources.

NOTE: The command examples in this quick start demonstrate how to use the Kafka scripts on Linux and macOS. If you're using Windows, use the Windows versions of the scripts. For example, instead of the `__<Kafka-distribution-dir>__/bin/kafka-console-producer.sh` script, use the `__<Kafka-distribution-dir>__\bin\windows\kafka-console-producer.bat` script.

.Prerequisites
ifndef::community[]
* You have a Red Hat account.
endif::[]
* You have a running Kafka instance in {product-kafka}.
* https://adoptopenjdk.net/[JDK^] 11 or later is installed. (The latest LTS version of OpenJDK is recommended.)
* You've downloaded the latest supported binary version of the https://kafka.apache.org/downloads[Apache Kafka distribution^]. You can check your version using the following command.
+
.Verifying Kafka scripts
[source]
----
$ ./kafka-console-producer.sh --version
3.0.0 (Commit:8cb0a5e9d3441962)
----

ifdef::qs[]
[#description]
Learn how to use Kafka scripts to interact with a Kafka instance in {product-long-kafka}.

[#introduction]
Welcome to the quick start for {product-long-kafka} with Kafka scripts. In this quick start, you'll learn how to use the Kafka scripts to produce and consume messages for your Kafka instances in {product-kafka}.
endif::[]

[id="proc-configuring-kafka-bin-scripts_{context}"]
== Configuring the Kafka scripts to connect to a Kafka instance

[role="_abstract"]
To enable the Kafka scripts to access a Kafka instance, you must configure the connection using the generated credentials for your {product-kafka} service account. For the Kafka scripts, you will create a configuration file that defines these values.

.Prerequisites
ifndef::qs[]
* You have the generated credentials for your service account. To regenerate the credentials, use the *Service Accounts* page in the {product-kafka} web console to find your service account and update the credentials.
* You've set the permissions for your service account to access the Kafka instance resources. To verify the current permissions, select your Kafka instance in the {product-kafka} web console and use the *Access* page to find your service account permission settings.
endif::[]

.Procedure

. In your Kafka distribution, navigate to the `config/` directory.

. Create a file called `{property-file-name}`.

. In the `{property-file-name}` file, set the SASL connection mechanism and the Kafka instance client credentials. Replace the values with your own credential information.
+
--
ifdef::qs[]
The `<client_id>` and `<client_secret>` are the generated credentials for your service account. You copied this information previously for the Kafka instance in {product-kafka} by selecting the options menu (three vertical dots), clicking *Connection*, and creating the service account.
endif::[]

.Setting server and credential values
[source,subs="+quotes"]
----
sasl.mechanism=PLAIN
security.protocol=SASL_SSL

sasl.jaas.config=org.apache.kafka.common.security.plain.PlainLoginModule required \
  username="__<client_id>__" \
  password="__<client_secret>__" ;
----

NOTE: {product-kafka} also supports the SASL/OAUTHBEARER mechanism for authentication, which is the recommended authentication mechanism to use. However, the Kafka scripts do not yet fully support OAUTHBEARER, so this example uses SASL/PLAIN.

--
. Save the file. You'll use this file in the next task to connect to your Kafka instance and produce messages.

[id="proc-producing-messages-kafka-bin-scripts_{context}"]
== Producing messages using Kafka scripts

[role="_abstract"]
You can use the `kafka-console-producer` script to produce messages to Kafka topics.

.Prerequisites

* You have a running Kafka instance in {product-kafka}.
ifndef::qs[]
* You have the bootstrap server endpoint for your Kafka instance. To relocate the server endpoint, select your Kafka instance in the {product-kafka} web console, select the options menu (three vertical dots), and click *Connection*.
* You've set the permissions for your service account to access the Kafka instance resources. To verify the current permissions, select your Kafka instance in the {product-kafka} web console and use the *Access* page to find your service account permission settings.
endif::[]
* You've created the `{property-file-name}` file to store your service account credentials.

.Procedure
. On the command line, from the `bin/` directory, enter the following command to create a Kafka topic.
+
--

ifdef::qs[]
The `<bootstrap_server>` is the bootstrap server endpoint for your Kafka instance. You copied this information previously for the Kafka instance in {product-kafka} by selecting the options menu (three vertical dots) and clicking *Connection*.
endif::[]

.Using the `kafka-topics` script to create a Kafka topic
[source,subs="+quotes,+attributes"]
----
$ ./kafka-topics.sh --create --topic my-other-topic --partitions 1 --replication-factor 3 --bootstrap-server __<bootstrap_server>__ --command-config ../config/{property-file-name}
Created topic my-other-topic.
----
--
+
The preceding example uses the `kafka-topics` script to create the `my-other-topic` Kafka topic with the default settings.

. Enter the following command to start the `kafka-console-producer` script.
+
--

.Starting the `kafka-console-producer` script
[source,subs="+quotes,+attributes"]
----
$ ./kafka-console-producer.sh --topic my-other-topic --bootstrap-server "__<bootstrap_server>__" --producer.config ../config/{property-file-name}
----
--
+
The preceding example uses the SASL/PLAIN authentication mechanism with the credentials that you saved in the `{property-file-name}` file. This example produces messages to the `my-other-topic` example topic that you created.

. With the `kafka-console-producer` script running, enter messages that you want to produce to the Kafka topic.
+
.Example messages to produce to the Kafka topic
+
[source]
----
>First message
>Second message
>Third message
----

. Keep the producer running to use later when you create a consumer.

.Verification
ifdef::qs[]
* Is the `kafka-console-producer` script still running without any errors in the terminal?
endif::[]
ifndef::qs[]
* Verify that the `kafka-console-producer` script is still running without any errors in the terminal.
endif::[]

[id="proc-consuming-messages-kafka-bin-scripts_{context}"]
== Consuming messages using Kafka scripts

[role="_abstract"]
You can use the `kafka-console-consumer` script to consume messages from Kafka topics. This example consumes the messages that you sent previously with the producer that you created with the `kafka-console-producer` script.

.Prerequisites

* You used the `kafka-console-producer` script to produce example messages to a topic.

.Procedure
. Open a second terminal window or tab, separate from the producer.

. On the command line, enter the following command to start the `kafka-console-consumer` script.
+
--

.Starting the `kafka-console-consumer` script

[source,subs="+quotes,+attributes"]
----
$ ./kafka-console-consumer.sh --topic my-other-topic --bootstrap-server "__<bootstrap_server>__" --from-beginning --consumer.config ../config/{property-file-name}
First message
Second message
Third message
----
--
The preceding example uses the SASL/PLAIN authentication mechanism with the credentials that you saved in the `{property-file-name}` file. This example consumes and displays the messages from the `my-other-topic` example topic.

. If your producer is still running in a separate terminal, continue entering messages in the producer terminal and observe the messages being consumed in the consumer terminal.

.Verification
ifdef::qs[]
* Is the `kafka-console-consumer` script running without any errors in the terminal?
* Did the `kafka-console-consumer` script display the messages from the `my-other-topic` example topic?
endif::[]
ifndef::qs[]
. Verify that the `kafka-console-consumer` script is running without any errors in the terminal.
. Verify that the `kafka-console-consumer` script displays the messages from the `my-other-topic` example topic.
endif::[]


ifdef::qs[]
[#conclusion]
Congratulations! You successfully completed the {product-kafka} Kafka scripts quick start, and are now ready to produce and consume messages in the service.
endif::[]

ifdef::parent-context[:context: {parent-context}]
ifndef::parent-context[:!context:]
