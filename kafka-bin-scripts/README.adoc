////
START GENERATED ATTRIBUTES
WARNING: This content is generated by running npm --prefix .build run generate:attributes
////


:community:
:imagesdir: ./images
:product-long: bf2fc6cc711aee1a0c2a
:product: bf2
// Placeholder URL, when we get a HOST UI for the service we can put it here properly
:service_url: https://localhost:1234/
:property-file-name: bf2.properties

:signup_link: https://localhost:1234/
// Other upstream project names
:quarkus: Quarkus
:quarkus_url: https://quarkus.io/
:samples_git_repo: https://github.com/bf2fc6cc711aee1a0c2a/guides

////
END GENERATED ATTRIBUTES
////

[id="chap-kafka-bin-scripts"]
= Using Kafka bin scripts with {product-long}
ifdef::context[:parent-context: {context}]
:context: using-kafka-bin-scripts

// Purpose statement for the assembly
[role="_abstract"]
As a developer of applications and services, you can use the Kafka bin scripts to manage your Kafka instances in {product-long}.
The Kafka bin scripts are a set of shell scripts that are included with the Apache Kafka distribution.
With these bin scripts, you can produce and consume messages for your Kafka instances.

.Prerequisites
ifndef::community[]
* You have a Red Hat account.
endif::[]
* You have a running Kafka instance in {product}.

ifdef::qs[]
[#description]
Learn how to use Kafka bin scripts to interact with a Kafka instance in {product-long}.

[#introduction]
Welcome to the {product-long} Kafka bin scripts quick start. In this quick start, you'll learn how to use the Kafka bin scripts to produce and consume messages for your Kafka instances in {product}.
endif::[]

[id="proc-downloading-kafka-bin-scripts_{context}"]
== Downloading the Kafka bin scripts

The Kafka bin scripts are the binary scripts that are provided in the https://kafka.apache.org/downloads[Apache Kafka distribution]. When you extract the Apache Kafka distribution, the `bin/` directory of the distribution contains a set of shell scripts that enable you to interact with your Kafka instance. With the bin scripts, you can produce and consume messages, and perform various operations against the Kafka APIs to administer topics, consumer groups, and other resources.

ifndef::community[]
NOTE: The Kafka bin scripts are part of the open source community version of Apache Kafka. The bin scripts are not a part of {product} and are therefore not supported by Red Hat.
endif::[]

.Procedure
. In a web browser, go to the Kafka https://kafka.apache.org/downloads[Download] page and download the latest version of Apache Kafka.
. Extract the downloaded archive and navigate to the `bin/` directory.
+
--
This example extracts the archive and then changes to the `bin/` directory.

.Extracting the Kafka archive and navigating to the `bin/` directory
[source]
----
$ tar -xzf kafka_2.13-2.7.0.tgz
$ cd kafka_2.13-2.7.0/bin
----

The `bin/` directory contains the Kafka bin scripts.
--

. Review the scripts in the `bin/` directory and verify that you have the `kafka-console-producer` and `kafka-console-consumer` scripts.

. Check the version number of the `kafka-console-producer` script to verify that the scripts were downloaded correctly.
+
.Verifying Kafka bin scripts
[source]
----
$ ./kafka-console-producer.sh --version
2.7.0 (Commit:448719dc99a19793)
----

.Verification
. Were the Kafka bin scripts installed successfully?

[id="proc-configuring-kafka-bin-scripts_{context}"]
== Configuring the Kafka bin scripts to connect to a Kafka instance

To enable the Kafka bin scripts to access a Kafka instance, you must configure the connection using the generated credentials for your {product} service account. For the Kafka bin scripts, you will create a configuration file that defines these values.

.Prerequisites

* You have the generated credentials for your service account. You retrieved this information previously for the Kafka instance in {product} by selecting the options menu (three vertical dots), clicking *Connect to instance*, and generating the service account.

.Procedure

. In your Kafka distribution, navigate to the `config/` directory.

. Create a file called `{property-file-name}`.

. In the `{property-file-name}` file, add the following content to set the Kafka instance client credentials. Replace the values with your own server and credential information.
+
.Setting server and credential values
[source,subs="+quotes"]
----
sasl.mechanism=PLAIN
security.protocol=SASL_SSL

sasl.jaas.config=org.apache.kafka.common.security.plain.PlainLoginModule required \
  username="__<client_id>__" \
  password="__<client_secret>__";
----
+
NOTE: {product} also supports the SASL/OAUTHBEARER mechanism for authentication, which is the recommended authentication mechanism to use. However, the Kafka bin scripts do not yet fully support OAUTHBEARER, so this example uses SASL/PLAIN.

. Save the file. You will use it in the next task to connect to your Kafka instance and produce messages.

[id="proc-producing-messages-kafka-bin-scripts_{context}"]
== Producing messages using Kafka bin scripts

You can use the `kafka-console-producer` script to produce messages to Kafka topics.

.Prerequisites

* The Kafka bin scripts are downloaded.
* You have a running Kafka instance in {product}.
* You have the bootstrap server endpoint (external server endpoint) for your service account. You retrieved this information previously for the Kafka instance in {product} by selecting the options menu (three vertical dots), clicking *Connect to instance*, and generating the service account.
* You have created the `{property-file-name}` file to store your service account credentials.

.Procedure

. On the command line, from the `bin/` directory, enter the following command to start the `kafka-console-producer` script.
+
--
This example uses the SASL/PLAIN authentication mechanism with the credentials that you saved in the `{property-file-name}` file. This example produces messages to the `my-other-topic` example topic. If this topic does not exist yet, it is automatically created with default settings.

.Starting the `kafka-console-producer` script
[source,subs="+quotes,+attributes"]
----
./kafka-console-producer.sh --topic my-other-topic --bootstrap-server "__<bootstrap_server>__" --producer.config ../config/{property-file-name}
----
--

. With the `kafka-console-producer` script running, enter messages that you want to produce to the Kafka topic.
+
.Example messages to produce to the Kafka topic
[source]
----
>First message
>Second message
>Third message
----

. Keep the producer running to use later when you create a consumer.

.Verification
ifdef::qs[]
* Is the `kafka-console-producer` script still running without any errors in the terminal?
endif::[]
ifndef::qs[]
* Verify that the `kafka-console-producer` script is still running without any errors in the terminal.
endif::[]

[id="proc-consuming-messages-kafka-bin-scripts_{context}""]
== Consuming messages using Kafka bin scripts

You can use the `kafka-console-consumer` script to consume messages from Kafka topics. This example consumes the messages that you sent previously with the producer that you created with the `kafka-console-producer` script.

.Prerequisites

* You used the `kafka-console-producer` script to produce example messages to a topic.

.Procedure

. On the command line in a separate terminal from your producer, enter the following command to start the `kafka-console-consumer` script.
+
--
This example uses the SASL/PLAIN authentication mechanism with the credentials that you saved in the `{property-file-name}` file. This example consumes and displays the messages from the `my-other-topic` example topic.

.Starting the `kafka-console-consumer` script

[source,subs="+quotes,+attributes"]
----
$ ./kafka-console-consumer.sh -topic my-other-topic --bootstrap-server "__<bootstrap_server>__" --from-beginning --consumer.config ../config/{property-file-name}
First message
Second message
Third message
----
--

. If your producer is still running in a separate terminal, continue entering messages in the producer terminal and observe the messages being consumed in the consumer terminal.

.Verification
ifdef::qs[]
* Is the `kafka-console-consumer` script running without any errors in the terminal?
* Did the `kafka-console-consumer` script display the messages from the `my-other-topic` example topic?
endif::[]
ifndef::qs[]
. Verify that the `kafka-console-consumer` script is running without any errors in the terminal.
. Verify that the `kafka-console-consumer` script displays the messages from the `my-other-topic` example topic.
endif::[]


ifdef::qs[]
[#conclusion]
Congratulations! You successfully completed the {product} Kafka bin scripts quick start, and are now ready to produce and consume messages in the service.
endif::[]

ifdef::parent-context[:context: {parent-context}]
ifndef::parent-context[:!context:]
