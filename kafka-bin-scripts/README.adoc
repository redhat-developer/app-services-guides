////
START GENERATED ATTRIBUTES
WARNING: This content is generated by running npm --prefix .build run generate:attributes
////


:community:
:imagesdir: ./images
:product-version: 1
:product-long: Application Services
:product: App Services
:registry-product-long: Red Hat OpenShift Service Registry
:registry: Service Registry
// Placeholder URL, when we get a HOST UI for the service we can put it here properly
:service-url: https://console.redhat.com/beta/application-services/streams/
:registry-url: https://console.redhat.com/beta/application-services/service-registry/
:property-file-name: app-services.properties
:rhoas-version: 0.32.0

// Other upstream project names
:samples-git-repo: https://github.com/redhat-developer/app-services-guides

//URL components for cross refs
:base-url: https://github.com/redhat-developer/app-services-guides/blob/main/
:base-url-cli: https://github.com/redhat-developer/app-services-cli/tree/main/docs/
:getting-started-url: getting-started/README.adoc
:getting-started-service-registry-url: getting-started-service-registry/README.adoc
:kafka-bin-scripts-url: kafka-bin-scripts/README.adoc
:kafkacat-url: kafkacat/README.adoc
:quarkus-url: quarkus/README.adoc
:quarkus-service-registry-url: quarkus-service-registry/README.adoc
:rhoas-cli-url: rhoas-cli/README.adoc
:rhoas-cli-kafka-url: rhoas-cli-kafka/README.adoc
:rhoas-cli-service-registry-url: rhoas-cli-service-registry/README.adoc
:rhoas-cli-ref-url: commands
:topic-config-url: topic-configuration/README.adoc
:consumer-config-url: consumer-configuration/README.adoc
:service-binding-url: service-discovery/README.adoc
:access-mgmt-url: access-mgmt/README.adoc

////
END GENERATED ATTRIBUTES
////

[id="chap-kafka-bin-scripts"]
= Configuring and connecting Kafka scripts with {product-long}
ifdef::context[:parent-context: {context}]
:context: using-kafka-bin-scripts

[IMPORTANT]
====
{product-long} is currently available for Development Preview. Development Preview releases provide early access to a limited set of features that might not be fully tested and that might change in the final GA version. Users should not use Development Preview software in production or for business-critical workloads. Limited documentation is available for Development Preview releases and is typically focused on fundamental user goals.
====

// Purpose statement for the assembly
[role="_abstract"]
As a developer of applications and services, you can use Kafka scripts to manage your Kafka instances in {product-long}.
The Kafka scripts are a set of shell scripts that are included with the https://kafka.apache.org/downloads[Apache Kafka distribution^].
With these scripts, you can produce and consume messages for your Kafka instances.

ifndef::community[]
NOTE: The Kafka scripts are part of the open source community version of Apache Kafka. The scripts are not a part of {product} and are therefore not supported by Red Hat.
endif::[]

When you download and extract the Apache Kafka distribution, the `bin/` directory (or the `bin\windows\` directory if you're using Windows) of the distribution contains a set of shell scripts that enable you to interact with your Kafka instance.
With the scripts, you can produce and consume messages, and perform various operations against the Kafka APIs to administer topics, consumer groups, and other resources.

NOTE: The command examples in this quick start demonstrate how to use the Kafka scripts on Linux and macOS. If you're using Windows, use the Windows versions of the scripts. For example, instead of the `__<Kafka-distribution-dir>__/bin/kafka-console-producer.sh` script, use the `__<Kafka-distribution-dir>__\bin\windows\kafka-console-producer.bat` script.

.Prerequisites
ifndef::community[]
* You have a Red Hat account.
endif::[]
* You have a running Kafka instance in {product}.
* https://adoptopenjdk.net/[JDK^] 11 or later is installed.
* For Windows, the latest version of https://www.oracle.com/java/technologies/javase-downloads.html[Oracle JDK^] is installed.
* You've downloaded the latest supported binary version of the https://kafka.apache.org/downloads[Apache Kafka distribution^].
+
.Verifying Kafka scripts
[source]
----
$ ./kafka-console-producer.sh --version
2.7.0 (Commit:448719dc99a19793)
----

ifdef::qs[]
[#description]
Learn how to use Kafka scripts to interact with a Kafka instance in {product-long}.

[#introduction]
Welcome to the quick start for {product-long} with Kafka scripts. In this quick start, you'll learn how to use the Kafka scripts to produce and consume messages for your Kafka instances in {product}.
endif::[]

[id="proc-configuring-kafka-bin-scripts_{context}"]
== Configuring the Kafka scripts to connect to a Kafka instance

To enable the Kafka scripts to access a Kafka instance, you must configure the connection using the generated credentials for your {product} service account. For the Kafka scripts, you will create a configuration file that defines these values.

.Prerequisites
ifndef::qs[]
* You have the generated credentials for your service account. To regenerate the credentials, use the *Service Accounts* page in the {product} web console to find your service account and update the credentials.
* You've set the permissions for your service account to access the Kafka instance resources. To verify the current permissions, select your Kafka instance in the {product} web console and use the *Access* page to find your service account permission settings.
endif::[]

.Procedure

. In your Kafka distribution, navigate to the `config/` directory.

. Create a file called `{property-file-name}`.

. In the `{property-file-name}` file, set the SASL connection mechanism and the Kafka instance client credentials. Replace the values with your own credential information.
+
--
ifdef::qs[]
The `<client_id>` and `<client_secret>` are the generated credentials for your service account. You copied this information previously for the Kafka instance in {product} by selecting the options menu (three vertical dots), clicking *Connection*, and creating the service account.
endif::[]

.Setting server and credential values
[source,subs="+quotes"]
----
sasl.mechanism=PLAIN
security.protocol=SASL_SSL

sasl.jaas.config=org.apache.kafka.common.security.plain.PlainLoginModule required \
  username="__<client_id>__" \
  password="__<client_secret>__" ;
----

NOTE: {product} also supports the SASL/OAUTHBEARER mechanism for authentication, which is the recommended authentication mechanism to use. However, the Kafka scripts do not yet fully support OAUTHBEARER, so this example uses SASL/PLAIN.

--
. Save the file. You will use it in the next task to connect to your Kafka instance and produce messages.

[id="proc-producing-messages-kafka-bin-scripts_{context}"]
== Producing messages using Kafka scripts

You can use the `kafka-console-producer` script to produce messages to Kafka topics.

.Prerequisites

* You have a running Kafka instance in {product}.
ifndef::qs[]
* You have the bootstrap server endpoint for your Kafka instance. To relocate the server endpoint, select your Kafka instance in the {product} web console, select the options menu (three vertical dots), and click *Connection*.
* You've set the permissions for your service account to access the Kafka instance resources. To verify the current permissions, select your Kafka instance in the {product} web console and use the *Access* page to find your service account permission settings.
endif::[]
* You've created the `{property-file-name}` file to store your service account credentials.

.Procedure
. On the command line, from the `bin/` directory, enter the following command to create a Kafka topic.
+
--
This example uses the `kafka-topics` script to create the `my-other-topic` Kafka topic with the default settings.

ifdef::qs[]
The `<bootstrap_server>` is the bootstrap server endpoint for your Kafka instance. You copied this information previously for the Kafka instance in {product} by selecting the options menu (three vertical dots) and clicking *Connection*.
endif::[]

.Using the `kafka-topics` script to create a Kafka topic
[source,subs="+quotes,+attributes"]
----
$ ./kafka-topics.sh --create --topic my-other-topic --bootstrap-server __<bootstrap_server>__ --command-config ../config/{property-file-name}
Created topic my-other-topic.
----
--

. Enter the following command to start the `kafka-console-producer` script.
+
--
This example uses the SASL/PLAIN authentication mechanism with the credentials that you saved in the `{property-file-name}` file. This example produces messages to the `my-other-topic` example topic that you created.

.Starting the `kafka-console-producer` script
[source,subs="+quotes,+attributes"]
----
$ ./kafka-console-producer.sh --topic my-other-topic --bootstrap-server "__<bootstrap_server>__" --producer.config ../config/{property-file-name}
----
--

. With the `kafka-console-producer` script running, enter messages that you want to produce to the Kafka topic.
+
.Example messages to produce to the Kafka topic
[source]
----
>First message
>Second message
>Third message
----

. Keep the producer running to use later when you create a consumer.

.Verification
ifdef::qs[]
* Is the `kafka-console-producer` script still running without any errors in the terminal?
endif::[]
ifndef::qs[]
* Verify that the `kafka-console-producer` script is still running without any errors in the terminal.
endif::[]

[id="proc-consuming-messages-kafka-bin-scripts_{context}"]
== Consuming messages using Kafka scripts

You can use the `kafka-console-consumer` script to consume messages from Kafka topics. This example consumes the messages that you sent previously with the producer that you created with the `kafka-console-producer` script.

.Prerequisites

* You used the `kafka-console-producer` script to produce example messages to a topic.

.Procedure

. On the command line in a separate terminal from your producer, enter the following command to start the `kafka-console-consumer` script.
+
--
This example uses the SASL/PLAIN authentication mechanism with the credentials that you saved in the `{property-file-name}` file. This example consumes and displays the messages from the `my-other-topic` example topic.

.Starting the `kafka-console-consumer` script

[source,subs="+quotes,+attributes"]
----
$ ./kafka-console-consumer.sh --topic my-other-topic --bootstrap-server "__<bootstrap_server>__" --from-beginning --consumer.config ../config/{property-file-name}
First message
Second message
Third message
----
--

. If your producer is still running in a separate terminal, continue entering messages in the producer terminal and observe the messages being consumed in the consumer terminal.

.Verification
ifdef::qs[]
* Is the `kafka-console-consumer` script running without any errors in the terminal?
* Did the `kafka-console-consumer` script display the messages from the `my-other-topic` example topic?
endif::[]
ifndef::qs[]
. Verify that the `kafka-console-consumer` script is running without any errors in the terminal.
. Verify that the `kafka-console-consumer` script displays the messages from the `my-other-topic` example topic.
endif::[]


ifdef::qs[]
[#conclusion]
Congratulations! You successfully completed the {product} Kafka scripts quick start, and are now ready to produce and consume messages in the service.
endif::[]

ifdef::parent-context[:context: {parent-context}]
ifndef::parent-context[:!context:]
