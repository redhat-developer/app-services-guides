////
START GENERATED ATTRIBUTES
WARNING: This content is generated by running npm --prefix .build run generate:attributes
////


:community:
:imagesdir: ./images
:product-version: 1
:product-long: Application Services
:product: App Services
// Placeholder URL, when we get a HOST UI for the service we can put it here properly
:service-url: https://cloud.redhat.com/beta/application-services/streams/
:property-file-name: app-services.properties

// Other upstream project names
:samples-git-repo: https://github.com/redhat-developer/app-services-guides

//URL components for cross refs
:base-url: https://github.com/redhat-developer/app-services-guides/blob/main/
:base-url-cli: https://github.com/redhat-developer/app-services-cli/tree/main/docs/
:getting-started-url: getting-started/README.adoc
:kafka-bin-scripts-url: kafka-bin-scripts/README.adoc
:kafkacat-url: kafkacat/README.adoc
:quarkus-url: quarkus/README.adoc
:rhoas-cli-url: rhoas-cli/README.adoc
:rhoas-cli-ref-url: commands
:topic-config-url: topic-configuration/README.adoc

////
END GENERATED ATTRIBUTES
////

[id="chap-kafka-bin-scripts"]
= Using Kafka bin scripts with {product-long}
ifdef::context[:parent-context: {context}]
:context: using-kafka-bin-scripts

[IMPORTANT]
====
{product-long} is currently available for Development Preview. Development Preview releases provide early access to a limited set of features that might not be fully tested and that might change in the final GA version. Users should not use Development Preview software in production or for business-critical workloads. Limited documentation is available for Development Preview releases and is typically focused on fundamental user goals.
====

// Purpose statement for the assembly
[role="_abstract"]
As a developer of applications and services, you can use the Kafka bin scripts to manage your Kafka instances in {product-long}.
The Kafka bin scripts are a set of shell scripts that are included with the Apache Kafka distribution.
With these bin scripts, you can produce and consume messages for your Kafka instances.

NOTE: The command examples in this quick start demonstrate how to use the Kafka bin scripts on Linux and macOS. If you're using Windows, use the Windows versions of the bin scripts. For example, instead of the `__<Kafka-distribution-dir>__/bin/kafka-console-producer.sh` script, use the `__<Kafka-distribution-dir>__\bin\windows\kafka-console-producer.bat` script.

.Prerequisites
ifndef::community[]
* You have a Red Hat account.
endif::[]
* You have a running Kafka instance in {product}.
* https://adoptopenjdk.net/[JDK^] 11 or later is installed.
* For Windows, the latest version of https://www.oracle.com/java/technologies/javase-downloads.html[Oracle JDK^] is installed.

ifdef::qs[]
[#description]
Learn how to use Kafka bin scripts to interact with a Kafka instance in {product-long}.

[#introduction]
Welcome to the quick start for {product-long} with Kafka bin scripts. In this quick start, you'll learn how to use the Kafka bin scripts to produce and consume messages for your Kafka instances in {product}.
endif::[]

[id="proc-downloading-kafka-bin-scripts_{context}"]
== Downloading the Kafka bin scripts

The Kafka bin scripts are the binary scripts that are provided in the https://kafka.apache.org/downloads[Apache Kafka distribution^]. When you extract the Apache Kafka distribution, the `bin/` directory (or the `bin\windows\` directory if you're using Windows) of the distribution contains a set of shell scripts that enable you to interact with your Kafka instance. With the bin scripts, you can produce and consume messages, and perform various operations against the Kafka APIs to administer topics, consumer groups, and other resources.

ifndef::community[]
NOTE: The Kafka bin scripts are part of the open source community version of Apache Kafka. The bin scripts are not a part of {product} and are therefore not supported by Red Hat.
endif::[]

.Procedure
. In a web browser, go to the Kafka https://kafka.apache.org/downloads[Download^] page and download the latest binary version of Apache Kafka.
. Extract the downloaded archive and navigate to the `bin/` directory.
+
--
This example extracts the archive and then changes to the `bin/` directory.

.Extracting the Kafka archive and navigating to the `bin/` directory
[source]
----
$ tar -xzf kafka_2.13-2.7.0.tgz
$ cd kafka_2.13-2.7.0/bin
----

The `bin/` directory contains the Kafka bin scripts.
--

. Review the scripts in the `bin/` directory and verify that you have the `kafka-console-producer` and `kafka-console-consumer` scripts.

. Check the version number of the `kafka-console-producer` script to verify that the scripts were downloaded correctly.
+
.Verifying Kafka bin scripts
[source]
----
$ ./kafka-console-producer.sh --version
2.7.0 (Commit:448719dc99a19793)
----

ifdef::qs[]
.Verification
. Were the Kafka bin scripts installed successfully?
endif::qs[]

[id="proc-configuring-kafka-bin-scripts_{context}"]
== Configuring the Kafka bin scripts to connect to a Kafka instance

To enable the Kafka bin scripts to access a Kafka instance, you must configure the connection using the generated credentials for your {product} service account. For the Kafka bin scripts, you will create a configuration file that defines these values.

.Prerequisites
ifndef::qs[]
* You have the generated credentials for your service account. You copied this information previously for the Kafka instance in {product} by selecting the options menu (three vertical dots), clicking *View connection information*, and creating the service account.
endif::[]

.Procedure

. In your Kafka distribution, navigate to the `config/` directory.

. Create a file called `{property-file-name}`.

. In the `{property-file-name}` file, add the following content to set the Kafka instance client credentials. Replace the values with your own server and credential information.
+
--
ifdef::qs[]
The `<client_id>` and `<client_secret>` are the generated credentials for your service account. You copied this information previously for the Kafka instance in {product} by selecting the options menu (three vertical dots), clicking *View connection information*, and creating the service account.
endif::[]

.Setting server and credential values
[source,subs="+quotes"]
----
sasl.mechanism=PLAIN
security.protocol=SASL_SSL

sasl.jaas.config=org.apache.kafka.common.security.plain.PlainLoginModule required \
  username="__<client_id>__" \
  password="__<client_secret>__";
----

NOTE: {product} also supports the SASL/OAUTHBEARER mechanism for authentication, which is the recommended authentication mechanism to use. However, the Kafka bin scripts do not yet fully support OAUTHBEARER, so this example uses SASL/PLAIN.

--
. Save the file. You will use it in the next task to connect to your Kafka instance and produce messages.

[id="proc-producing-messages-kafka-bin-scripts_{context}"]
== Producing messages using Kafka bin scripts

You can use the `kafka-console-producer` script to produce messages to Kafka topics.

.Prerequisites

* The Kafka bin scripts are downloaded.
* You have a running Kafka instance in {product}.
ifndef::qs[]
* You have the bootstrap server endpoint for your service account. You copied this information previously for the Kafka instance in {product} by selecting the options menu (three vertical dots) and clicking *View connection information*.
endif::[]
* You have created the `{property-file-name}` file to store your service account credentials.

.Procedure
. On the command line, from the `bin/` directory, enter the following command to create a Kafka topic.
+
--
This example uses the `kafka-topics` script to create the `my-other-topic` Kafka topic with the default settings.

ifdef::qs[]
The `<bootstrap_server>` is the bootstrap server endpoint for your service account. You copied this information previously for the Kafka instance in {product} by selecting the options menu (three vertical dots) and clicking *View connection information*.
endif::[]

.Using the `kafka-topics` script to create a Kafka topic
[source,subs="+quotes,+attributes"]
----
$ ./kafka-topics.sh --create --topic my-other-topic --bootstrap-server __<bootstrap_server>__ --command-config ../config/{property-file-name}
Created topic my-other-topic.
----
--

. Enter the following command to start the `kafka-console-producer` script.
+
--
This example uses the SASL/PLAIN authentication mechanism with the credentials that you saved in the `{property-file-name}` file. This example produces messages to the `my-other-topic` example topic that you created.

.Starting the `kafka-console-producer` script
[source,subs="+quotes,+attributes"]
----
$ ./kafka-console-producer.sh --topic my-other-topic --bootstrap-server "__<bootstrap_server>__" --producer.config ../config/{property-file-name}
----
--

. With the `kafka-console-producer` script running, enter messages that you want to produce to the Kafka topic.
+
.Example messages to produce to the Kafka topic
[source]
----
>First message
>Second message
>Third message
----

. Keep the producer running to use later when you create a consumer.

.Verification
ifdef::qs[]
* Is the `kafka-console-producer` script still running without any errors in the terminal?
endif::[]
ifndef::qs[]
* Verify that the `kafka-console-producer` script is still running without any errors in the terminal.
endif::[]

[id="proc-consuming-messages-kafka-bin-scripts_{context}"]
== Consuming messages using Kafka bin scripts

You can use the `kafka-console-consumer` script to consume messages from Kafka topics. This example consumes the messages that you sent previously with the producer that you created with the `kafka-console-producer` script.

.Prerequisites

* You used the `kafka-console-producer` script to produce example messages to a topic.

.Procedure

. On the command line in a separate terminal from your producer, enter the following command to start the `kafka-console-consumer` script.
+
--
This example uses the SASL/PLAIN authentication mechanism with the credentials that you saved in the `{property-file-name}` file. This example consumes and displays the messages from the `my-other-topic` example topic.

.Starting the `kafka-console-consumer` script

[source,subs="+quotes,+attributes"]
----
$ ./kafka-console-consumer.sh -topic my-other-topic --bootstrap-server "__<bootstrap_server>__" --from-beginning --consumer.config ../config/{property-file-name}
First message
Second message
Third message
----
--

. If your producer is still running in a separate terminal, continue entering messages in the producer terminal and observe the messages being consumed in the consumer terminal.

.Verification
ifdef::qs[]
* Is the `kafka-console-consumer` script running without any errors in the terminal?
* Did the `kafka-console-consumer` script display the messages from the `my-other-topic` example topic?
endif::[]
ifndef::qs[]
. Verify that the `kafka-console-consumer` script is running without any errors in the terminal.
. Verify that the `kafka-console-consumer` script displays the messages from the `my-other-topic` example topic.
endif::[]


ifdef::qs[]
[#conclusion]
Congratulations! You successfully completed the {product} Kafka bin scripts quick start, and are now ready to produce and consume messages in the service.
endif::[]

ifdef::parent-context[:context: {parent-context}]
ifndef::parent-context[:!context:]
